<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Methodology | DO NOT DISTRIBUTE: PP-attachment ambiguities</title>
  <meta name="description" content="3 Methodology | DO NOT DISTRIBUTE: PP-attachment ambiguities" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Methodology | DO NOT DISTRIBUTE: PP-attachment ambiguities" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Methodology | DO NOT DISTRIBUTE: PP-attachment ambiguities" />
  
  
  

<meta name="author" content="Tyler J. Peckenpaugh" />


<meta name="date" content="2019-07-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="background.html">
<link rel="next" href="results-and-discussion.html">
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="assets/kePrint-0.0.1/kePrint.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#todo"><i class="fa fa-check"></i><b>0.1</b> TODO</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-is-a-garden-path"><i class="fa fa-check"></i><b>1.1</b> What is a garden path?</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#pp-attachment-garden-paths"><i class="fa fa-check"></i><b>1.2</b> PP-attachment garden paths</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#an-observation"><i class="fa fa-check"></i><b>1.3</b> An observation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>2</b> Background</a><ul>
<li class="chapter" data-level="2.1" data-path="background.html"><a href="background.html#mech"><i class="fa fa-check"></i><b>2.1</b> Structural overview of the ambiguity relevant to this study</a></li>
<li class="chapter" data-level="2.2" data-path="background.html"><a href="background.html#interrogativity"><i class="fa fa-check"></i><b>2.2</b> Interrogativity</a></li>
<li class="chapter" data-level="2.3" data-path="background.html"><a href="background.html#prosody-of-questions-vs.-declaratives"><i class="fa fa-check"></i><b>2.3</b> Prosody of questions vs. declaratives</a></li>
<li class="chapter" data-level="2.4" data-path="background.html"><a href="background.html#can-prosody-affect-parsing"><i class="fa fa-check"></i><b>2.4</b> Can prosody affect parsing?</a></li>
<li class="chapter" data-level="2.5" data-path="background.html"><a href="background.html#predictions-for-the-current-study"><i class="fa fa-check"></i><b>2.5</b> Predictions for the current study</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="methodology.html"><a href="methodology.html"><i class="fa fa-check"></i><b>3</b> Methodology</a><ul>
<li class="chapter" data-level="3.1" data-path="methodology.html"><a href="methodology.html#participants-recruitment"><i class="fa fa-check"></i><b>3.1</b> Participants recruitment</a></li>
<li class="chapter" data-level="3.2" data-path="methodology.html"><a href="methodology.html#location"><i class="fa fa-check"></i><b>3.2</b> Location</a></li>
<li class="chapter" data-level="3.3" data-path="methodology.html"><a href="methodology.html#equipment-and-software"><i class="fa fa-check"></i><b>3.3</b> Equipment and software</a></li>
<li class="chapter" data-level="3.4" data-path="methodology.html"><a href="methodology.html#materials"><i class="fa fa-check"></i><b>3.4</b> Materials</a><ul>
<li class="chapter" data-level="3.4.1" data-path="methodology.html"><a href="methodology.html#experimental-items"><i class="fa fa-check"></i><b>3.4.1</b> Experimental items</a></li>
<li class="chapter" data-level="3.4.2" data-path="methodology.html"><a href="methodology.html#fillers"><i class="fa fa-check"></i><b>3.4.2</b> Fillers</a></li>
<li class="chapter" data-level="3.4.3" data-path="methodology.html"><a href="methodology.html#length"><i class="fa fa-check"></i><b>3.4.3</b> Length</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="methodology.html"><a href="methodology.html#versions-of-the-experiment"><i class="fa fa-check"></i><b>3.5</b> Versions of the experiment</a></li>
<li class="chapter" data-level="3.6" data-path="methodology.html"><a href="methodology.html#procedure"><i class="fa fa-check"></i><b>3.6</b> Procedure</a><ul>
<li class="chapter" data-level="3.6.1" data-path="methodology.html"><a href="methodology.html#look-ahead"><i class="fa fa-check"></i><b>3.6.1</b> On look-ahead</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="methodology.html"><a href="methodology.html#methodirt"><i class="fa fa-check"></i><b>3.7</b> Inter-reading time (IRT) measurement</a><ul>
<li class="chapter" data-level="3.7.1" data-path="methodology.html"><a href="methodology.html#timing-measurement-reliability"><i class="fa fa-check"></i><b>3.7.1</b> Timing measurement reliability</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="methodology.html"><a href="methodology.html#prosodic-judgments"><i class="fa fa-check"></i><b>3.8</b> Prosodic judgments</a><ul>
<li class="chapter" data-level="3.8.1" data-path="methodology.html"><a href="methodology.html#reliability"><i class="fa fa-check"></i><b>3.8.1</b> Reliability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="results-and-discussion.html"><a href="results-and-discussion.html"><i class="fa fa-check"></i><b>4</b> Results and discussion</a><ul>
<li class="chapter" data-level="4.1" data-path="results-and-discussion.html"><a href="results-and-discussion.html#missing-data"><i class="fa fa-check"></i><b>4.1</b> Missing data</a></li>
<li class="chapter" data-level="4.2" data-path="results-and-discussion.html"><a href="results-and-discussion.html#results-prosody"><i class="fa fa-check"></i><b>4.2</b> Prosodic break patterns</a><ul>
<li class="chapter" data-level="4.2.1" data-path="results-and-discussion.html"><a href="results-and-discussion.html#regression-models-of-prosodic-break-patterns"><i class="fa fa-check"></i><b>4.2.1</b> Regression models of prosodic break patterns</a></li>
<li class="chapter" data-level="4.2.2" data-path="results-and-discussion.html"><a href="results-and-discussion.html#on-reading-1-delay"><i class="fa fa-check"></i><b>4.2.2</b> On reading 1 delay</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="results-and-discussion.html"><a href="results-and-discussion.html#irt"><i class="fa fa-check"></i><b>4.3</b> Inter-reading time</a><ul>
<li class="chapter" data-level="4.3.1" data-path="results-and-discussion.html"><a href="results-and-discussion.html#irtDis"><i class="fa fa-check"></i><b>4.3.1</b> Data cleanup</a></li>
<li class="chapter" data-level="4.3.2" data-path="results-and-discussion.html"><a href="results-and-discussion.html#irtRes"><i class="fa fa-check"></i><b>4.3.2</b> IRT results</a></li>
<li class="chapter" data-level="4.3.3" data-path="results-and-discussion.html"><a href="results-and-discussion.html#pp2h"><i class="fa fa-check"></i><b>4.3.3</b> On PP2 heads</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="results-and-discussion.html"><a href="results-and-discussion.html#discussion-of-irt-results"><i class="fa fa-check"></i><b>4.4</b> Discussion of IRT results</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discussion-and-conclusion.html"><a href="discussion-and-conclusion.html"><i class="fa fa-check"></i><b>5</b> Discussion and conclusion</a><ul>
<li class="chapter" data-level="5.1" data-path="discussion-and-conclusion.html"><a href="discussion-and-conclusion.html#the-intuition"><i class="fa fa-check"></i><b>5.1</b> The intuition</a><ul>
<li class="chapter" data-level="5.1.1" data-path="discussion-and-conclusion.html"><a href="discussion-and-conclusion.html#behavioral-correlate-for-the-intuition"><i class="fa fa-check"></i><b>5.1.1</b> Behavioral correlate for the intuition</a></li>
<li class="chapter" data-level="5.1.2" data-path="discussion-and-conclusion.html"><a href="discussion-and-conclusion.html#explaining-the-intuition"><i class="fa fa-check"></i><b>5.1.2</b> Explaining the intuition</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="discussion-and-conclusion.html"><a href="discussion-and-conclusion.html#confound"><i class="fa fa-check"></i><b>5.2</b> On future work</a><ul>
<li class="chapter" data-level="5.2.1" data-path="discussion-and-conclusion.html"><a href="discussion-and-conclusion.html#hesitations-vs.-prosodic-breaks"><i class="fa fa-check"></i><b>5.2.1</b> Hesitations vs. prosodic breaks</a></li>
<li class="chapter" data-level="5.2.2" data-path="discussion-and-conclusion.html"><a href="discussion-and-conclusion.html#embedded-questions"><i class="fa fa-check"></i><b>5.2.2</b> Embedded questions</a></li>
<li class="chapter" data-level="5.2.3" data-path="discussion-and-conclusion.html"><a href="discussion-and-conclusion.html#erp"><i class="fa fa-check"></i><b>5.2.3</b> Event-related potential (ERP)</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="rec.html"><a href="rec.html"><i class="fa fa-check"></i><b>A</b> Recruitment notice</a></li>
<li class="chapter" data-level="B" data-path="appExp.html"><a href="appExp.html"><i class="fa fa-check"></i><b>B</b> Experimental items</a></li>
<li class="chapter" data-level="C" data-path="appFill.html"><a href="appFill.html"><i class="fa fa-check"></i><b>C</b> Filler items</a></li>
<li class="chapter" data-level="D" data-path="instr.html"><a href="instr.html"><i class="fa fa-check"></i><b>D</b> Instructions to participants</a></li>
<li class="chapter" data-level="E" data-path="RA.html"><a href="RA.html"><i class="fa fa-check"></i><b>E</b> Instructions to RA</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DO NOT DISTRIBUTE: PP-attachment ambiguities</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methodology" class="section level1">
<h1><span class="header-section-number">3</span> Methodology</h1>
<p>This section outlines the methodology employed for the reported study. The methodology outlined is referred to as the <em>Double Reading Procedure</em> and was first implemented by <span class="citation">Fodor et al. (2019)</span>. In this procedure, participants are asked to read sentences twice, once without taking any time to preview it(Reading 1), and then again after unlimited preview (Reading 2). <span class="citation">Fodor et al. (2019)</span> wanted to investigate the extent to which preview impacted the prosodic phrasing of center embedded sentences, as well as whether or not readers would find the doubly center-embedded sentences more comprehensible after preview (or, comprehensible at all, as the doubly center embedded sentences often were not on first attempt). In the prosody literature up to this point, preview has largely been ignored as a factor in reading aloud tasks. The <span class="citation">Fodor et al. (2019)</span> study found that preview did indeed impact both prosodic grouping that readers used and comprehensibility. While the questions being asked here are different, we are still concerned with the prosody that is produced, and the difficulty the reader experiences in parsing a sentence read aloud. This experimental paradigm eliminates the possible noise of not knowing whether a given pronunciation represents a considered or naive attempt to read a sentence aloud.</p>
<div id="participants-recruitment" class="section level2">
<h2><span class="header-section-number">3.1</span> Participants recruitment</h2>
<p>The participants in this study were all undergraduate students enrolled in Psychology 101. These students were required by thire university to participant in studies for course credit. Self reported age ranged from 18 to 25 years. Participants were recruited using the Queens College Sona system, which is software designed for university participant pools. Students saw a notice on the Sona website (see Appendix <a href="rec.html#rec">A</a>) and were able to schedule their own appointment time within the hours offered.</p>
<p>All participants were self identified native and primary speakers of American English. One participant was disqualified post-hoc after producing a Caribbean English pronunciation pattern; one other participant was excluded post-hoc due to an extremely disfluent reading cadence. Both excluded participants were still awarded class credit for participating.</p>
</div>
<div id="location" class="section level2">
<h2><span class="header-section-number">3.2</span> Location</h2>
<p>All data were collected in a private room with only the experimenter and participant present. While every effort was undertaken to ensure a quiet environment, intrusive noise from passersby or neighboring rooms were sometimes unavoidable. This resulted in some unusable or partially unusable recordings (detailed in section <a href="results-and-discussion.html#irtDis">4.3.1</a> of the results chapter).</p>
</div>
<div id="equipment-and-software" class="section level2">
<h2><span class="header-section-number">3.3</span> Equipment and software</h2>
<p>The experiment was presented on a laptop running Windows 10 with stickers on the keyboard labeling relevant keys. The left shift key was labeled <em>START</em>, right shift was labeled <em>NEXT</em>, and the touch-pad was labeled <em>DONE</em>.</p>
<p>The presentation of items and instruction<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> was done using the Open Sesame software <span class="citation">(Mathôt, Schreij, &amp; Theeuwes, 2012)</span> which provides a graphical user interface, scripting language, and interpretation of Python code, for precise control of experimental presentation.</p>
<p>Recording was done using a Blue Yeti USB microphone position near the participant’s left hand and angled to point at the space in front of the participant’s mouth. The angle was adjusted for each participant’s height. It recording 44.1kHz single-channel audio.</p>
</div>
<div id="materials" class="section level2">
<h2><span class="header-section-number">3.4</span> Materials</h2>
<p>In total there were 16 experimental items in 4 versions each, and 32 fillers in two versions each. The design decisions are discussed in detail in this section.</p>
<div id="experimental-items" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Experimental items</h3>
<p>The basic experimental items were created in a 2 x 2 design with one factor being speech act (interrogative/Q vs. declarative/D) and the other being PP2 status, i.e. PP2 was either a PP1 which must be an argument of the verb (Arg) or else one which can be a modifier (Mod) of the preceding phrase (PP1).</p>
<ol start="33" class="example" style="list-style-type: decimal">
<li>[Subject] [Verb-cluster: AUX + Matrix + Main] [Object] [PP1] [PP2]</li>
</ol>
<p>PP1 is always interpretable as either a modifier of the object NP or as the goal argument of the main verb; i.e. it is temporarily ambiguous. As a reminder, the running assumption is that the parser will initially assume PP1 to be the goal argument and attach it high (as an argument of the verb). For the +GP cases, PP2 will be incompatible with that structure and force reanalysis, so that PP1 attaches low as a modifier of the object and PP2 attaches high as the verbal argument. For the -GP cases, conversely, PP2 will be compatible with high attachment of PP1, i.e. will attach low as a modifier of PP1’s embedded NP. An example item in its four versions is provided in table <a href="methodology.html#tab:sentences">3.1</a>.</p>
<table>
<caption>
<span id="tab:sentences">Table 3.1: </span>Experimental item in four versions
</caption>
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Sentence
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
D Mod
</td>
<td style="text-align:left;">
He had intended to cram the paperwork in the drawer of his filing cabinet.
</td>
</tr>
<tr>
<td style="text-align:left;">
Q Mod
</td>
<td style="text-align:left;">
Had he intended to cram the paperwork in the drawer of his filing cabinet?
</td>
</tr>
<tr>
<td style="text-align:left;">
D Arg
</td>
<td style="text-align:left;">
He had intended to cram the paperwork in the drawer into his boss’s desk.
</td>
</tr>
<tr>
<td style="text-align:left;">
Q Arg
</td>
<td style="text-align:left;">
Had he intended to cram the paperwork in the drawer into his boss’s desk?
</td>
</tr>
</tbody>
</table>
<p>The experimental stimuli were based on earlier pilot study exploring this same phenomenon <span class="citation">Peckenpaugh (2016)</span>, but with several issues with that study’s items corrected. The sequence of parts for each of the basic items was always the same, shown in (34).</p>
<ol start="34" class="example" style="list-style-type: decimal">
<li><img src="item_diagram.png" /></li>
</ol>
<p>All versions of a quadruple had exactly the same introductory material, with the only difference with the introductory material being the necessary inversion of the auxiliary and the subject across the speech act factor. Across quadruples, the subject alternated between <em>she</em> and <em>he</em>, with half (8) using one and half using the other. The auxiliary was always <em>had</em>, between all quadruples and within each quadruple. The matrix verb did not vary within a quadruple, but did vary between quadruples; for any given quadruple, the matrix verb was one of four verbs of mental state (<em>decided</em>, <em>intended</em>, <em>wanted</em>, or <em>planned</em>).</p>
<p>The verb within the construction did not vary within a quadruple, but a given quadruple could have one of four verbs: <em>cram</em>, <em>put</em>, <em>stick</em> or <em>set.</em> The construction verb was always infinitival. Each construction verb was used in four quadruples, and paired once with each matrix verb, so that there were 16 unique pairings of matrix verb to construction verb forming the foundation of the 16 basic items, i.e. four basic items for each matrix verb, each one paired with a unique construction verb (e.g. <em>decided to cram</em>, <em>decided to stick</em>, <em>decided to put</em>, and <em>decided to set</em>); and four basic items for each construction verb, each one paired with a unique matrix verb (e.g. <em>decided to cram</em>, <em>intended to cram</em>, <em>wanted to cram</em>, and <em>planned to cram</em>). The content and word order of the construction was the same across all versions of a quadruple, with the exception of the content of PP2 which varied across the PP2-status factor but was fixed across the speech act factor. The Arg versions (Q and D) of a quadruple had a PP2 which was headed by <em>into</em> or <em>onto</em>, while the Mod versions of a quadruple had a PP2 which was headed by <em>of</em> or <em>from.</em></p>
<p>PP1 was the same across versions of a given quadruple. That is, PP1 was ambiguous in every version of a given quadruple, being interpretable as either a modifier of the object NP or as the goal argument of the construction verb; however, in Arg versions of a quadruple, the argument interpretation of PP1 becomes impossible once PP2 is encountered. In those cases PP2 must fill the goal argument slot and PP1 must be a modifier. The working assumptions about parsing discussed earlier, i.e. that the parser will initially assume PP1 to be the goal argument due to the primary status of arguments, assumes that Arg versions of a quadruple require reanalysis. Between quadruples, the preposition that headed PP1 varied, but was always one which was compatible with it being a goal argument or a modifier of the object: <em>in</em> (8), <em>on</em> (7), and in one case, <em>under.</em></p>
<p>One benefit of using a complex verb cluster (auxiliary + matrix + infinitive) rather than a single verb was that it isolated the differences across the versions of a quadruple triggered by the speech act factor to the left extremity of the introductory material of the sentence: only the position of the subject and the auxiliary were affected, meaning that the construction itself was completely untouched by this manipulation. Additionally, the use of an auxiliary eliminated length differences across D vs. Q versions of a quadruple that would have resulted without one: if an auxiliary verb were not present, the interrogative versions of a quadruple would have an extra word, the result of so-called <em>do</em>-support, that would not appear in the declaratives (e.g. <em>she put</em> … vs. <em>did she put</em> …?) As previously stated, the auxiliary was <em>had</em> for every member of every quadruple.</p>
<p>The purpose of including the past participle matrix verbs was to reduce the oddity of the polar questions (the two interrogative versions of each quadruple). It seems odd to ask, “did Mary put the jelly beans in the window onto a fancy dish?” because, when it is clear that the speaker already knows so much about the situation, it becomes difficult to imagine a pragmatically plausible context where the question would be asked. Such sentences might be described as “prosecutorial<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.” Arguably, this is somewhat mitigated by the addition of a verb like <em>decided</em>: rather than asking about facts that we already seem to know, we are instead asking about the actor’s mental state with regard to those facts. Even if we know the facts of the situation, we do not necessarily know, for instance, whether it was the result of a decision, some third party’s action, or mere happenstance.</p>
<p>Another concession to this concern was to limit the amount of detail in the sentence (e.g., fewer adjectives and adverbs compared to the items in <span class="citation">Peckenpaugh (2016)</span>) and to limit the subjects to first person nominative pronouns (<em>he</em> or <em>she</em>, 8 each).</p>
<p>Importantly, the construction verb was always one which required a PP goal argument. One of the issues with the items from <span class="citation">Peckenpaugh (2016)</span> was that some of the verbs used in the items for that study only optionally took a goal. Verbs that only optionally take a goal might result in a parse where PP1 is not immediately incorporated as the goal argument, which would mean that PP2 would not necessarily force reanalysis. Consider the contrasting sub-categorization of the verbs in (3536):</p>
<ol start="35" class="example" style="list-style-type: decimal">
<li><p><strong>Optional goal</strong> (<em>hide</em>)
The gangsters had hidden the shotguns in a U-Haul truck.
✓ The gangsters had hidden the shotguns.</p></li>
<li><strong>Obligatory goal</strong> (<em>put</em>)
The gangsters had put the shotguns in a U-Haul truck.</li>
</ol>
<ul>
<li>The gangsters had put the shotguns.</li>
</ul>
<p>A verb like hide, as in (35), can take a goal, but can also be used without one. A verb like put, on the other hand, as in (36), really must have a goal. In designing the items for this study, only verbs that require a goal argument were used in order to maximize the likelihood of a robust garden path effect in the Arg versions, when PP2 triggers reanalysis. The four main verbs used in this study were: cram, put, stick and set.</p>
<p>Another important consideration was ensuring that the Arg versions had a PP2 which fully disambiguated the attachment site of PP1 such that reanalysis is forced. In (37), PP2 is implausible as a modifier of rocking horse, but not strictly impossible, and the sentence is certainly grammatical with low attachment of PP2. On the other hand, the use of onto in (38) completely disallows the low attachment of PP2 at the syntactic level: a PP headed by onto cannot grammatically modify the preceding NP.</p>
<ol start="37" class="example" style="list-style-type: decimal">
<li>She had decided to put the child [PP1 on the rocking horse] [PP2 on the see-saw].</li>
<li>She had decided to put the child [PP1 on the rocking horse] [PP2 onto the see-saw].</li>
</ol>
<p>Where <span class="citation">Peckenpaugh (2016)</span> relied on plausibility to force reanalysis, the current study uses syntactic disambiguation, such that the Arg versions always have a PP2 headed by into or onto which cannot head a PP2 that modifies the NP of PP1. This avoids any noise that might result from discrepancies between individuals’ real world knowledge or beliefs. For the Mod items, the head preposition of PP2 was always either <em>from</em> or <em>of</em> (half and half, 8 each), which are compatible with a parse where PP1 is the goal argument and PP2 is modifying the NP within PP1. While from can be read as a goal argument, the assumptions made about how parsing works lead this to be an unlikely analysis, and of-headed PPs certainly cannot be a goal argument.</p>
<p>It is worth noting that some linguists believe of is not a preposition in the same sense as from, on, or in, etc., in that it appears to be serving a strictly grammatical or functional purpose, without any lexical content. Importantly, it is also only 2 characters, whereas into, onto, and from (the other possible heads of PP2) are all 4 characters. This is revisited and its possible impact is explored in the results section (section <a href="results-and-discussion.html#pp2h">4.3.3</a>.</p>
<p>To sum up, the experimental items were designed to have limited detail, with either <em>he</em> or <em>she</em> as the subject. A complex verb cluster, e.g. <em>had decided to cram</em> was used to facilitate subject-auxiliary inversion without <em>do</em>-support in the interrogatives and limit the difference between items, as well as provide a verb of mental state (<em>decided</em>, <em>intended</em>, <em>wanted</em>, or <em>planned</em>) to support more pragmatically plausible questions. PP1 was always interpretable as either the goal argument or a modifier of the object. PP2 differed across the PP2 status factor, but not across the speech act factor. In the two Arg versions of a quadruple, it was headed by <em>into</em> or <em>onto</em> and was intended to force reanalysis, under the assumption that PP1 had been incorporated into the parse as an argument, since a PP headed by <em>into</em> or <em>onto</em> must be interpreted as the goal argument, the position that PP1 would have presumably been occupying in the ongoing parse. For the two Mod versions of a quadruple, PP2 was headed by <em>from</em> or <em>of</em> and therefore was not expected to require reanalysis, as <em>from</em>- and <em>of</em>-headed PPs can attach as modifiers of a preceding NP (in this case, the NP within PP1), allowing PP1 to stay in the goal argument slot.</p>
</div>
<div id="fillers" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Fillers</h3>
<p>There were 32 filler items that ranged in complexity. Of these 32, 16 were designed to end in a sequence of two PPs, to mirror the experimental items (+PP). The other half contained no final PPs (-PP). All fillers were designed in two versions: declarative (D) and interrogative (Q).</p>
<ol start="39" class="example" style="list-style-type: decimal">
<li><em>D+PP:</em> He had forgotten to try the famous pastry in the restaurant of the fancy hotel.</li>
<li><p><em>Q+PP:</em> Had he forgotten to try the famous pastry in the restaurant of the fancy hotel?</p></li>
<li><em>D-PP:</em> She had forgotten to report that the clerk was ignoring her request.</li>
<li><p><em>Q-PP:</em> Had she forgotten to report that the clerk was ignoring her request?</p></li>
</ol>
<p>The +PP fillers were not related to the -PP fillers. All filler items had the same sort of introductory material as the experimental item (<em>he/she</em> + <em>had</em> + past participle verb of mental state). The past participle was always one of the four mental state used for the experimental items (<em>intended</em>, <em>decided</em>, <em>planned</em>, and <em>wanted</em>), or one of these additional four verbs of mental state: <em>forgotten</em>, <em>remembered</em>, <em>meant</em>, or <em>needed</em>, with each of the 8 past participles being used twice in the +PP fillers and twice in the -PP fillers, for a total of 4 times each. This means that a participant would see 6 instances each of <em>intended</em>, <em>decided</em>, <em>planned</em>, and <em>wanted</em> but only 4 instances of <em>forgotten</em>, <em>remembered</em>, <em>meant</em>, and <em>needed.</em> Fillers used both mental state verbs from the experimental items as well as others was to prevent the experimental items as being identifiable by which mental state verb was used, and to avoid extreme amounts of repetition for any given lexical item.</p>
<p>A full list of fillers is available in the appendices.</p>
</div>
<div id="length" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Length</h3>
<p>Length was tightly controlled across items. For experimental quadruples, all sentences were between 66 and 75 characters long, and between 13 and 15 words long. The length within a quadruple never varied across the D vs. Q factor. Across the PP2-status factor, given that the content of PP2 differed within a given quadruple, there was a maximum length difference of one character. Two quadruples varied in word length across PP2-status by one word. ACross all quadruples an equal number were longer (word- and character-wise) in the Arg condition as in the Mod condition. The experimental items ranged from 18 to 22 syllables.
Control over filler pair length was slightly less stringent. They ranged from 63 to 79 characters and 12 to 14 words. Length was never different within a filler pair.</p>
</div>
</div>
<div id="versions-of-the-experiment" class="section level2">
<h2><span class="header-section-number">3.5</span> Versions of the experiment</h2>
<p>The experiment was presented in 4 basic versions, with split-half ordering (where the first 24 of the items presented to one group was the second 24 presented to the other) for a total of 8 groups. Each version contained 8 practice items, 4 of which were overt practice and 4 of which were covert practice, as well as one version of each of the 16 experimental and 32 filler items. No version contained more than one version of a given experimental quadruple, or a given filler pair, and each version contained one member of every experimental quadruple and filler pair. Each participant saw the same number of each type of experimental quadruple: 4 D Arg, 4 Q Arg, 4 D Mod and 4 Q Mod. The experimental items were presented in pseudo-random order, interspersed with 1 to 3 fillers. Ignoring fillers, the same version of a different quadruple never occured in sequence (e.g. after encountering a D Arg, the next experimental item was never another D Arg).</p>
</div>
<div id="procedure" class="section level2">
<h2><span class="header-section-number">3.6</span> Procedure</h2>
<p>Participants were given a verbal overview of the experimental procedure and then asked to read a one page printout of the procedure before signing a consent form. After signing a consent form, participants sat at the computer and were once again walked through instructions before the first practice item was presented.</p>
<p>Participants sat at a computer and used keyboard button presses to navigate the experimental presentation. They received thorough instructions and completed three practice items, the consulted with the experimenter, before beginning the main portion of the study. The study also contained 4 pseudo-practice items that were not included in any analyses, in order to allow some time for the participant to settle into the procedure before any results were recorded.</p>
<p>Each experimental item was preceded by a screen showing a line of ten Xes with its left edge aligned with the left edge of the to-be-revealed sentence. This was intended to fix the participant’s attention on the start of the sentence, and hopefully avoid unintended look-ahead. The issue of potential look-ahead is discussed at greater length in section <a href="methodology.html#look-ahead">3.6.1</a></p>
<p>This screen remained visible indefinitely, until the participant pressed <em>START</em>.</p>
<p>Immediately after <em>START</em> was pressed, recording of the first reading began and the sentence appeared on the screen on a blue background. The recording continued and the screened remained visible until the participant pressed <em>NEXT</em>. After pressing <em>NEXT</em>, a screen appeared with instructions telling the participant that they were between readings, and needed to press <em>START</em> to reveal the sentence again and prepare for their second reading. Immediately after <em>START</em> was pressed, the first recording ended and the second recording began, and the sentence reappeared, this time on a green background.</p>
<div class="figure">
<img src="dissertation-procedure.png" alt="Procedure diagram" />
<p class="caption">Procedure diagram</p>
</div>
<p>The shifting of required key presses and the changing background color were intended to aid the participant in remember where they were in the process, and to prevent accidental double-presses of any given button from having unintended side effects. It took some time for the participants to adapt to the somewhat complicated procedure, but generally were well adjusted by the time the first item was presented.</p>
<div id="look-ahead" class="section level3">
<h3><span class="header-section-number">3.6.1</span> On look-ahead</h3>
<p>An advantage that the Double Reading Procedure has is that it allows for certain assumptions to be made about Reading 2 that otherwise would be unclear: Reading 2 certainly represents a considered reading of the sentence. Not only has the reader had ample time to examine the sentence, they have necessarily read it, and they have heard themselves read by way of producing Reading 1. This means Reading 2 can plausibly be thought to represent a considered prosodic structure, at least more so than an entirely naive reading, and it should not represent any processing issues, because a parse should have already been obtained during Reading 1, or during subsequent study of the sentence prior to Reading 2.</p>
<p>The nature of Reading 1 is less clear. Because there is variability in the delay between the display of the sentence and the onset of phonation, it’s possible that Reading 1 is not entirely without preview. The properties of these Reading 1 delays are discussed at length in a later section, but for now it suffices to say that the amount of preview that is possible during a delay that typically falls in the 0.2 to 2.7s range (median = 1s, SD = 0.4) is limited. As an example of common reading rates, Ashby et al. (2012) reported faster readers as averaging 328 words per minute (wpm), and slower readers 228wpm in silent reading. That study found that reading time is slower for reading aloud, and that the availability of parafoveal information (i.e. the difference between 1 word and 3 word windows) is less impactful for that reading mode. Given that the experimental items range from 13 to 15 words, most of the R1 delays would not allow even a fast reader to read the entire sentence: the median 1s R1 delay would allow a fast reader time to read only between 5 and 6 words. The utterance of Reading 1 should, for most recordings, contain within it any behavioral reflex of whatever parsing difficult the reader has.</p>
<p>In order to clearly understand the results of this double reading study, it’s important to understand the mechanics of reading. Specifically, we would want to know at what point during their reading of the sentence the participant will become aware of the existence of the disambiguating PP2, since this is when they will realize that their parse is going to crash. The work of several decades on this subject is thoroughly summarized in <span class="citation">Rayner, Pollatsek, Ashby, &amp; Clifton Jr (2012)</span>. They describe reading as consisting of a series of fixations, where the eyes attend to a specific point, and saccades, where the eyes move ahead ballistically (i.e. on a planned trajectory that cannot be interrupted). A consequence of the ballistics property of saccade movement and the additional finding that the landing sites (fixations) are not random, we can infer that at least some lookahead is available, i.e. the reader must know something about what is coming in order to choose a suitable landing site. The primary predictor of fixation point seems to be the character length of a word, meaning that the presence of characters and word boundary information (represented orthographically by spaces) at least are necessary at the periphery of attention, i.e. within the perceptual span. Some details on the perceptual span, or the information that can be accessed by the eyes at any given time, is discussed in brief, with special attention to its relevance for the study at hand.</p>
<p><span class="citation">Rayner et al. (2012)</span> discuss a number of studies that explore the size and properties of this span, the most fruitful of which is the gaze-contingent moving-window technique. In this technique, text is presented on a video monitor while the reader is also hooked up to eye-tracking equipment. A computer samples the position of the reader’s eyes every millisecond and updates the display. Using this elaborate system, and the mutilation of text outside a window of clear text, they can create a so-called moving window around the reader’s point of fixation. By manipulating the size of this window, they were able to determine that reading speed is maximized when about 15 characters to either side of the fixation site. Later, they discovered that this is actually asymmetric, and the window need only go as far as the start of currently fixated word in the direction of what has already been read (to the left, for English readers). In order to determine how much information was available at the periphery of the perceptual span, they manipulated how much information was destroyed outside the window of clear text, and used a window size known to be smaller than the ideal (21 characters, 10 to either side). They used a condition where all characters and spaces were replaced with xs, essentially destroying all information outside the window. They compared reading speeds with this system to one where character spaces were maintained, but all other information was obscured, as well as to one where characters were replaced with characters that had similar shape (i.e., the same pattern of ascenders and descenders) as the character they replaced, with and without spaces. Finally, they also looked at a mask where characters were replaced with dissimilar substitutes, with and without spaces.</p>
<p>Using these techniques and again manipulating the size of the window, they were able to determine that it is only word boundary information that is available at the extreme edge of the perceptual span; character shape (ascenders and descenders) is available about 10 characters out from the fixation point, and character identity is available more or less only for the fixated word.</p>
<p>The relevant question for the study at hand is, how much of the sentence will the reader have seen and processed when they are pronouncing a given word? A typical item is displayed in (43), with the words expected to be fixated underlined, numbered by presumed fixation sequence, and labeled. The number of characters intervening before the start of the disambiguating region (the left edge of PP2) is displayed below each label. These counts are from the initial character of the fixated word to the initial character of the disambiguating region; the actual fixation site is likely to be closer to the center of the word, meaning the distance would be shortened by a few (1-4) characters, depending on the length of the fixated word.</p>
<ol start="43" class="example" style="list-style-type: decimal">
<li><img src="distance-to-cr.png" /></li>
</ol>
<p>Table <a href="methodology.html#tab:dtcs">3.2</a> describes these distances across items all experimental items. Note that these values do not vary across condition, because counting starts after both the subject and auxiliary verb, and ends before PP2, and the only changes across versions are subject-auxiliary inversion and the content of PP2.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:dtcs">Table 3.2: </span>Distance in characters from fixation to disambiguation in experimental items
</caption>
<thead>
<tr>
<th style="text-align:right;">
</th>
<th style="text-align:center;">
1-INITIAL
</th>
<th style="text-align:center;">
2-CONSTRUCTION VERB
</th>
<th style="text-align:center;">
3-OBJ
</th>
<th style="text-align:right;">
4-PP1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
MEDIAN
</td>
<td style="text-align:center;">
46
</td>
<td style="text-align:center;">
34.5
</td>
<td style="text-align:center;">
25.5
</td>
<td style="text-align:right;">
7.5
</td>
</tr>
<tr>
<td style="text-align:right;">
MAX
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
38.0
</td>
<td style="text-align:center;">
27.0
</td>
<td style="text-align:right;">
9.0
</td>
</tr>
<tr>
<td style="text-align:right;">
MIN
</td>
<td style="text-align:center;">
45
</td>
<td style="text-align:center;">
32.0
</td>
<td style="text-align:center;">
21.0
</td>
<td style="text-align:right;">
5.0
</td>
</tr>
</tbody>
</table>
<p>From the initial fixation point, the distance to disambiguation ranges from 45 to 50 characters, with a median of 46 characters. If we recall that word boundary information is available 15 to 18 characters to the right of fixation, we can be certain that the disambiguating region is far out of view until several fixations in.</p>
<p>So, when does the reader become aware of the existence of PP12? When fixated on the direct object head noun, the range of distance is 21 to 27 characters, with a median of 25.5: still outside of view, even in the case of the smallest distance, and adjusting it to be a few characters smaller to account for the fact that fixation is likely to occur closer to the center of the word rather than on its first character. At most, the presence of the first few characters of PP2’s preposition may be available, but certainly not the character space after it. The distance from the PP1 fixation point (the head noun within that PP) ranges from 5 to 9 characters, with a median between 7 and 8 characters. Thus, we can say with some certainty that the reader of a sentence such as (1) will be aware that another phrase, one which starts with a 4 character word, remains to be incorporated into their parse sometime after they have processed the direct object, and before they have finished processing PP1.</p>
<p>There is yet another piece to consider: the so-called eye-voice span (EVS), and the fact that the readers in this study are reading aloud rather than silently. According to <span class="citation">Laubrock &amp; Kliegl (2015)</span>, when reading aloud the voice is typically behind the eyes by about 10-20 characters (M = 16.2 characters, SD = 5.2 characters). If we adjust table 1 by subtracting 16 from each cell, we can approximate the position of the voice when the disambiguating region comes within the perceptual span. These values are shown in table <a href="methodology.html#tab:evsdtcr">3.3</a>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:evsdtcr">Table 3.3: </span>EVS-adjusted character distance to disambiguation in experimental items
</caption>
<thead>
<tr>
<th style="text-align:right;">
</th>
<th style="text-align:center;">
1-INITIAL
</th>
<th style="text-align:center;">
2-CONSTRUCTION VERB
</th>
<th style="text-align:center;">
3-OBJ
</th>
<th style="text-align:right;">
4-PP1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
MEDIAN
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
18.5
</td>
<td style="text-align:center;">
9.5
</td>
<td style="text-align:right;">
-8.5
</td>
</tr>
<tr>
<td style="text-align:right;">
MAX
</td>
<td style="text-align:center;">
34
</td>
<td style="text-align:center;">
22.0
</td>
<td style="text-align:center;">
11.0
</td>
<td style="text-align:right;">
-7.0
</td>
</tr>
<tr>
<td style="text-align:right;">
MIN
</td>
<td style="text-align:center;">
29
</td>
<td style="text-align:center;">
16.0
</td>
<td style="text-align:center;">
5.0
</td>
<td style="text-align:right;">
-11.0
</td>
</tr>
</tbody>
</table>
<p>It is likely, then, that the voice would actually still be on the object when the eyes discover the existence of PP2, and will still be pronouncing PP1 when the eyes are first fixated on PP2. This raises a question about any prosodic breaks produced after the object, because it is difficult to distinguish between an intentional prosodic break at that point, versus the reader using a natural break for hesitation related to the garden path effect of discovering the disambiguating PP2.</p>
</div>
</div>
<div id="methodirt" class="section level2">
<h2><span class="header-section-number">3.7</span> Inter-reading time (IRT) measurement</h2>
<p>Subjects were asked to read each sentence twice, once with no preview at all (reading 1, a cold reading), and then again after unlimited preview (reading 2, a previewed reading). Inter-reading time (IRT) is a measure of the amount of time between when a subject stops speaking after a cold reading and when they begin speaking for a previewed reading.</p>
<p>IRT was measured using a Python script and Google’s WebRTC Voice Activity Detection (VAD) over 44.1kHz WAV files down-sampled to 8kHz via SOX<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. This VAD system uses Gaussian Mixture Models to make probabilistic decisions on whether a given audio frame is speech or noise (see <span class="citation">Falk &amp; Chan (2006)</span> for a complete explanation). Google’s implementation takes one parameter, which they call aggressiveness: a 4-tier setting for the level of confidence necessary to call a given frame speech. I call this “rejection rate”, where a higher rejection rate means that the model requires a high level of confidence before assuming a frame is speech, i.e. it is more likely to label something noise than speech. The implementation codes this setting as 0-3, where 0 is the most lenient (most likely to label a frame as speech) and 3 is the most stringent (most likely to label a frame as noise).</p>
<p>The recordings vary in the volume of the speaker’s voice and the amount of background noise present. An algorithm was constructed to allow for the most stringent measurement of the least modified data that gave plausible measurements. Specifically, each file was measured using the highest possible rejection rate for the VAD algorithm and no modification of the file. If the timings detected were not plausible, the timings were re-measured with the same rejection rate, but after the recording had undergone a 200Hz high-pass filter<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> (HPF). If that still failed, a 400Hz HPF was used. After a further failure, the rejection rate for the VAD was lowered, and the whole thing was tried again (0, 200Hz, 400Hz); and that process was itself repeated until the lowest possible rejection rate was tried of the four possible settings.</p>
<p>A plausible set of measurements had to meet the following criteria:</p>
<p><em>Utterance length:</em> An utterance length between 2s and 10s, where utterance timing is the longest contiguous span in the recording that VAD reports as phonation, with breaks in phonation of less than 1s not breaking contiguity (<span class="citation">Goldman-Eisler (1961)</span> found that a large majority (82.5 to 87%) of pauses in fluent speech are less than 1s). Stimuli range from 18-22 syllables in length. If we assume a speech rate of 3 to 7 syllables per second <span class="citation">(Jacewicz, Fox, &amp; Wei, 2010)</span> we would expect utterances between 2.5s and 7.3s. Conservative thresholds higher and lower than the expected were used, especially on the higher end, to allow for any difficulties processing or fluency that might have lead to longer reading times.</p>
<p><em>Minimum leading silence:</em> A leading silence (“delay”) of more than 120ms. Even a very fast human reaction time should not permit a delay shorter than 120ms, so a shorter delay likely means something went wrong with the procedure and the participant is already speaking before the sentence is displayed.</p>
<p><em>Maximum edge silence:</em> A maximum trailing and leading silence length of less than 95% of the file’s length was also used, in order to filter out recordings that do not represent a valid trial. Very long silences less than this very conservative threshold that impact the IRT are dealt with in the data clean up rather than via phonation detection, as described in the results section of this paper (section <a href="results-and-discussion.html#irtDis">4.3.1</a>.</p>
<p>With 32 participants reading 48 items (experimental and filler) twice each, there are an expected number of 3072 recordings; due to technical issues at the time of data collection, 71 recordings are missing. Of the 3001 recordings subjected to this treatment, 2976 resulted in plausible timings. For those that were successful, the breakdown of HPF and rejection rate used is reported in Table <a href="methodology.html#tab:metable">3.4</a>. A further 9 were set by hand, resulting in a total of 2985 recordings.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:metable">Table 3.4: </span>VAD rejection rate and high pass filter (HPF) values
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
No HPF
</th>
<th style="text-align:right;">
HPF at 200Hz
</th>
<th style="text-align:right;">
HPF at 400Hz
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Lowest VAD rejection rate
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
…
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
…
</td>
<td style="text-align:right;">
392
</td>
<td style="text-align:right;">
37
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Highest VAD rejection rate
</td>
<td style="text-align:right;">
1380
</td>
<td style="text-align:right;">
1159
</td>
<td style="text-align:right;">
4
</td>
</tr>
</tbody>
</table>
<div id="timing-measurement-reliability" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Timing measurement reliability</h3>
<p>Timings were collected by hand for 768 recordings (25.6% of all data). Human measured timings were within 100ms of the VAD-measured timings in <code>??</code>%<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> of cases.</p>
</div>
</div>
<div id="prosodic-judgments" class="section level2">
<h2><span class="header-section-number">3.8</span> Prosodic judgments</h2>
<p>A trained linguist informant naive to the research being conducted listened to recordings and reported the presence or absence of breaks in certain regions of the sentence, as well as several other judgments. She was instructed to familiarize herself with a speaker’s speech patterns before rating any recordings by listening to 6 filler item recordings from that speaker. She was given a diagram of the sentences as in table , as well as full plain-text lists of all items.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:reg">Table 3.5: </span>Sentence region labels
</caption>
<thead>
<tr>
<th style="text-align:left;">
SUBJ
</th>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
V
</th>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
OBJ
</th>
<th style="text-align:left;">
PP1
</th>
<th style="text-align:left;">
PP2
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
He
</td>
<td style="text-align:left;">
had
</td>
<td style="text-align:left;">
meant
</td>
<td style="text-align:left;">
to stick ||<span class="math inline">\(_{V}\)</span>
</td>
<td style="text-align:left;">
the pencil case ||<span class="math inline">\(_{OBJ}\)</span>
</td>
<td style="text-align:left;">
in the cabinet ||<span class="math inline">\(_{PP1}\)</span>
</td>
<td style="text-align:left;">
into his book bag.
</td>
</tr>
<tr>
<td style="text-align:left;">
NP<span class="math inline">\(_{SUBJ}\)</span>
</td>
<td style="text-align:left;">
AUX
</td>
<td style="text-align:left;">
V<span class="math inline">\(_1\)</span>
</td>
<td style="text-align:left;">
V<span class="math inline">\(_2\)</span>
</td>
<td style="text-align:left;">
NP<span class="math inline">\(_{OBJ}\)</span>
</td>
<td style="text-align:left;">
PP<span class="math inline">\(_1\)</span>
</td>
<td style="text-align:left;">
PP<span class="math inline">\(_2\)</span>
</td>
</tr>
</tbody>
</table>
<p>She was asked to report on whether or not she heard a prosodic boundary directly after the region labeled <strong>V</strong>, directly after the region labeled <strong>OBJ</strong>, and directly after the region labeled <strong>PP1</strong>. The following definition of prosodic break was provided:</p>
<blockquote>
<p>Please work with the assumption that “prosodic boundary” in what follows is any subset of the following features, clustered in such a way as to trigger your intuition that a new prosodic element (of any size) is beginning: pitch change, volume change, segmental lengthening, or pause.</p>
</blockquote>
<p>The judgments requested also included whether or not the speaker struggled, where that struggle began, whether or not the speaker used question intonation, and which break(s) were stronger or more prominent than which other break(s).</p>
<p>Detailed instructions on the order in which items should be listened to, both within speaker and across speakers, were also provided. The result was that she never listened to both readings of a sentence in sequence; she never listened to two reading 1 versions of different sentences in sequence; and she never listened to the sentences in the same order for a given participant as she did for the previous one.</p>
<p>Details on the instructions given and the judgments collected can be found in the appendices (<a href="RA.html#RA">E</a>.</p>
<div id="reliability" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Reliability</h3>
<p>A second trained linguist repeated the task over 128 recordings selected from 8 participants (two from each group, one per ordering). Even number experimental items were used from 4 participants, and odd numbered from the other 4. There were 8 recordings missing from the 128 selected, so the reliability task resulted in judgments over 120 recordings. The first informant also blindly re-rated those 120, with the recording name obscured and instructions not to revisit her original ratings. Reliability scores (percent of recordings agreed upon) are reported in table <a href="methodology.html#tab:validity">3.6</a>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:validity">Table 3.6: </span>Inter and intra-rater agreement with Cohen’s Kappa
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Breaks
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Break strength
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Struggle
</div>
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
V
</th>
<th style="text-align:center;">
OBJ
</th>
<th style="text-align:center;">
PP1
</th>
<th style="text-align:center;">
STRONGEST
</th>
<th style="text-align:center;">
WEAKEST
</th>
<th style="text-align:center;">
STRUGGLED
</th>
<th style="text-align:center;">
START REGION
</th>
<th style="text-align:center;">
FINAL RISE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;font-weight: bold;vertical-align: middle !important;" rowspan="3">
Inter-rater
</td>
<td style="text-align:center;">
50.0%
</td>
<td style="text-align:center;">
65.0%
</td>
<td style="text-align:center;">
78.3%
</td>
<td style="text-align:center;">
54.2%
</td>
<td style="text-align:center;">
23.3%
</td>
<td style="text-align:center;">
85.0%
</td>
<td style="text-align:center;">
80.0%
</td>
<td style="text-align:center;">
95.8%
</td>
</tr>
<tr>
<td style="text-align:center;">
K = 0.03
</td>
<td style="text-align:center;">
K = 0.17**
</td>
<td style="text-align:center;">
K = 0.09 .
</td>
<td style="text-align:center;">
K = 0.25***
</td>
<td style="text-align:center;">
K = 0.00
</td>
<td style="text-align:center;">
K = 0.43***
</td>
<td style="text-align:center;">
K = 0.27***
</td>
<td style="text-align:center;">
K = 0.90***
</td>
</tr>
<tr>
<td style="text-align:center;">
(z = 0.63)
</td>
<td style="text-align:center;">
(z = 2.61)
</td>
<td style="text-align:center;">
(z = 1.86)
</td>
<td style="text-align:center;">
(z = 3.99)
</td>
<td style="text-align:center;">
(z = 0.06)
</td>
<td style="text-align:center;">
(z = 5.23)
</td>
<td style="text-align:center;">
(z = 4.80)
</td>
<td style="text-align:center;">
(z = 9.88)
</td>
</tr>
<tr>
<td style="text-align:center;font-weight: bold;vertical-align: middle !important;" rowspan="3">
Intra-rater
</td>
<td style="text-align:center;">
94.2%
</td>
<td style="text-align:center;">
77.5%
</td>
<td style="text-align:center;">
85.0%
</td>
<td style="text-align:center;">
72.5%
</td>
<td style="text-align:center;">
61.7%
</td>
<td style="text-align:center;">
92.5%
</td>
<td style="text-align:center;">
92.5%
</td>
<td style="text-align:center;">
95.8%
</td>
</tr>
<tr>
<td style="text-align:center;">
K = 0.34***
</td>
<td style="text-align:center;">
K = 0.52***
</td>
<td style="text-align:center;">
K = 0.52***
</td>
<td style="text-align:center;">
K = 0.44***
</td>
<td style="text-align:center;">
K = 0.38***
</td>
<td style="text-align:center;">
K = 0.60***
</td>
<td style="text-align:center;">
K = 0.58***
</td>
<td style="text-align:center;">
K = 0.90***
</td>
</tr>
<tr>
<td style="text-align:center;">
(z = 4.22)
</td>
<td style="text-align:center;">
(z = 5.73)
</td>
<td style="text-align:center;">
(z = 5.82)
</td>
<td style="text-align:center;">
(z = 5.70)
</td>
<td style="text-align:center;">
(z = 6.08)
</td>
<td style="text-align:center;">
(z = 6.62)
</td>
<td style="text-align:center;">
(z = 7.57)
</td>
<td style="text-align:center;">
(z = 9.95)
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Note: </span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05, . p &lt; 0.1
</td>
</tr>
</tfoot>
</table>
<p>The lower intra-rater agreement for relative break strength was likely a result of a methodological issue: it was possible to report the same pattern, e.g. a pattern where a PP1 break is stronger than an OBJ break, by either giving the response “PP1” for strongest break, and “OBJ” for weakest break; or, “PP1” for strongest and “NONE” for weakest; or, “NONE” for strongest and “OBJ” for weakest. While the instructions to the rater requested full verbosity, it’s likely that inconsistencies occurred for these cases.</p>
<p>The same inconsistencies would have hurt inter-rater agreement for strongest/weakest also. A further contributing issue for inter-rater agreement of those two judgments stems from the poor agreement on the presence of the verb break. When the raters do not agree about the presence of a break, that disagreement is magnified for the judgement of the relative strength of breaks.</p>

<pre><code>## Registering fonts with R</code></pre>
<pre><code>## 
## Attaching package: &#39;psych&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<pre><code>## Arial Black already registered with pdfFonts().</code></pre>
<pre><code>## Arial already registered with pdfFonts().</code></pre>
<pre><code>## Bahnschrift already registered with pdfFonts().</code></pre>
<pre><code>## Calibri already registered with pdfFonts().</code></pre>
<pre><code>## Calibri Light already registered with pdfFonts().</code></pre>
<pre><code>## No regular (non-bold, non-italic) version of Cambria. Skipping setup for this font.</code></pre>
<pre><code>## Candara already registered with pdfFonts().</code></pre>
<pre><code>## Comic Sans MS already registered with pdfFonts().</code></pre>
<pre><code>## Consolas already registered with pdfFonts().</code></pre>
<pre><code>## Constantia already registered with pdfFonts().</code></pre>
<pre><code>## Corbel already registered with pdfFonts().</code></pre>
<pre><code>## Courier New already registered with pdfFonts().</code></pre>
<pre><code>## Digital-7 Mono already registered with pdfFonts().</code></pre>
<pre><code>## Ebrima already registered with pdfFonts().</code></pre>
<pre><code>## Franklin Gothic Medium already registered with pdfFonts().</code></pre>
<pre><code>## Gabriola already registered with pdfFonts().</code></pre>
<pre><code>## Gadugi already registered with pdfFonts().</code></pre>
<pre><code>## Georgia already registered with pdfFonts().</code></pre>
<pre><code>## HoloLens MDL2 Assets already registered with pdfFonts().</code></pre>
<pre><code>## Impact already registered with pdfFonts().</code></pre>
<pre><code>## Ink Free already registered with pdfFonts().</code></pre>
<pre><code>## Javanese Text already registered with pdfFonts().</code></pre>
<pre><code>## Leelawadee UI already registered with pdfFonts().</code></pre>
<pre><code>## Leelawadee UI Semilight already registered with pdfFonts().</code></pre>
<pre><code>## Lucida Console already registered with pdfFonts().</code></pre>
<pre><code>## Lucida Sans Unicode already registered with pdfFonts().</code></pre>
<pre><code>## Malgun Gothic already registered with pdfFonts().</code></pre>
<pre><code>## Malgun Gothic Semilight already registered with pdfFonts().</code></pre>
<pre><code>## Marlett already registered with pdfFonts().</code></pre>
<pre><code>## Microsoft Himalaya already registered with pdfFonts().</code></pre>
<pre><code>## Microsoft Yi Baiti already registered with pdfFonts().</code></pre>
<pre><code>## Microsoft New Tai Lue already registered with pdfFonts().</code></pre>
<pre><code>## Microsoft PhagsPa already registered with pdfFonts().</code></pre>
<pre><code>## Microsoft Sans Serif already registered with pdfFonts().</code></pre>
<pre><code>## Microsoft Tai Le already registered with pdfFonts().</code></pre>
<pre><code>## Mongolian Baiti already registered with pdfFonts().</code></pre>
<pre><code>## MV Boli already registered with pdfFonts().</code></pre>
<pre><code>## Myanmar Text already registered with pdfFonts().</code></pre>
<pre><code>## Nirmala UI already registered with pdfFonts().</code></pre>
<pre><code>## Nirmala UI Semilight already registered with pdfFonts().</code></pre>
<pre><code>## Palatino Linotype already registered with pdfFonts().</code></pre>
<pre><code>## Segoe MDL2 Assets already registered with pdfFonts().</code></pre>
<pre><code>## Segoe Print already registered with pdfFonts().</code></pre>
<pre><code>## Segoe Script already registered with pdfFonts().</code></pre>
<pre><code>## Segoe UI already registered with pdfFonts().</code></pre>
<pre><code>## Segoe UI Light already registered with pdfFonts().</code></pre>
<pre><code>## Segoe UI Semibold already registered with pdfFonts().</code></pre>
<pre><code>## Segoe UI Semilight already registered with pdfFonts().</code></pre>
<pre><code>## Segoe UI Black already registered with pdfFonts().</code></pre>
<pre><code>## Segoe UI Emoji already registered with pdfFonts().</code></pre>
<pre><code>## Segoe UI Historic already registered with pdfFonts().</code></pre>
<pre><code>## Segoe UI Symbol already registered with pdfFonts().</code></pre>
<pre><code>## SimSun-ExtB already registered with pdfFonts().</code></pre>
<pre><code>## Sylfaen already registered with pdfFonts().</code></pre>
<pre><code>## Symbol already registered with pdfFonts().</code></pre>
<pre><code>## Tahoma already registered with pdfFonts().</code></pre>
<pre><code>## Times New Roman already registered with pdfFonts().</code></pre>
<pre><code>## Trebuchet MS already registered with pdfFonts().</code></pre>
<pre><code>## Verdana already registered with pdfFonts().</code></pre>
<pre><code>## Webdings already registered with pdfFonts().</code></pre>
<pre><code>## Wingdings already registered with pdfFonts().</code></pre>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Instructions were also provided verbally and via printout. Details on the instructions are available in the appendices.<a href="methodology.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Thank you to Dr. Dianne Bradley for making this observation, and for the very clever “prosecutorial” descriptor.<a href="methodology.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Google’s VAD API only accepts WAV files with sample rates that are a multiple of 8kHz. It ultimately down-samples all files to 8kHz, regardless of the input rate.<a href="methodology.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>The exact algorithm is available on <a href="https://gist.github.com/moui72/4ebc4eb8f69eb9fdb1cab160ce299675">github</a> (URL: <a href="https://bit.ly/2uMrcrG">bit.ly/2uMrcrG</a>)<a href="methodology.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>NOTE: Hand measurement is not yet completed.<a href="methodology.html#fnref6" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="background.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="results-and-discussion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
