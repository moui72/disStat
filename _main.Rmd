---
title: "Summary"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  pdf_document: default
  html_document:
    highlight: tango
    theme: journal
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)

got_prosody <- read_csv("dissertation/csvs/got_prosody.csv")

mdata <- read_csv("dissertation/csvs/got_prosody.csv")
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$goodProsody <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")

inter_item_timings_all <- read_csv("dissertation/csvs/inter_item_timings.csv", 
    col_types = cols(item = col_character(), 
        participant = col_character()))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading <0] <- NA
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings <- subset(inter_item_timings_all, Exp & participant != "108")

gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```

# 3-level prosodic pattern
```{r 3lvlxtabs}
prosodies.full <- xtabs(~ prosody + Condition_Q + Condition_GP, mdata)
prosodies.r1 <- xtabs(~ prosody + Condition_Q + Condition_GP, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ prosody + Condition_Q + Condition_GP, subset(mdata,Reading==2))
pander(prosodies.full, caption = "both readings")
pander(prosodies.r1, caption = "reading 1")
pander(prosodies.r2, caption = "reading 2")
```

# 2-level prosodic pattern
```{r 2lvlxtabs}
prosodies.full <- xtabs(~ two_level_prosody + Condition_Q + Condition_GP, mdata)
prosodies.r1 <- xtabs(~ two_level_prosody + Condition_Q + Condition_GP, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ two_level_prosody + Condition_Q + Condition_GP, subset(mdata,Reading==2))
pander(prosodies.full)
pander(prosodies.r1, caption = "reading 1")
pander(prosodies.r2, caption = "reading 2")
```


# Timing models (ME Linear Regression)
```{r lmerModel,echo=FALSE}
if(!exists("models.timing")){
  models.timing <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(!exists("models.timingNoInt")){
  models.timingNoInt <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}

if(!exists("models.timing.Sense")){
  models.timing.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(!exists("models.timingNoInt.Sense")){
  models.timingNoInt.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
```
```{r assumptionChecks}
inter_item_timings$resids_main[!is.na(inter_item_timings$inter_reading)] <- residuals(models.timing)
inter_item_timings$resids_main.abs <- abs(inter_item_timings$resids_main)
inter_item_timings$resids_main.sq <-inter_item_timings$resids_main.abs^2
sensitive_timings <- subset(inter_item_timings, !(participant %in% gpInsensitive))

timings_sq_resid <- lm(inter_item_timings$resids_main.sq ~ inter_item_timings$participant, data=inter_item_timings) #ANOVA of the squared residuals
sens_timings_sq_resid <- lm(resids_main.sq ~ participant, data=sensitive_timings) #ANOVA of the squared residuals
```
# Homogeneity of variance
Anova of squared residuals ~ participant for full data and "GP-sensitive" subset
```{r homovar}
anova(timings_sq_resid) #displays the results
anova(sens_timings_sq_resid) #displays the results
```
# Normal distribution of residuals
All participants
`r qqmath(models.timing, id=0.05)`
Only GP-sensitive participants
`r qqmath(models.timing.Sense, id=0.05)`
```
# Models
## Full model
```{r full}
summary(models.timing)
```
## Without interacton term
```{r noInt}
summary(models.timingNoInt)
```
## Only "gp-sensitive"
The following excludes all participants whose mean inter-item reading time for `+GP` items is less than for `-GP` items
### With interaction
```{r gpSense}
summary(models.timing.Sense)
```
## Without interaction
```{r gpSenseNoInt}
summary(models.timingNoInt.Sense)

```
# Logit models
```{r logitModels}
# models.full <- glmer(PP1~V*OBJ+Condition_Q*Condition_GP+Reading + (1+V*OBJ+Condition_Q*Condition_GP+Reading | SID) + (1+V*OBJ+Condition_Q*Condition_GP+Reading | IID),data=mdata,family = binomial, control = glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=2e8)))
# summary(models.full)
if(!exists("models.goodP")){
  models.goodP <- glmer(goodProsody~Condition_Q*Condition_GP*Reading + (1+Condition_Q*Condition_GP*Reading | SID) + (1+Condition_Q*Condition_GP*Reading | IID),data=mdata,family = binomial, control = glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=2e8)))
}
summary(models.goodP)
```

<!--chapter:end:all.Rmd-->

---
title: "Binomial models"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    highlight: pygments
    number_sections: yes
    theme: journal
    toc: yes
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(lme4)
library(lmerTest)

refresh = FALSE # set to true to re-run models
order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))
gpInsensitive <- paste(c(1,12,14,15,19,2,20,203,21,210,22,4,6))

morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)

getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

mdata <- read_csv("csvs/got_prosody.csv")

mdata$Sorder <- 2
mdata$Sorder[mdata$SID %in% order1] <- 1
mdata$Iorder <- getIOrd(mdata$IID,mdata$Sorder)

mdata<-subset(mdata,!is.na(PP1) & !is.na(two_level_prosody))
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$lowAttach <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$IID[mdata$IID == 108] <- 8
mdata$LQI <- mdata$QI == "YES"
mdata$HtOrMs_QI <- mdata$LQI == mdata$Condition_Q

mdata$condition <- paste(ifelse(mdata$Condition_GP, "+GP", "-GP")," ",ifelse(mdata$Condition_Q, "+Q", "-Q"))




```

# Logit models

```{r pp1logit}
# model failse to converge
# if(F & !exists("models.logi.attach.full") | refresh){
#   models.logi.pp1.full <- glmer(
#     PP1~OBJ + Condition_Q * Condition_GP + Reading + 
#       (OBJ+Condition_Q*Condition_GP+Reading | SID) + 
#       (OBJ+Condition_Q*Condition_GP+Reading | IID),
#     family = binomial, 
#     data = mdata,
#     control = glmerControl(optimizer = "bobyqa",
#                            optCtrl=list(maxfun=2e8)),
#     verbose = 2
#   )
# }
```
```{r attachment,echo=FALSE}
if(!exists("models.logi.attach.full.wD") | refresh){
  models.logi.attach.full.wD <- glmer(
    lowAttach~Condition_Q*Condition_GP*Reading + 
      (1+Condition_Q*Condition_GP*Reading | SID) + 
      (1+Condition_Q*Condition_GP*Reading | IID),
    data = mdata,
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```
```{r attachment_noRint}
if(!exists("models.logi.attach.noRint") | refresh){
  models.logi.attach.noRint <- glmer(
    lowAttach~Condition_Q*Condition_GP+Reading + 
      (1+Condition_Q*Condition_GP+Reading | SID) + 
      (1+Condition_Q*Condition_GP+Reading | IID),
    data = mdata,
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```
```{r attachment_noR}
if(!exists("models.logi.attach.noR") | refresh){
  models.logi.attach.noR <- glmer(
    lowAttach~Condition_Q*Condition_GP + 
      (1+Condition_Q*Condition_GP | SID) + 
      (1+Condition_Q*Condition_GP | IID),
    data = mdata,
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```
```{r attachment_noR_r2}
if(!exists("models.logi.attach.noR.r2") | refresh){
  models.logi.attach.noR.r2 <- glmer(
    lowAttach~Condition_Q*Condition_GP + 
      (1+Condition_Q*Condition_GP | SID) + 
      (1+Condition_Q*Condition_GP | IID),
    data = subset(mdata, Reading == 2),
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```


## Predicting PP1 as strongest or only break

Is PP1 being the strongest or only break predicted by condition * reading?

# Full model

```{r summarizeAttach}
summary(models.logi.attach.full.wD)
```

# Model with no interaction of reading
Simplified model and comparison to full model

```{r sumNoRInt}
summary(models.logi.attach.noRint)
anova(models.logi.attach.full.wD,models.logi.attach.noRint)
```

# Model with no fixed effect of reading

Simplified model and comparison to full model

```{r sumNoR}
summary(models.logi.attach.noR)
anova(models.logi.attach.full.wD,models.logi.attach.noR)
```

# Model with just reading 2

Simplified model and comparison to full model

```{r sumR2}
summary(models.logi.attach.noR.r2)
#anova(models.logi.attach.full.wD,models.logi.attach.noR.r2)
```

<!--chapter:end:bin.Rmd-->

---
title: "Binomial models"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    highlight: pygments
    number_sections: yes
    theme: journal
    toc: yes
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(lme4)
library(lmerTest)
library(glue)
excl <- c(5,11)
refresh = FALSE # set to true to re-run models
order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))
gpInsensitive <- paste(c(1,12,14,15,19,2,20,203,21,210,22,4,6))

morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)

getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

mdata <- read_csv("csvs/got_prosody.csv")
fmdata<-mdata
mdata<-subset(mdata,!SID %in% excl)
mdata$SID <- as.factor(mdata$SID)
mdata$Sorder <- 2
mdata$Sorder[mdata$SID %in% order1] <- 1
mdata$Iorder <- getIOrd(mdata$IID,mdata$Sorder)

mdata<-subset(mdata,!is.na(PP1) & !is.na(two_level_prosody))
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$lowAttach <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$IID[mdata$IID == 108] <- 8
mdata$LQI <- mdata$QI == "YES"
mdata$HtOrMs_QI <- mdata$LQI == mdata$Condition_Q

mdata$condition <- paste(ifelse(mdata$Condition_GP, "+GP", "-GP")," ",ifelse(mdata$Condition_Q, "+Q", "-Q"))

mdata$flat_2lp <- trim(paste(ifelse(mdata$PP1, "+PP1", "-PP1"),ifelse(mdata$OBJ,"+OBJ","-OBJ")))

```
# crosstab
```{r xt}

# PP1
kable(xtabs(~PP1+condition,data=mdata),caption="PP1 break by condition")%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:2,color="#444444")

kable(xtabs(~PP1+Condition_Q,data=mdata),caption="PP1 break by Q",col.names = c("+Q","-Q"))%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:2,color="#444444")

kable(xtabs(~PP1+Condition_GP,data=mdata),caption="PP1 break by GP",col.names = c("+GP","-GP"))%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:2,color="#444444")


# OBJ
kable(xtabs(~OBJ+Condition_Q,data=mdata),caption="OBJ break by Q",col.names = c("+Q","-Q"))%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:2,color="#444444")
kable(xtabs(~OBJ+Condition_GP,data=mdata),caption="OBJ break by GP",col.names = c("+GP","-GP"))%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:2,color="#444444")

kable(xtabs(~OBJ+condition,data=mdata),caption="OBJ break by condition")%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:2,color="#444444")

kable(xtabs(~flat_2lp + Condition_Q, data=mdata), caption="PP1+OBJ by Q",col.names = c("+Q","-Q"))%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:3,color="#444444")

kable(xtabs(~flat_2lp + Condition_GP, data=mdata),col.names = c("+GP","-GP"), caption="PP1+OBJ by GP")%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:3,color="#444444")

kable(xtabs(~flat_2lp+condition,data=mdata), caption="PP1+OBJ by condition")%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) %>%
  row_spec(1:3,color="#444444")

```

# Logit models

## Both readings

```{r pp1SimpleBothR}
lrm.PP1.simple <- glmer(
  PP1 ~ Reading + Condition_GP * Condition_Q + (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)
lrm.PP1.simple.noR <- glmer(
  PP1 ~ Condition_GP * Condition_Q + 
    (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)
anova(lrm.PP1.simple.noR,lrm.PP1.simple)
lrm.PP1.simple.noInt <- glmer(
  PP1 ~ Condition_GP + Condition_Q + 
    (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)
anova(lrm.PP1.simple,lrm.PP1.simple.noInt)
anova(lrm.PP1.simple.noR,lrm.PP1.simple.noInt)
lrm.PP1.simple.noQ <- glmer(
  PP1 ~ Condition_GP + 
    (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)
anova(lrm.PP1.simple.noInt,lrm.PP1.simple.noQ)
lrm.PP1.simple.noGP <- glmer(
  PP1 ~ Condition_Q + 
    (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)
anova(lrm.PP1.simple.noInt,lrm.PP1.simple.noGP)

anova(lrm.PP1.simple.noInt,lrm.PP1.simple.noQ)
lrm.PP1.null <- glmer(
  PP1 ~ 1 + 
    (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial,
  control=glmerControl(optimizer = "bobyqa"),
  REML=F
)
anova(lrm.PP1.simple.noInt,lrm.PP1.simple.noGP)


```
# reading 1

```{r pp1simpleR1}
# ---- these fail to converge -----
# lrm.PP1.full.r1 <- glmer(
#   PP1 ~ Condition_GP * 
#     Condition_Q + 
#     (1 + Condition_GP * Condition_Q| SID) +
#     (1 +Condition_GP * Condition_Q| IID),
#   data=subset(mdata,Reading==1),
#   family=binomial
# )

# lrm.PP1.simple.r1 <- glmer(
#   PP1 ~ Condition_GP * Condition_Q + 
#     (1 + Condition_GP + Condition_Q| SID) + 
#     (1 +Condition_GP + Condition_Q| IID),
#   data=subset(mdata,Reading==1),
#   family=binomial
# )
# ---------------------------------
lrm.PP1.simplest.r1 <- glmer(
  PP1 ~ Condition_GP * Condition_Q + (1 | SID) + (1 | IID),
  data=subset(mdata,Reading==1),
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)
lrm.PP1.simplest.r1.noInt <- glmer(
  PP1 ~ Condition_GP + Condition_Q + (1 | SID) + (1 | IID),
  data=subset(mdata,Reading==1),
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)
anova(lrm.PP1.simplest.r1,lrm.PP1.simplest.r1.noInt)
```

# reading 2

```{r pp1simpleR2}

lrm.PP1.simplest.r2 <- glmer(
  PP1 ~ Condition_GP * Condition_Q + (1 | SID) + (1 | IID),
  data=subset(mdata,Reading==2),
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)


lrm.PP1.simplest.r2.noInt <- glmer(
  PP1 ~ Condition_GP + Condition_Q + (1 | SID) + (1 | IID),
  data=subset(mdata,Reading==2),
  family=binomial,
  control=glmerControl(optimizer = "bobyqa")
)
anova(lrm.PP1.simplest.r2,lrm.PP1.simplest.r2.noInt)
```
# OBJ

```{r objSimple}
lrm.OBJ.simple <- glmer(
  OBJ ~ Reading +  Condition_GP * Condition_Q + (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial
)
lrm.OBJ.simple.noR <- glmer(
  OBJ ~ Condition_GP * Condition_Q + (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial
)
lrm.OBJ.simple.noInt <- glmer(
  OBJ ~ Condition_GP + Condition_Q + (1 | SID) + (1 | IID),
  data=mdata,
  family=binomial
)
anova(lrm.OBJ.simple, lrm.OBJ.simple.noR)
anova(lrm.OBJ.simple.noInt, lrm.OBJ.simple.noR)
```
```{r objR1}
lrm.OBJ.simple.r1 <- glmer(
  OBJ ~ Condition_GP * Condition_Q + (1 | SID) + (1 | IID),
  data=subset(mdata,Reading==1),
  family=binomial
)
```
```{r objR2}
lrm.OBJ.simple.r2 <- glmer(
  OBJ ~  Condition_GP * Condition_Q + (1 | SID) + (1 | IID),
  data=subset(mdata,Reading==2),
  family=binomial
)
```
```{r qi, include=F}
# lrm.QI.simple <- glmer(
#   HtOrMs_QI~Reading + Condition_GP * Condition_Q + (1 | SID) + (1 | IID), 
#   data=mdata,
#   family=binomial
# )
lrm.QI.simple.r1 <- glmer(
  HtOrMs_QI~ Condition_GP * Condition_Q + PP1+OBJ + (1 | SID) + (1 | IID), 
  data=subset(mdata,Reading==1),
  family=binomial
)

```

```{r strug, include=F}
lrm.STRUG.simple <- glmer(
  STRUG ~ Condition_GP * Condition_Q + Reading + (1 | SID) + (1 | IID), 
  data=mdata,
  family=binomial
)
lrm.STRUG.simple.r1 <- glmer(
  STRUG ~ Condition_GP * Condition_Q + (1 | SID) + (1 | IID), 
  data=subset(mdata,Reading==1),
  family=binomial
)

```

<!--chapter:end:bin2.Rmd-->

---
title: "Binomial models"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(lme4)
library(lmerTest)


refresh = FALSE # set to true to re-run models
order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))
gpInsensitive <- paste(c(1,12,14,15,19,2,20,203,21,210,22,4,6))
morder<-paste(c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,1,16))
sorder<-paste(c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2))

mdata <- read_csv("csvs/got_prosody.csv")
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$lowAttach <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$IID[mdata$IID == 108] <- 8
mdata$LQI <- mdata$QI == "YES"
mdata$HtOrMs_QI <- mdata$LQI == mdata$Condition_Q
mdata$Sorder <- 2
mdata$Sorder[mdata$SID %in% order1] <- 1
mdata$condition <- paste(ifelse(mdata$Condition_GP, "+GP", "-GP")," ",ifelse(mdata$Condition_Q, "+Q", "-Q"))
mdata$Iorder <- ifelse(mdata$Sorder==1,match(mdata$SID,morder),match(mdata$SID,sorder))

```

# Crosstabs

## Struggle 

Note that struggle does not show good cross-rater reliability

```{r strug}
label = "struggle:"
f <- ~STRUG + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption = paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## V break

Note that V break does not show good cross-rater reliability

```{r v}
label = "pp1 break:"
f <- ~V + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption = paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## PP1 break

```{r pp1}
label = "pp1 break:"
f <- ~PP1 + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption = paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## OBJ break

```{obj}
label <- "obj:"
f <- ~OBJ + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption =paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## Question intonation hit/miss

```{r qihit}
label <- "QI hit:"
f <- ~HtOrMs_QI + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption = paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

# 3-level prosodic pattern
```{r 3lvlxtabs}
f <- ~ prosody + condition
prosodies.full <- xtabs(f, mdata)
prosodies.r1 <- xtabs(f, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(f, subset(mdata,Reading==2))
kable(prosodies.full, caption = "both readings") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(prosodies.r1, caption = "reading 1") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(prosodies.r2, caption = "reading 2") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

# 2-level prosodic pattern
```{r 2lvlxtabs}
form <- ~ condition+ two_level_prosody
prosodies.full <- xtabs(form, mdata)
prosodies.r1 <- xtabs(form, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(form, subset(mdata,Reading==2))
kable(prosodies.full) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(prosodies.r1, caption = "reading 1") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(prosodies.r2, caption = "reading 2") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) 
```

# Logit models

```{r pp1logit}

models.logi.pp1.full <- glmer(
  PP1~Condition_Q * Condition_GP * Reading + 
    (Condition_Q*Condition_GP+Reading | SID) + 
    (Condition_Q*Condition_GP+Reading | IID),
  family = binomial, 
  data = mdata,
  control = glmerControl(optimizer = "bobyqa",
                         optCtrl=list(maxfun=2e8)),
  verbose = 2
)

if(!exists("models.logi.attach.full") | refresh){
  models.logi.pp1.full <- glmer(
    PP1~OBJ + Condition_Q * Condition_GP + Reading + 
      (OBJ+Condition_Q*Condition_GP+Reading | SID) + 
      (OBJ+Condition_Q*Condition_GP+Reading | IID),
    family = binomial, 
    data = mdata,
    control = glmerControl(optimizer = "bobyqa",
                           optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}

```
```{r attachment}
if(!exists("models.logi.attach.full") | refresh){
  models.logi.attach.full <- glmer(
    lowAttach~Condition_Q*Condition_GP+Reading + 
      (1+Condition_Q*Condition_GP+Reading | SID) + 
      (1+Condition_Q*Condition_GP+Reading | IID),
    data = mdata,
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", calc.derivs=F, optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```

## Predicting PP1

Is the existence of PP1 break predicted by condition * reading?

```{r summarizePP1}
summary(models.logi.pp1.full)
```

## Predicting PP1 as strongest or only break

Is PP1 being the strongest or only break predicted by condition * reading?

```{r summarizeAttach}
summary(models.logi.attach.full)
```

<!--chapter:end:binary-and-categorical.Rmd-->

---
title: "Working results"
author: "Tyler Peckenpaugh"
date: "4/3/2019"
output:
  tufte::tufte_handout: 
    toc: True  
    latex_engine: xelatex
  tufte::tufte_html: 
    tufte_features: ["fonts", "italics"]
---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3)
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lattice)
library(psych)
library(geepack)
library(tidyr)
library(dplyr)
library(ggplot2)
library(stargazer)

getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

# load file, set columns
inter_item_timings_new <- read_csv("csvs/irt-rvad-all-48k-2019-04-03_17h03m24s.csv")
inter_item_timings_new$GP_condition <- inter_item_timings_new$Condition_GP
inter_item_timings_new$Q_condition <- inter_item_timings_new$Condition_Q
inter_item_timings_new$Condition_Q <- NULL
inter_item_timings_new$Condition_GP <- NULL

# remove 0 irts
zeros<-subset(inter_item_timings_new,irt==0)
inter_item_timings_new<-subset(inter_item_timings_new,irt>0)

# generate condition column for ease of display
inter_item_timings_new$condition <- paste(
  ifelse(inter_item_timings_new$Q_condition,"+Q","-Q"),
  ifelse(
    inter_item_timings_new$isFiller,
    ifelse(inter_item_timings_new$GP_condition,"+PP","-PP"),
    ifelse(inter_item_timings_new$GP_condition,"+GP","-GP")
  )
)

# make lowercase columns
inter_item_timings_new$participant <- as.factor(inter_item_timings_new$Participant)
inter_item_timings_new$item <- as.factor(inter_item_timings_new$Item)

# basic outlier removal
descrip <- describe(inter_item_timings_new$irt)
gmean <- round(descrip$mean,2)
gsd <- round(descrip$sd,2)
QS<-quantile(inter_item_timings_new$irt,c(.02,.05,.1,.9,.95,.98))
cutoff=5
gmax <- QS[paste(100-cutoff,"%",sep="")]
gmin <- QS[paste(cutoff,"%",sep="")]
numOver <- nrow(inter_item_timings_new[inter_item_timings_new$irt > gmax,])
numUnder <- nrow(inter_item_timings_new[inter_item_timings_new$irt < gmin,])

data <- droplevels(subset(
  inter_item_timings_new, 
  !isFiller==T & irt > gmin & irt < gmax
))

# get only experimental items
allparts <- droplevels(subset(inter_item_timings_new, !isFiller==T))

# OR winsorize all irt by participant?
data<-transform(
  data,
  winsrdIRT = ave(irt,participant,FUN=winsor)
)

# for Martin...
# write_csv2(data,"csvs/irt-working.csv")

# preserve data before attrition
irt_no_excl <-data

# attritionize prep
expdata <- subset(data, !isFiller)
mitable <- aggregate(irt ~ condition + item, data=na.omit(expdata), mean)
sbjmean <- aggregate(irt ~ participant, data=na.omit(expdata), mean)
maxmiss = 3
misstab<-with(expdata, table(participant))
exclude_miss<-names(misstab[misstab<16-maxmiss])
exclude_mean<-sbjmean[sbjmean$irt<2400|sbjmean$irt>10000,]$participant
exclude_items<-mitable[mitable$`-Q -GP` > 7000,]$item
exclude<-append(exclude_miss,exclude_mean)
# attritionize do
irt_data <- droplevels(subset(
  expdata, 
  !participant %in% exclude
))

irt_data_itemsExcluded <- droplevels(subset(
  irt_data, 
  !item %in% exclude_items
))

# name swap!
inter_item_timings <- irt_data
inter_item_timings$inter_reading <- inter_item_timings$winsrdIRT
# transform!
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading)

# set order/group vals
order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))
morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)
inter_item_timings$Sorder <- 2
inter_item_timings$Sorder[inter_item_timings$Participant %in% order1] <- 1
inter_item_timings$Iorder <- getIOrd(
  inter_item_timings$item,inter_item_timings$Sorder
)
inter_item_timings$Sorder <- as.factor(inter_item_timings$Sorder)
inter_item_timings$list <- inter_item_timings$Participant %% 4
inter_item_timings$grp <- paste(
  inter_item_timings$Sorder,
  inter_item_timings$list,
  sep="-"
)
```

# Inter-item timing

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. Inter-reading time (IRT) is a measure of the amount of time between when a subject stops speaking after a cold reading and when they begin speaking for a previewed reading. 

> IRT = delay after the end of a cold reading and before the start of a previewed reading

Practically, this was done over `r nrow(inter_item_timings_new)` recordings (33 participants, 48 items = `r 33 * 48` pairs, with `r  33 * 48 - nrow(inter_item_timings_new)` missing data). This was measured using Google's WebRTC Voice Activity Detection (VAD) over .wav files that had been subjected to a high-pass filter with a low threshold of 0 to 500Hz[^hum] using the highest aggressiveness that yielded good results, depending on the noise level in the recording.

[^hum]: a low hum in the room needed to be accounted for; the exact algorithm is available at [github](https://gist.github.com/moui72/4ebc4eb8f69eb9fdb1cab160ce299675) (URL: bit.ly/2uMrcrG)

## Description and cleanup

The following section details the IRT data and the outlier removal and resulting participant attrition. 

## Distribution of IRTs, all participants

The overal mean IRT for all participants, all items (including fillers), and all conditions is `r gmean`ms (sd = `r gsd`). The highest IRT was `r paste(round(descrip$max,2))`ms.

The following histograms show the distribution of IRT across all items and all participants. In the second graph, overly short IRTs (shorter than `r gmin`ms; `r numUnder`[^lo] such data) are excluded. In the third, overly long (longer than `r paste(gmax)`; `r numOver` such data) and overly short IRTs are excluded.

The third graph represent what I will call data that has undergone "basic outlier removal."

[^lo]: This is `r cutoff`% of the `r nrow(inter_item_timings_new)` total data

```{r allhist}
allparts <- inter_item_timings_new
hist(na.omit(allparts$irt), breaks=16,xlab="Raw IRT",main="Raw IRT, all Parts")
```
```{r nolowhist}
hist(
  subset(allparts, irt > gmin)$irt, 
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short excluded"
)
```
```{r nolownohighhist}
hist(
  subset(allparts, irt > gmin & irt < gmax)$irt,
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short and long excluded"
)
```

IRTs were finally winsorized to lessen the impact of outliers.

> A question for DCB: should the IRTs be winsorized by a participant's mean/sd for all items (including fillers), or only by experimental item mean/sd? I assume the former in this document. Should this be done before or after basic outlier removal? I assume after in this document.

```{r winshist}
hist(
  data$winsrdIRT,
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short and long excluded"
)
```

## Missing data and attrition

Due to noise in recordings and/or technical difficulties during data collection, a number of IRTs are missing for experimental items in the data. The following table shows which participants are missing how many IRTs; ideally each would have 48 IRTs and 16 experimental IRTs.

```{r missingData}
kable(
  caption="Missing data, by participant",
  align="r",
  cbind(
    with(inter_item_timings_new, 48-table(participant)),
    with(
      inter_item_timings_new, 
      paste(round(100 * (table(participant)/48),2),"%",sep="")
    ),
    with(irt_no_excl, 16-table(participant)),
    with(irt_no_excl, paste(100 * (table(participant)/16),"%",sep=""))
  ), 
  col.names = c(
    "Missing IRTs", "Available % of IRTs", 
    "Missing experimental IRTs", 
    "Available % of experimental IRTs"
  )
)
np <- nrow(levels(inter_item_timings$Participant))
```

The `r length(exclude)` participants missing more than `r maxmiss` experimental IRTs (`r exclude_miss`) are excluded.

Subjects with overall mean IRTs that are very short (< 2200) or very long (> 10000) are also excluded (`r setdiff(exclude_mean,exclude_miss)`)

## Group sizes after attrition

The following table[^g1] shows how the participants are distributed across groupsafter attrition. Ideally, there would be 4 per group-order cell, but because of attrition the cells are uneven. Because regression is able to account for uneven groups, this defect will hopefully not play an important role in the analyses that follow.

[^g1]: There are 5 particpiants in Group 1, Split BA because I ran four participants per group-order, and then one extra who happened to be assigned to group 1, split BA; and by happenstance, none of the participants from that cell needed to be excluded.

```{r groupses}
groupses<-addmargins(with(inter_item_timings[!duplicated(inter_item_timings$Participant),],table(list,Sorder)))
row.names(groupses) <- c(paste("Group",1:4),"Split Total")
kable(groupses, caption="Group/order totals after attrition", 
  col.names = c("Split AB","Split BA","Group Total"))
```

## Distribution of experimental item IRT after attrition

The following histograms show the distribution of experimental item IRTs after attrition, and then the Winsorized IRTs, and finally the common log of winsorized IRTs, which are the shape of the data most suited to regression analyses.

```{r attritionhists}

hist(inter_item_timings$irt, breaks=8,xlab="raw IRT",main="Raw IRT")

hist(inter_item_timings$inter_reading, breaks=8,xlab="IRT",main="Winsorized IRT")

hist(inter_item_timings$inter_reading.log10, breaks=8,xlab="log10 IRT",main="Common log of winsorized IRT")
```

## Mean and SD of winsorized IRT by condition

If we assume that interrogative PP-attachment garden paths are easier to process as an interrogative than in the declarative, and that IRT represents how difficult a sentence is to process, we would expect the difference in mean IRT to be larger for declarative garden paths compared to declarative controls than for the same comparison of interrogatives.
```{r sdtable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

sdtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, sd))

ctable <- rbind(mtable,sdtable)
row.names(ctable) <- c("Mean", "SD")
decl <- round(mtable["-Q +GP"] - mtable["-Q -GP"],2)
int <- round(mtable["+Q +GP"] - mtable["+Q -GP"],2)
diffGPQ <- decl - int
```
```{r sdtableOut}
kable(t(ctable), caption="Condition means")
```

The means of the Winsorized IRT by condition indeed show this pattern.

```{r interactionPlot, fig.cap="Mean experimental IRT by condition"}
groupedMeans<-inter_item_timings %>%
  group_by(GP_condition,Q_condition) %>%
  summarise(mean(irt))
groupedMeans$GP_condition <- ifelse(
  groupedMeans$GP_condition, "Garden path", "Non-garden path"
)
groupedMeans$Q_condition <- ifelse(
  groupedMeans$Q_condition, "Interrogative", "Declarative"
)
ggplot(
  groupedMeans, 
  aes(x=GP_condition,y=`mean(irt)`,group=Q_condition,linetype=Q_condition)
) + ylim(4000,6000) +
  geom_line() +
  geom_point(stat="identity") +
  theme_classic(base_family = "Palatino",base_size = 12) + 
  theme(
    axis.title=element_text(size = "14",face="bold"),
    legend.title =element_text(size = "14",face="bold")
  ) +
  labs(x="", y="Mean IRT",linetype="Interrogative")

```
The difference in mean IRT acriss &plusmn; for declaratives is `r decl`; for interrogatives, it's `r int`. This is a difference of `r diffGPQ`, representing the impact of &plusmn;GP for +Q compared to -Q. This supports the hypothesis that garden paths are easier to comprehend when presented as interrogative. It is strange that the garden-path interrogatives appear to be comprehended more quickly than the non-garden path interrogatives. A possible explanation will be explored in the discussion section.

## Item and subject variation

There is variation across participants in terms of whether or not they show this pattern.

```{r meantable, echo=FALSE}
mstable <- aggregate(inter_reading ~ condition + participant, data=inter_item_timings, mean)
mitable <- aggregate(inter_reading ~ condition + item, data=na.omit(inter_item_timings), mean)

mitable<-spread(mitable, key=condition, value=inter_reading, fill = NA, convert = FALSE)
mstable<-spread(mstable, key=condition, value=inter_reading, fill = NA, convert = FALSE)

mstable$pattern <- mstable$`-Q +GP` - mstable$`-Q -GP` > mstable$`+Q -GP` - mstable$`+Q -GP` 
mitable$pattern <- mitable$`-Q +GP` - mitable$`-Q -GP` > mitable$`+Q -GP` - mitable$`+Q -GP`

binP <- binom.test(table(mstable$pattern)["TRUE"],nrow(mstable),alternative="less")
binI <- binom.test(table(mitable$pattern)["TRUE"],nrow(mitable),alternative="less")

```


## Number of participants who show predicted pattern

In the analyzed data,`r table(mstable$pattern)["TRUE"]` of `r nrow(mstable)` participants show the expected pattern. 

```{r meansbyp}
kable(mstable, caption="Mean IRT by condition and participant")
```

## Number of items that show predicted pattern

For items, `r table(mitable$pattern)["TRUE"]` of `r nrow(mitable)` show the pattern. 

```{r meansbyi}
kable(mitable, caption="Mean IRT by condition and item")
```

# Analyses

The following models explore the effect of garden path (&plusmn;GP) and interrogativeness (&plusmn;Q) on IRT.

## Regression analyses

Regression models with fixed effects of &plusmn;GP and &plusmn;Q were run, one including the interaction of &plusmn;GP and &plusmn;Q and one without the interaction term. Both included random effects for item and participant.

Models with random slopes for GP, Q, and their interaction for both error terms fails to converge. A model with random slopes for just GP and Q ain effects likewise fails to converge. Models without random slopes of fixed effects were used.

```{r lmerfull}
full <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | item) +
  (1  | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | item) +
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
irt.compared <- anova(full,no_interaction)
```
```{r results="asis",fig.fullwidth=TRUE}
stargazer(full,no_interaction,header=F,type="latex",covariate.labels = c("Garden path","Interrogative","Interaction"),dep.var.labels = "Common log of IRT",title = "Mixed effects model")
```

The interaction model represents a better fit; the non-interaction model represents a singular fit that is worse overall  (&Chi;^2^ = `r round(irt.compared$Chisq[2],3)`, p < `r round(irt.compared["Pr(>Chisq)"],2)[2,1]`). This supports the hypothesis and the earlier observation over the means that garden paths are more difficult as declaratives than interrogatives.

The relevance of random effects were also tested, by comparing models that exclude each to the model with both random effects (I call this the "full model" in what follows).

```{r lmernorand}
no_item <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_item_no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_participant <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | item),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_participant_no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | item),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_random = lm(  
  inter_reading.log10 ~ 
  GP_condition + Q_condition,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
irt.noParticipant.compared <- anova(full,no_participant)
irt.noItem.compared <-anova(full,no_item)
irt.norandom.compared <-anova(full,no_random)
irt.norandom2noitem.compared <-anova(no_item,no_random)
```

Removing the random effect of item does not degrade the model in a stastically significant way (AIC~full model~ = -305; AIC~no item error~ = -307; -&Chi;^2^ = `r round(irt.noItem.compared$Chisq[2],2)`, p = `r round( irt.noItem.compared["Pr(>Chisq)"][2,1],2)`), but removing the random effect of participant does (AIC~full model~ = -305; AIC~no participant error~ = 47; &Chi;^2^ = `r round(irt.noParticipant.compared$Chisq[2],2)`, p = `r round( irt.noParticipant.compared["Pr(>Chisq)"][2,1],2)`). The model with no random effects is worse than both the full model and the model with only item removed. Ultimately, it's difficult to select between the full model and the "no item" model, as both offer strong fits with more or less the same outcome.

```{r setup2, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(stargazer)
library(lattice)
library(ggplot2)
library(dplyr)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3)
mdata <- read_csv("~/dissertation/csvs/got_prosody.csv")
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$condition <- with(mdata,
  paste(
    ifelse(Condition_Q,"+Q","-Q"),
    ifelse(Condition_GP,"+GP","-GP")
  )
)
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$pdom <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$odom <- mdata$two_level_prosody %in% c("OBJ", "OBJ > PP1")
gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```

# Breaks by condition

## PP1 Break

```{r pp1breaks, fig.cap="PP1 Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + condition, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + condition, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + condition, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings")
kable(pp1br.r1, caption="Reading 1")
kable(pp1br.r2, caption="Reading 2")
```

## OBJ Break

```{r objbreaks, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + condition, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + condition, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + condition, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings")
kable(pp1br.r1, caption="Reading 1")
kable(pp1br.r2, caption="Reading 2")
```

# Breaks by &plusmn;Q

## PP1 Break by &plusmn;Q

```{r gpp1, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + Condition_Q, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + Condition_Q, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + Condition_Q, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-Q","+Q"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-Q","+Q"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-Q","+Q"))
```

## OBJ Break by &plusmn;Q

```{r gpobj, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + Condition_Q, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + Condition_Q, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + Condition_Q, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-Q","+Q"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-Q","+Q"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-Q","+Q"))
```

# Breaks by &plusmn;GP

## PP1 Break by &plusmn;GP

```{r qpp1, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + Condition_GP, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + Condition_GP, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + Condition_GP, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-GP","+GP"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-GP","+GP"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-GP","+GP"))
```

## OBJ Break by &plusmn;GP

```{r qobj, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + Condition_GP, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + Condition_GP, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + Condition_GP, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-GP","+GP"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-GP","+GP"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-GP","+GP"))
```

# 3-level prosodic pattern

```{r 3lvlxtabs}
prosodies.full <- xtabs(~ prosody +condition, mdata)
prosodies.r1 <- xtabs(~ prosody +condition, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ prosody +condition, subset(mdata,Reading==2))
kable(prosodies.full, caption = "Both readings")
kable(prosodies.r1, caption = "Reading 1")
kable(prosodies.r2, caption = "Reading 2")
```

# 2-level prosodic pattern

```{r 2lvlxtabs}
prosodies.full <- xtabs(~ two_level_prosody +condition, mdata)
prosodies.r1 <- xtabs(~ two_level_prosody +condition, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ two_level_prosody +condition, subset(mdata,Reading==2))
kable(prosodies.full, caption = "Both readings")
kable(prosodies.r1, caption = "Reading 1")
kable(prosodies.r2, caption = "Reading 2")
```

# PP1 or PP1 > OBJ

```{r pdom}
pdom <- xtabs(~condition+pdom,data=mdata)
pdom.r1 <- xtabs(~condition+pdom,data=subset(mdata,Reading==1))
pdom.r2 <- xtabs(~condition+pdom,data=subset(mdata,Reading==2))


kable(
  pdom, caption="Both readings",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
kable(
  pdom.r1, caption="Reading 1",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
kable(
  pdom.r2, caption="Reading 2",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
```

# OBJ or OBJ > PP1

```{r odom}
odom <- xtabs(~condition + odom ,data=mdata)
odom.r1 <- xtabs(~condition + odom,data=subset(mdata,Reading==1))
odom.r2 <- xtabs(~condition + odom,data=subset(mdata,Reading==2))

kable(odom, caption="Both readings",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
kable(odom.r1, caption="Reading 1",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
kable(odom.r2, caption="Reading 2",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
```

# Logistic regression models

The interaction between &plusmn;GP and &plusmn;Q approaches significance (p < 0.06) as a predictor of the object break, but not the PP1 break.

```{r models,results="asis"}
obj <- glmer(OBJ~Condition_GP*Condition_Q+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)
pp <- glmer(PP1~Condition_GP*Condition_Q+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)

stargazer(obj,pp,header=F)
```

<!--chapter:end:handout.Rmd-->

---
title: "Inter-reading timing"
author: "Tyler Peckenpaugh"
date: "April 7, 2019"
bibliography: refs.bib
tables: true
output: 
  bookdown::tufte_handout2: 
    toc: True
    latex_engine: xelatex
#   tufte_features: ["fonts", "italics"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3)

library(readr)
library(psych)
library(dplyr)
library(tidyr)
library(knitr)
library(lme4)
library(stargazer)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(jsonlite)

use_old <- FALSE
old<-"csvs/irt-rvad-4_11.csv"
new<-"csvs/irt-rvad-8k.csv"
raw_file <- read_csv(ifelse(use_old,old,new), 
  col_types = cols(
    Item = col_factor(levels = seq(1,48)), 
    Participant = col_character()
  )
)

irt_data <- raw_file

# P 8 is messed up
irt_data<-subset(irt_data,Participant != 8)

# counts
irt_data$Participant <- as.factor(irt_data$Participant)
irt_data$Participant <- relevel(irt_data$Participant,ref=9)
recs<-nrow(irt_data)
subjs<-length(levels(irt_data$Participant))
items<-length(levels(irt_data$Item))
  
irt_data$cond <- paste(
  ifelse(irt_data$Condition_Q,"+Q","-Q"),
  ifelse(
    irt_data$isFiller,
    ifelse(irt_data$Condition_GP,"+PP","-PP"),
    ifelse(irt_data$Condition_GP,"+GP","-GP")
  )
)

irt_data$Q <- ifelse(
  irt_data$Condition_Q,
  "+Q",
  "-Q"
)
irt_data$GP <- ifelse(
  irt_data$Condition_GP,
  "+GP",
  "-GP"
)

# utterance lengths
if(!use_old){
  # only available in newer files
  uls <- append(irt_data$`R1 UL`,irt_data$`R2 UL`)
  uls_desc <- describe(uls)
  uls_r1_desc <- describe(irt_data$`R1 UL`)
  uls_r2_desc <- describe(irt_data$`R2 UL`)
}

irt_props_all <- describe(irt_data$irt)
irt_data_all <- irt_data # data before trimming

# exclude 250 < IRTs > 25000
irt_min <- 250
irt_max <- 25000

irt_lo <- subset(irt_data, irt < irt_min)
irt_hi <- subset(irt_data, irt > irt_max)

irt_data <- subset(
  irt_data, 
  irt > irt_min & irt < irt_max & !isFiller
)
irt_data$Participant<-relevel(irt_data$Participant,ref=5)
irt_data$Item<-relevel(irt_data$Item,ref="1")
# winsorize top/bottom 5% of data (for normal distrbution, this is +/- 2sd)
# see: https://sciencing.com/relationship-between-standard-deviations-percentiles-8768703.html
win_trim=0.05
irt_data <- irt_data %>% group_by(Participant) %>% mutate(win_irt = winsor(irt, trim=win_trim))

# log 10 transform
irt_data$wirt.log10 <- log10(irt_data$win_irt)

# means by condition
meansByConditionLong <- aggregate(
  irt_data$win_irt,
  by=list(
    "Q"=irt_data$Q,
    "GP"=irt_data$GP
  ),
  FUN=mean
) 
meansByCondition <- meansByConditionLong %>% spread(Q,x) 
names(meansByCondition)[1] <- "Condition"
diffs<-list(Condition="Increase", `-Q`=diff(meansByCondition$`-Q`), `+Q`= diff(meansByCondition$`+Q`))
meansByCondition<-rbind(meansByCondition, diffs)
cdiff <- meansByCondition$`-Q`[3]-meansByCondition$`+Q`[3]

# participant means by condition
pmeansByCondition <- aggregate(
  irt_data$irt,
  by=list(
    "Condition"=irt_data$cond,
    "Participant"=irt_data$Participant
  ),
  FUN=mean
) %>% spread(Condition,x) 
pmeansByCondition$pattern <- (
  pmeansByCondition$`+Q +GP` - pmeansByCondition$`+Q -GP` <
  pmeansByCondition$`-Q +GP` - pmeansByCondition$`-Q -GP`
) 

# simple P means
spm <- aggregate(
  irt_data$irt,
  by=list(
    "Participant"=irt_data$Participant
  ),
  FUN=mean
) 

json <- read_file("meta-4_11.json")
meta<-fromJSON(json)
irt_props <- describe(irt_data$irt)
wirt_props <- describe(irt_data$win_irt)
```

# Inter reading time

This document examines the inter-reading time (IRT) from the study. Subjects were asked to read each sentence twice, once with no preview at all (reading 1, a cold reading), and then again after unlimited preview (reading 2, a previewed reading). Inter-reading time (IRT) is a measure of the amount of time between when a subject stops speaking after a cold reading and when they begin speaking for a previewed reading. IRT was measured over `r recs` recordings: 32 participants, 48 items = `r subjs * items` recording pairs (reading 1 and reading 2), with `r  subjs * items - recs` missing pairs. 

## IRT measurement

IRT was measured using a Python script and Google's WebRTC Voice Activity Detection (VAD) over 44.1kHz WAV files downsampled to 8kHz via SOX[^upsamp]. This VAD system uses Gaussian Mixture Models to make probabilistic decisions on whether a given audio frame is speech or noise (see [@gmm1] for a complete explanation). Google's implementation takes one paramater, which they call aggressiveness: a 4-tier setting for the level of confidence necessary to call a gvien frame speech. I call this "rejection rate", where a higher rejection rate means that the model requires a high level of confidence before assuming a frame is speech, i.e. it is more likely to label something noise than speech. The implementation codes this setting as 0-3, where 0 is the most lenient (most likely to label a frame as speech) and 3 is the most stringent (most likely to label a frame as noise).

[^upsamp]: Google's VAD API only accepts WAV files with sample rates that are a multiple of 8kHz. It ultimately downsamples all files to 8kHz, regardless of the input rate.

The recordngs vary in the volume of the speaker's voice and the amount of background noise present. An algorothm was constructed to allow for the most stringent measurement of the least modified data that gave plausible measurements. Specifically, each file was measured using the highest possible rejection rate for the VAD algorithm and no modification of the file. If the timings detected were not plausible, the timings were re-measured with the same rejection rate, but after the recording had undergone a 200Hz high-pass filter[^alg] (HPF). If that still failed, a 400Hz HPF was used. After a further failure, the rejection rate for the VAD was lowered, and the whole thing was tried again (0, 200Hz, 400Hz); and that process was itself repeated until the lowest possible rejection rate was tried of the four possible settings. 

Plausible timings had to meet the following criteria: 

1. An utterance length between 2s and 10s[^spchRate], where utterance timing is the longest contiguous span in the recording that VAD reports as phonation, with breaks in phonation of less than 1s[^shortPauses] not breaking contiguity.

2. A leading silence (delay) length of more than 120ms[^humanRT] and less than 95% of the entire recording's duration.

3. A trailing silence length of less than 95% of the entire recording's duraton.

<!-- TODO add Goldman-Eisler & Jacewicz to bib -->

[^humanRT]: Human reaction time should not permit a smaller delay.

[^spchRate]: Stimuli range from 18-22 syllables in length. If we assume a speeach rate of 3 to 7 syllables per second [@jacewicz2010-sr] we would expect utterances between 2.5s and 7.3s. Conservative thresholds higher and lower than the expected were used, especially on the higher end to allow for any processing or fluency difficulty.

[^shortPauses]: @goldman1961-pa found that a large majority (82.5 to 87%) of pauses in fluent speech are less than 1s.

```{r metable, tidy=FALSE}
metaTable<-xtabs(~agg+hpf, meta[meta$success,])
row.names(metaTable)<-c("Lowest rejection rate","...","...","Highest rejection rate")
kable(
  metaTable, 
  col.names = c("No HPF", "HPF at 200Hz", "HPF at 400Hz"),
  caption="Rejection rate and HPF values",
  booktab=T
)
```

Of the `r nrow(meta)` recordings subjected to this treatment, `r nrow(meta[meta$success,])` resulted in plausible timings. For those that were successfull, the breakdown of HPF and rejection rate used is reported in Table \ref{tab:metable}.

[^alg]: The exact algorithm is available at [github](https://gist.github.com/moui72/4ebc4eb8f69eb9fdb1cab160ce299675) (URL: [bit.ly/2uMrcrG](https://bit.ly/2uMrcrG))

# Distribution of IRT

The raw IRTs including fillers and before any outliers are trimmed are distributed as shown in Figure \ref{fig:rawIRThist}. Overall mean IRT of these data (n = `r irt_props_all$n`), is `r round(irt_props_all$mean/1000,1)`s. The longest is `r round(irt_props_all$max/1000,1)`s and the shortest `r round(irt_props_all$min,0)`ms. Median IRT is `r round(irt_props_all$median/1000,1)`s.

```{r rawIRThist,fig.cap="Distribution of raw IRT"}
histSettings = geom_histogram(binwidth = 500,color="white",fill="#333333")
ggplot(irt_data_all, aes(irt)) +
  histSettings + 
  theme_tufte() +
  xlab("Raw IRT") + 
  ylab("Frequency") + 
  ggtitle("Distribution of raw IRT",subtitle="Bin size = 500ms")
```

IRTs below `r irt_min`ms (`r nrow(irt_lo)`) and above `r round(irt_max/1000,1)`s (`r nrow(irt_hi)`) are (assumed to be implausible) omitted. Experimental data were then Winsorized by participant to bring data in the `r win_trim*100`th and `r 100-(100*win_trim)`th percentile of data to the value at those tresholds. The resulting measure is referred to as wIRT and is distribued as shown in Figure \ref{fig:wIRT} (n = `r wirt_props$n`). Overall mean for wIRT is `r round(wirt_props$mean/1000,1)`s. The longest IRT is `r round(wirt_props$max/1000,1)`s and the shortest is `r round(wirt_props$min,0)`ms. Median wIRT is `r round(wirt_props$median/1000,1)`s.

```{r wIRT,fig.cap="Distribution of wIRT"}
ggplot(irt_data, aes(win_irt)) +
  histSettings + theme_tufte() +
  xlab("wIRT") + ylab("Frequency") + 
  ggtitle(
    "Distribution of wIRT (ms)", 
    subtitle="Bin size = 500ms"
  )
```

For the purposes of regression analysis, a common log transformation reduces the skew in the data. This distribution is seen in Figure \ref{fig:log10wins}.

```{r log10wins,fig.cap="Common log of wIRT"}
ggplot(irt_data, aes(wirt.log10)) +
  geom_histogram(binwidth = 0.1, color="white",fill="#333333") + theme_tufte() +
  xlab("Common log of wIRT") + ylab("Frequency") + 
  ggtitle("Distribution of Common Log of wIRT", subtitle="Bin size = 0.1")

```

# Means by condition

Table \ref{tab:mns} shows the mean wIRT by experimental condition. The top left cell represents the mean wIRT for the declaritive controls ("-Q -GP"). The bottom row shows the increase in IRT across the garden path condition. 

```{r mns}
meansByConditionS <- meansByCondition
meansByConditionS$`-Q` <- meansByConditionS$`-Q`/1000
meansByConditionS$`+Q` <- meansByConditionS$`+Q`/1000
kable(
  meansByConditionS, 
  caption = "Means (s) by condition",
  digits = 2,
  booktab=T
)
```

The difference in the effect of &plusmn;GP across &plusmn;Q is `r round(cdiff,0)`ms. This difference `r ifelse(cdiff > 0, paste("is"),paste("is not"))` in the direction that supports the hypothesis.

```{r interactinplot,fig.cap="Mean IRT by condition"}

meansByConditionLong$Qn <- ifelse(
  meansByConditionLong$Q == "+Q", 
  "Interrogative", 
  "Declarative"
)

meansByConditionLong$GPn <- ifelse(
  meansByConditionLong$GP == "+GP", 
  "Garden path", 
  "Non-garden path"
)

ggplot(
  meansByConditionLong, 
  aes(x,x=GPn,y=x,group=Qn,linetype=Qn)
) + 
  geom_line() +
  geom_point() +
  theme_tufte() +
  labs(x="", y="Mean IRT (ms)",linetype="") 
```

# Regression models

The models with random slopes for participant and item did not converge, so the tables in this section show models with no random slopes. 

```{r lmeMods}

irt.full <- lmer(
  win_irt ~ Condition_Q * Condition_GP + 
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noInteraction <- lmer(
  win_irt ~ Condition_Q + Condition_GP + 
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noParticipant <- lmer(
  win_irt ~ Condition_Q * Condition_GP + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noItem <- lmer(
  win_irt ~ Condition_Q * Condition_GP + 
    (1 | Participant),
  data = irt_data,
  REML=F
)

irt.noFxd <- lmer(
  win_irt ~
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noRand <- lm(win_irt ~ Condition_Q * Condition_GP,
                 data = irt_data)

irt.dummy <- lm(win_irt ~ Condition_Q * Condition_GP,
                  data = irt_data
                )
irt.dummy.noInt <- lm(win_irt ~  Condition_Q + Condition_GP + 
                  Participant + Item,
                  data = irt_data
                )
```
For the first model, fixed effects of &plusmn;GP and &plusmn;Q as well is the interaction between them were included, along with random effects of participant and item. The second model removes the interaction, but keeps both main effects.

```{r modTabLME,results="asis"}
stargazer(
  irt.full,irt.noInteraction,
  header = F,
  title="Interaction vs. non-interaction model",
  dep.var.labels=c("Winsorized IRT"),
  covariate.labels=c(
    "+GP",
    "+Q",
    "+GP +Q"
  )
)
```

A model with no fixed effects was also run, here it is shown beside the interaction model from the previous table.

```{r modelsTables, results="asis"}
stargazer(
  irt.full,irt.noFxd,
  header = F,
  title="Interaction vs. no fixed effects",
  dep.var.labels=c("Winsorized IRT"),
  covariate.labels=c(
    "+GP",
    "+Q",
    "+GP +Q"
  )
)
```
```{r, results="asis"}
stargazer(
  irt.full,irt.noRand,
  header = F,
  title="Interaction vs. no random effects",
  dep.var.labels=c("Winsorized IRT"),
  covariate.labels=c(
    "+GP",
    "+Q",
    "+GP +Q"
  )
)
```

# Delay comparison for cold vs. previewed readings

A comparison of the delay for cold readings compared with that of previewed readings can lend insight into the extent to which subjects followed task instructions.

"Delay" here is the amount of time after the start of a recording until the beginning of phonation of the target sentence. Cold readings are also called "reading 1", while previewed readings are the same as "reading 2". Implausible delays of >15s are excluded in the data shown here.

```{r delayComparison, echo=F}
raw_rs_file <- read_csv("csvs/rvad-raw-8k.csv")
raw_rs <- subset(raw_rs_file,!isFiller & Leading < 15000)
raw_rs$reading <- raw_rs$Reading
raw_rs$Reading <- ifelse(raw_rs$reading == 1, "Cold", "Previewed")
ggplot(raw_rs, aes(Leading, fill = Reading)) +
  geom_histogram(binwidth = 400,position="dodge",color="black") +
  theme_tufte()+
  scale_fill_manual(values=c("black","white")) +
  ggtitle("Distribution of delay by reading", subtitle = "Bin size = 400ms")

diffs <- raw_rs[c("Reading","Leading","Participant","Item","isFiller","Condition_Q","Condition_GP")]  %>% spread(Reading,Leading)

diffs$diffs <- diffs$Previewed-diffs$Cold
diffDis<- describe(diffs$diffs)
diffsByP<-aggregate(diffs~Participant,data=diffs,FUN=function(x){round(mean(x))})
colnames(diffsByP) <- c("Participant", "Mean difference in delay (ms)")
diffsByP.props <- describe(diffsByP$`Mean difference in delay (ms)`)
```

For cold readings, n = `r table(raw_rs$Reading)["Cold"]` and for previewed, n = `r table(raw_rs$Reading)["Previewed"]`. 

## Difference in delay across paired readings

Overall, each recording pair (n = `r diffDis$n`) has a mean difference in delay (DelDif = previewed delay - cold delay) of `r round(diffDis$mean/1000,1)`s (sd = `r round(diffDis$sd/1000,1)`s), with a minumum of `r round(diffDis$min/1000,1)`s and a max of `r round(diffDis$max/1000,1)`s. The median DelDif is `r round(diffDis$median/1000,1)`s. The distribution DelDif is shown in Figure \ref{fig:deddif}.

```{r deddif, fig.cap="Distribution of DelDif"}
ggplot(na.omit(diffs), aes(diffs)) +
  geom_histogram(binwidth = 500,color="white",fill="black") +
  theme_tufte() +
  labs(x="Difference in delay", y="Count",title="Distribution of difference in delay",subtitle="Bin width = 500ms")
```

If we calculate the mean delay difference by participant, we find a mean participant DelDef of `r round(diffsByP.props$mean/1000,1)`s. Each participant's DelDif is &le; `r diffsByP.props$min`ms and &ge; `r round( diffsByP.props$max/1000,1)`s, with a median of `r round(diffsByP.props$median/1000,2)`s. Table \ref{tab:difsbyp} shows these values.

```{r difsbyp}
kable(
  diffsByP[order(diffsByP[,2]),],
  digits = 0,
  caption="Delay differences by participant",
  booktab=T,
  longtab=T
)
```

The distribution of the participants' DelDifs can be found in Figure \ref{fig:difhistbyp}.

```{r difhistbyp, fig.cap="Mean difference in delay by participant"}
ggplot(diffsByP, aes(`Mean difference in delay (ms)`/1000)) +
  geom_histogram(binwidth = 1,color="white",fill="black") +
  theme_tufte() +
  labs(x="Mean difference in delay", y="Count",title="Mean difference in delay by participant", subtitle="Bin size = 1s")
```

# Individual variation

Individuals vary with regard to the effect of the garden path condition on IRT. For `r table(pmeansByCondition$pattern)["TRUE"]` of `r nrow(pmeansByCondition)`, the increase in IRT for garden paths is greater for interrogatives than it is for declaratives.

```{r pPattern}
kable(
  pmeansByCondition[c(1:5)],
  caption="Mean wIRT (ms) by condition and participant",
  booktab=T,
  longtab=T
)
```

```{r irtzoomLft, fig.cap="Left tail of raw IRT distribution"}
ggplot(subset(irt_data_all,irt<1000), aes(irt)) +
  geom_histogram(binwidth = 50,color="white",fill="#333333") + theme_tufte() +
  xlab("Raw IRT") + ylab("Frequency") + 
  ggtitle("Left tail of IRT distribution (ms)",subtitle="IRT < 1s, bin size = 50ms")
```


```{r zoomRgt, fig.cap="Right tail of raw IRT distribution"}
ggplot(subset(irt_data_all,irt>22000), aes(irt/1000)) +
   geom_histogram(binwidth = 1, color="white", fill="#333333") + theme_tufte() +
  xlab("Raw IRT") + ylab("Frequency") + 
  ggtitle("Right tail of IRT distribution (s)", subtitle="IRT > 22s, bin size = 1s")
```

# References

<!--chapter:end:irt-data.Rmd-->

---
title: "Description of Inter-Item Timing"
author: "Tyler Peckenpaugh"
date: "3/25/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    latex_engine: xelatex
    toc: true
    fig_caption: true
mainfont: Georgia
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3, table)
library(readr)
library(knitr)
library(kableExtra)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)
library(psych)
library(geepack)
library(tidyr)
library(ggplot2)
getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

mean.sd <- function(x) c(mean = mean(x), sd = sd(x))
# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = TRUE
inter_item_timings_new <- read_csv("csvs/src/vad-irt-all-48k_agg-3_2019-03-26_131537.csv")
inter_item_timings_new$GP_condition <- inter_item_timings_new$Condition_GP
inter_item_timings_new$Q_condition <- inter_item_timings_new$Condition_Q
inter_item_timings_new$Condition_Q <- NULL
inter_item_timings_new$Condition_GP <- NULL


inter_item_timings_new$condition <- paste(
  ifelse(inter_item_timings_new$Q_condition,"+Q","-Q"),
  ifelse(
    inter_item_timings_new$isFiller,
    ifelse(inter_item_timings_new$GP_condition,"+PP","-PP"),
    ifelse(inter_item_timings_new$GP_condition,"+GP","-GP")
  )
)

inter_item_timings_new$participant <- as.factor(inter_item_timings_new$Participant)

allparts <- subset(
  inter_item_timings_new, 
   !isFiller
)

inter_item_timings <- subset(
  inter_item_timings_new, 
   !isFiller
  # exclude ps where number of IRTs < 35/48 (72.9%)
  & !Participant %in% c(7,13,5,17,12,21,22,3) 
  & irt < 20000
  & irt > 150
)
inter_item_timings$item <- as.factor(inter_item_timings$Item)

inter_item_timings<-transform(inter_item_timings,winsrdIRT = ave(irt,participant,FUN=winsor))

inter_item_timings$inter_reading <- inter_item_timings$winsrdIRT

inter_item_timings$inter_reading.ln <- log(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.inverse <- 1/(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.sqred <- (inter_item_timings$inter_reading)^2


order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))

morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)
inter_item_timings$Sorder <- 2
inter_item_timings$Sorder[inter_item_timings$Participant %in% order1] <- 1
inter_item_timings$Iorder <- getIOrd(inter_item_timings$item,inter_item_timings$Sorder)
inter_item_timings$Sorder <- as.factor(inter_item_timings$Sorder)
inter_item_timings$list <- inter_item_timings$Participant %% 4
inter_item_timings$grp <- paste(inter_item_timings$Sorder,inter_item_timings$list,sep="-")
```

# Inter-item timing

Inter-reading time (IRT) is a measure of the amount of time inbetween when a subject stops speaking during a cold reading and when they begin speaking for a previewed reading. Practically, this was done over 1,533 recording (33 participants, 48 items = `r 33 * 48` pairs, with some missing data resulting in the 1,533). This was measured using Google's WebRTC Voice Activity Detection (VAD).

> IRT(item) = the timestamp of the start of speech for item[reading one] plus (the length of item[reading two] minus the timestamp of the end of speech)

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. IRT is meant to represent their chosen preview time for the second reading.

# Distribution of IRTs, all participants

```{r}
gmean <- mean(inter_item_timings_new$irt)
gsd<-sd(inter_item_timings_new$irt)
gmax<-gmean+3*gsd
```
The overal mean IRT for all participants, all items (including fillers), and all conditions is `r gmean`ms (`r gsd`).

The following histograms show the distribution of IRT across all items and all participants. In the second graph, overly short IRTs (shorter than 150ms) are excluded. In the third, overly long (longer than ~18s) and overly short IRTs are excluded.

```{r fig.cap="Raw IRT"}
allparts <- inter_item_timings_new
hist(na.omit(allparts$irt), breaks=50,xlab="Raw IRT",main="Raw IRT, all Parts",xlim=c(0,20000))
```
```{r}
hist(subset(allparts, irt>150)$irt, breaks=50,xlab="Raw IRT",main="Raw IRT, all Parts, short excluded",xlim=c(0,20000))
```
```{r}
hist(subset(allparts, irt>150 & irt < gmax)$irt, breaks=50,xlab="Raw IRT",main="Raw IRT, all Parts, short and long excluded",xlim=c(0,20000))

```

# Missing data and attrition

Due to noise in recordings and/or technical difficulties during data collection, a number of IRTs are missing in the data. The following total shows which participants are missing how many IRTs; ideally each would have 48 IRTs.

```{r}
missingIrts<-read.csv("~/Downloads/missing_irts - Sheet2.csv")
kable(missingIrts, caption="Missing IRTs",
      col.names = c(
        "Participant",
        "IRTs missing",
        "IRTs availble",
        "Recording pairs",
        "Percentage available",
        "Group"
      ),
      align="c")%>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

Participants with fewer than 72% of the expected number of IRTs are excluded: 7, 13, 5, 17, 12, 21, 22, and 3, 8 in total. The resulting number of remaining participants is 25.

## Group sizes after attrition

The following table shows how the participants are distributed across groups after attrition. While each group and each split are similar in size overall, there is an unfortunate disparity across ordering for two groups: Group 2 and Group 4.

```{r}
groupses<-addmargins(with(inter_item_timings[!duplicated(inter_item_timings$Participant),],table(list,Sorder)))
row.names(groupses) <- c(paste("Group",1:4),"Split Total")
kable(groupses, caption="Group/order totals after attrition", align="c",
      col.names = c("Split AB","Split BA","Group Total")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

### Avaialability of experimental item IRT after attrition

For the remaining participants, the availability of IRT for experimental items was 88.7%, ranging by participant from 16/16 to 10/16.

In detail, 13 of 25 participants had all experimental IRTs available, while five had 11/16. There were two participants who had 12/16, 14/16 and 15/16 respectively, and one with 10/16.

## Distribution of experimental item IRT after attrition

The following histograms show the distribution of experimental item IRTs after attrition, and then the Winsorized IRTs, and finally the common log of winsorized IRTs, which are the shape of the data most suited to regression analyses.

```{r hist}

hist(inter_item_timings$irt, breaks=50,xlab="raw IRT",main="Raw IRT",xlim=c(0,20000))

hist(inter_item_timings$inter_reading, breaks=50,xlab="IRT",main="Winsorized IRT",xlim=c(0,20000))

hist(inter_item_timings$inter_reading.log10, breaks=50,xlab="log10 IRT",main="Common log of winsorized IRT",xlim=c(2.5,4.5))
```

# Mean and SD of winsorized IRT by condition

If we assume that interrogative PP-attachment garden paths are easier to process as an interrogative than in the declarative, and that IRT represents how difficult a sentence is to process, we would expect the difference in mean IRT to be larger for declarative garden paths compared to declarative controls than for the same comparison of interrogatives.

The means of the Winsorized IRT by condition indeed show this pattern.

```{r sdtable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

sdtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, sd))

ctable <- rbind(mtable,sdtable)
row.names(ctable) <- c("Mean", "SD")
```

Difference for declaratives: `r round(mtable[2] - mtable[1],2)`; for interrogatives: `r round(mtable[4]-mtable[3],2)`. While the difference across the interrogative/declarative condition is not huge, it is there.

```{r sdtableOut}
kable(t(ctable), align="r", caption="Condition means") %>%
  kable_styling(bootstrap_options = c("striped")) %>%
  column_spec(1,bold=T)
```

<!-- ## Means by condition and item/subject (all data) -->

<!-- There is variation across participants in terms of whether or not they show this pattern. -->

<!-- ```{r allmeantable, echo=FALSE} -->
<!-- mstable <- aggregate(irt ~ condition + Participant, data=na.omit(inter_item_timings_new), mean) -->
<!-- mitable <- aggregate(irt ~ condition + Item, data=na.omit(inter_item_timings_new), mean) -->

<!-- mitable<-spread(mitable, key=condition, value=irt, fill = NA, convert = FALSE) -->
<!-- mstable<-spread(mstable, key=condition, value=irt, fill = NA, convert = FALSE) -->

<!-- mstable$pattern <- mstable$`-Q +GP` - mstable$`-Q -GP` > mstable$`+Q -GP` - mstable$`+Q -GP`  -->
<!-- mitable$pattern <- mitable$`-Q +GP` - mitable$`-Q -GP` > mitable$`+Q -GP` - mitable$`+Q -GP` -->
<!-- ``` -->

<!-- ```{r allmeansbyp} -->
<!-- kable(mstable, align="r") %>% -->
<!--   kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>% -->
<!--   column_spec(1,bold=T) -->
<!-- ``` -->
<!-- ```{r allmeansbyi} -->
<!-- kable(mitable, align="r") %>% -->
<!--   kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>% -->
<!--   column_spec(1,bold=T) -->
<!-- ``` -->

# Item and subject variation

There is variation across participants in terms of whether or not they show this pattern.

```{r meantable, echo=FALSE}
mstable <- aggregate(inter_reading ~ condition + participant, data=na.omit(inter_item_timings), mean)
mitable <- aggregate(inter_reading ~ condition + item, data=na.omit(inter_item_timings), mean)

mitable<-spread(mitable, key=condition, value=inter_reading, fill = NA, convert = FALSE)
mstable<-spread(mstable, key=condition, value=inter_reading, fill = NA, convert = FALSE)

mstable$pattern <- mstable$`-Q +GP` - mstable$`-Q -GP` > mstable$`+Q -GP` - mstable$`+Q -GP` 
mitable$pattern <- mitable$`-Q +GP` - mitable$`-Q -GP` > mitable$`+Q -GP` - mitable$`+Q -GP`
```


## Number of participants who show predicted pattern

17 of 25 participants show the expected pattern (p = 0.05 in a one-tailedd binomial test). This suggests that the pattern generalizes across participants.

<!-- # ```{r PmatchesPatterns} -->
<!-- # pc <- table(mstable$pattern) -->
<!-- # row.names(pc) <- c("Does not show pattern", "Shows pattern") -->
<!-- # kable(pc, col.names = c("", "Number of participants"),caption="Participants who show expected pattern") %>% -->
<!-- #   kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>% -->
<!-- #   column_spec(1,bold=T) -->
<!-- # ``` -->

```{r meansbyp}
kable(mstable, align="r",caption="Mean IRT by condition and participant") %>%
  kable_styling(bootstrap_options = c("striped")) %>%
  column_spec(1,bold=T)
```

## Number of items that show predicted pattern

Notably, only 9 of 16 items show the pattern (p = 0.4 in a one-tailed binomial test). This suggests that the pattern does not generalize across items. This is likely problematic for any regression analyses.

<!-- # ```{r ImatchesPat} -->
<!-- # ic <- table(mitable$pattern) -->
<!-- # row.names(ic) <- c("Does not show pattern", "Shows pattern") -->
<!-- # kable(ic, col.names = c("", "Number of items"),caption="Items that show expected pattern") %>% -->
<!-- #   kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>% -->
<!-- #   column_spec(1,bold=T) -->
<!-- # ``` -->


```{r meansbyi}
kable(mitable, align="r",caption="Mean IRT by condition and item") %>%
  kable_styling(bootstrap_options = c("striped")) %>%
  column_spec(1,bold=T)
```



<!--chapter:end:irt-desc.Rmd-->

---
title: "Description of Inter-Item Timings (IRTs)"
author: "Tyler Peckenpaugh"
date: "3/29/2019"
output:
  tufte::tufte_html: 
    tufte_features: ["fonts", "italics"]
    toc: True
  tufte::tufte_handout: 
    toc: True  
    latex_engine: xelatex

---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3)
library(readr)
library(knitr)
library(kableExtra)
library(pander)
library(lme4)
library(lmerTest)
library(sjPlot) # table functions
library(lattice)
library(psych)
library(geepack)
library(tidyr)
library(ggplot2)

getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

inter_item_timings_new <- read_csv("csvs/irt-all-48k_agg-3_2019-04-01_173138.csv")
inter_item_timings_new$GP_condition <- inter_item_timings_new$Condition_GP
inter_item_timings_new$Q_condition <- inter_item_timings_new$Condition_Q
inter_item_timings_new$Condition_Q <- NULL
inter_item_timings_new$Condition_GP <- NULL

inter_item_timings_new<-subset(inter_item_timings_new,irt>0)

inter_item_timings_new$condition <- paste(
  ifelse(inter_item_timings_new$Q_condition,"+Q","-Q"),
  ifelse(
    inter_item_timings_new$isFiller,
    ifelse(inter_item_timings_new$GP_condition,"+PP","-PP"),
    ifelse(inter_item_timings_new$GP_condition,"+GP","-GP")
  )
)

inter_item_timings_new$participant <- as.factor(inter_item_timings_new$Participant)
inter_item_timings_new$item <- as.factor(inter_item_timings_new$Item)

allparts <- droplevels(subset(inter_item_timings_new, !isFiller==T))
allparts<-transform(allparts,winsrdIRT = ave(irt,participant,FUN=winsor))
write_csv2(allparts,"csvs/irt-working.csv")
descrip <- describe(inter_item_timings_new$irt)
gmean <- round(descrip$mean,2)
gsd <- round(descrip$sd,2)
# EXCLUDE TOP AND BOTTOM 5% (N=77)
# quantile(inter_item_timings_new$irt,c(.02,.05,.1,.9,.95,.98))
#   2%    5%   10%   90%   95%   98% 
# 1442  1823  2596 11581 13798 17554 
QS<-quantile(inter_item_timings_new$irt,c(.02,.05,.1,.9,.95,.98))
cutoff=5
gmax <- 25000
gmin <- 250
#--------------------------
numOver <- nrow(inter_item_timings_new[inter_item_timings_new$irt > gmax,])
numUnder <- nrow(inter_item_timings_new[inter_item_timings_new$irt < gmin,])

irt_no_excl <- droplevels(subset(
  inter_item_timings_new, 
   !isFiller & irt > gmin & irt < gmax
))
mitable <- aggregate(irt ~ condition + item, data=na.omit(irt_no_excl), mean)
maxmiss = 4
misstab<-with(irt_no_excl, table(participant))
exclude<-names(misstab[misstab<16-maxmiss])
exclude_items<-mitable[mitable$`-Q -GP` > 7000,]$item

irt_data <- droplevels(subset(
  inter_item_timings_new, 
    !participant %in% exclude &
    !isFiller & 
    irt > gmin &
    irt < gmax 
))

irt_data_itemsExcluded <- droplevels(subset(
  inter_item_timings_new, 
    !isFiller & 
    irt > gmin &
    irt < gmax &
    !item %in% exclude_items
))
inter_item_timings <- irt_data

inter_item_timings<-transform(inter_item_timings,winsrdIRT = ave(irt,participant,FUN=winsor))

inter_item_timings$inter_reading <- inter_item_timings$winsrdIRT
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading)



order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))

morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)
inter_item_timings$Sorder <- 2
inter_item_timings$Sorder[inter_item_timings$Participant %in% order1] <- 1
inter_item_timings$Iorder <- getIOrd(inter_item_timings$item,inter_item_timings$Sorder)
inter_item_timings$Sorder <- as.factor(inter_item_timings$Sorder)
inter_item_timings$list <- inter_item_timings$Participant %% 4
inter_item_timings$grp <- paste(inter_item_timings$Sorder,inter_item_timings$list,sep="-")
```

# Inter-item timing

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. Inter-reading time (IRT) is a measure of the amount of time between when a subject stops speaking after a cold reading and when they begin speaking for a previewed reading. 

> IRT = delay after the end of a cold reading and before the start of a previewed reading

Practically, this was done over `r nrow(inter_item_timings_new)` recordings (33 participants, 48 items = `r 33 * 48` pairs, with `r  33 * 48 - nrow(inter_item_timings_new)` missing data). This was measured using Google's WebRTC Voice Activity Detection (VAD) over .wav files that had been subjected to a band-pass filter with a low threshold of 200Hz[^hum] and a high threshold of 3100Hz.

[^hum]: a low hum in the room needed to be accounted for

## Description and cleanup

The following section details the IRT data and the outlier removal and resulting participant attrition. 

## Distribution of IRTs, all participants

The overal mean IRT for all participants, all items (including fillers), and all conditions is `r gmean`ms (sd = `r gsd`). The highest IRT was `r paste(round(descrip$max,2))`ms.

The following histograms show the distribution of IRT across all items and all participants. In the second graph, overly short IRTs (shorter than `r gmin`ms; `r numUnder`[^lo] such data) are excluded. In the third, overly long (longer than `r paste(gmax)`; `r numOver` such data) and overly short IRTs are excluded.

[^lo]: This is `r cutoff`% of the `r nrow(inter_item_timings_new)` total data

```{r allhist}
allparts <- inter_item_timings_new
hist(subset(allparts,irt<250)$irt, breaks=100,xlab="Raw IRT",main="Raw IRT, all Parts")
```
```{r nolowhist}
hist(
  subset(allparts, irt > gmin)$irt, 
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short excluded"
)
```
```{r nolownohighhist, include=FALSE}
hist(
  subset(allparts, irt > gmin & irt < gmax)$irt,
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short and long excluded"
)

```

## Missing data and attrition

Due to noise in recordings and/or technical difficulties during data collection, a number of IRTs are missing for experimental items in the data. The following table shows which participants are missing how many IRTs; ideally each would have 48 IRTs and 16 experimental IRTs.

```{r missingData}
kable(
  caption="Mising data, by participant",
  align="r",
  cbind(
    with(inter_item_timings_new[inter_item_timings_new$irt>0,], 48-table(participant)),
    with(inter_item_timings_new[inter_item_timings_new$irt>0,], paste(round(100 * (table(participant)/48),2),"%",sep="")),
    with(irt_no_excl, 16-table(participant)),
    with(irt_no_excl, paste(100 * (table(participant)/16),"%",sep=""))
  ), col.names = c("Missing IRTs", "Available % of IRTs", "Missing experimental IRTs", "Available % of experimental IRTs")
)
np <- nrow(levels(inter_item_timings$Participant))
```

The `r length(exclude)` participants missing more than `r maxmiss` experimental IRTs (`r exclude`) are excluded.

## Group sizes after attrition

The following table[^g1] shows how the participants are distributed across groupsafter attrition. Ideally, there would be 4 per group-order cell, but because of attrition the cells are uneven. Because regression is able to account for uneven groups, this defect will hopefully not play an important role in the analyses that follow.

[^g1]: There is 5 in Group 1, Split BA because I ran four participants per group-order, and then one extra who happened to be assigned to group 1, split BA; and by happenstance, none of the participants from that cell needed to be excluded.

```{r groupses}
groupses<-addmargins(with(inter_item_timings[!duplicated(inter_item_timings$Participant),],table(list,Sorder)))
row.names(groupses) <- c(paste("Group",1:4),"Split Total")
kable(groupses, caption="Group/order totals after attrition", 
  col.names = c("Split AB","Split BA","Group Total"))
```
## Distribution of experimental item IRT after attrition

The following histograms show the distribution of experimental item IRTs after attrition, and then the Winsorized IRTs, and finally the common log of winsorized IRTs, which are the shape of the data most suited to regression analyses.

```{r attritionhists}

hist(inter_item_timings$irt, breaks=8,xlab="raw IRT",main="Raw IRT")

hist(inter_item_timings$inter_reading, breaks=8,xlab="IRT",main="Winsorized IRT")

hist(inter_item_timings$inter_reading.log10, breaks=8,xlab="log10 IRT",main="Common log of winsorized IRT")
```

## Mean and SD of winsorized IRT by condition

If we assume that interrogative PP-attachment garden paths are easier to process as an interrogative than in the declarative, and that IRT represents how difficult a sentence is to process, we would expect the difference in mean IRT to be larger for declarative garden paths compared to declarative controls than for the same comparison of interrogatives.

The means of the Winsorized IRT by condition indeed show this pattern.

```{r sdtable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

sdtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, sd))

ctable <- rbind(mtable,sdtable)
row.names(ctable) <- c("Mean", "SD")
decl <- round(mtable["-Q +GP"] - mtable["-Q -GP"],2)
int <- round(mtable["+Q +GP"] - mtable["+Q -GP"],2)
diffGPQ <- decl - int
```

Difference for declaratives: `r decl`; for interrogatives: `r int`. While a difference across the interrogative/declarative condition of `r diffGPQ` is not huge, it does match the hypothesized pattern.

```{r sdtableOut}
kable(t(ctable), caption="Condition means")
```

## Item and subject variation

There is variation across participants in terms of whether or not they show this pattern.

```{r meantable, echo=FALSE}
mstable <- aggregate(inter_reading ~ condition + participant, data=inter_item_timings, mean)
mitable <- aggregate(inter_reading ~ condition + item, data=na.omit(inter_item_timings), mean)

mitable<-spread(mitable, key=condition, value=inter_reading, fill = NA, convert = FALSE)
mstable<-spread(mstable, key=condition, value=inter_reading, fill = NA, convert = FALSE)

mstable$pattern <- mstable$`-Q +GP` - mstable$`-Q -GP` > mstable$`+Q -GP` - mstable$`+Q -GP` 
mitable$pattern <- mitable$`-Q +GP` - mitable$`-Q -GP` > mitable$`+Q -GP` - mitable$`+Q -GP`

binP <- binom.test(table(mstable$pattern)["TRUE"],nrow(mstable),alternative="less")
binI <- binom.test(table(mitable$pattern)["TRUE"],nrow(mitable),alternative="less")

```


## Number of participants who show predicted pattern

In the analyzed data,`r table(mstable$pattern)["TRUE"]` of `r nrow(mstable)` participants show the expected pattern. A one-tailed binomial allows against the null hyopthesis that the true probability of the pattern holding across participants is less than 50% is significant (p = `r round(1-binP$p.value,2)`).

```{r meansbyp}
kable(mstable, caption="Mean IRT by condition and participant")
```

## Number of items that show predicted pattern

 For items, `r table(mitable$pattern)["TRUE"]` of `r nrow(mitable)` show the pattern. A one-tailed binomial against the null hyopthesis that the true probability of the pattern holding across items is less than 50% is satistically significant (p = `r round( 1-binI$p.value,2)`).


```{r meansbyi}
kable(mitable, caption="Mean IRT by condition and item")
```
# Analyses

The following models explore the effect of garden path (&plusmn;GP) and interrogativeness (&plusmn;Q) on IRT.

## Regression analyses

A full model with random slopes for GP, Q, and their interaction for both error terms fails to converge. A model with random slopes for just GP `+` Q likewise fails to converge. Simple models with no random slopes are shown below. 

```{r lmerfull}
full <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | item) +
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | item) +
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
tab_model(full,no_interaction)
irt.compared <- anova(full,no_interaction)
```


The interaction model does not represent a statistically significant improvement in fit (&Chi;^2^ = `r round(irt.compared$Chisq[2],3)`, p < `r round(irt.compared["Pr(>Chisq)"],2)[2,1]`), and so does not support the primary hypothesis.

```{r lmernorand}
no_item <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_item_no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_participant <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | item),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)

irt.noParticipant.compared <- anova(full,no_participant)
irt.noItem.compared <-anova(full,no_item)
```

The simplified model still does not show a statstically significant interaction.

```{r lmertable}
tab_model(no_item)
```

Removing the random effect of item does not degrade the model in a stastically significant way (&Chi;^2^ = `r round(irt.noItem.compared$Chisq[2],2)`, p = `r round( irt.noItem.compared["Pr(>Chisq)"][2,1],2)`), but removing the random effect of participant does (&Chi;^2^ = `r round(irt.noParticipant.compared$Chisq[2],2)`, p = `r round( irt.noParticipant.compared["Pr(>Chisq)"][2,1],2)`).

## GEE Analyses

Generalized Estimating Equation (GEE) analyses with participant as the error term show much the same results.

```{r gee1}
gee.byP <- geeglm(
  inter_reading.log10 ~ GP_condition * Q_condition,
  id=participant,
  data=inter_item_timings
)
gee.byP.noInt<- geeglm(
  inter_reading.log10 ~ GP_condition + Q_condition,
  id=participant,
  data=inter_item_timings
)
tab_model(gee.byP,gee.byP.noInt)
irt.compared<-anova(gee.byP,gee.byP.noInt)
```

The interaction model does not represent a statistically significant improvement in fit (&Chi; = `r round(irt.compared$X2[1],3)`, p < `r round(irt.compared["P(>|Chi|)"],2)`), and so does not support the primary hypothesis.

# Excluding items

If we exclude items where the IRT for the control condition (-Q, -GP) is longer than 7s, we get the following:
```{r gee2, echo=FALSE}
inter_item_timings<-irt_data_itemsExcluded
inter_item_timings$inter_reading <- inter_item_timings$irt
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$irt)

mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

sdtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, sd))

ctable <- rbind(mtable,sdtable)
row.names(ctable) <- c("Mean", "SD")
decl <- round(mtable["-Q +GP"] - mtable["-Q -GP"],2)
int <- round(mtable["+Q +GP"] - mtable["+Q -GP"],2)
diffGPQ <- decl - int
```

Difference for declaratives: `r decl`; for interrogatives: `r int`; difference of differences: `r diffGPQ`.

```{r exclit}
kable(t(ctable), caption="Condition means")
```

## GEE Analyses

Generalized Estimating Equation (GEE) analyses with participant as the error term show much the same results.

```{r exclitgee}
gee.byP <- geeglm(
  inter_reading.log10 ~ GP_condition * Q_condition,
  id=participant,
  data=inter_item_timings
)
gee.byP.noInt<- geeglm(
  inter_reading.log10 ~ GP_condition + Q_condition,
  id=participant,
  data=inter_item_timings
)
tab_model(gee.byP,gee.byP.noInt)
irt.compared<-anova(gee.byP,gee.byP.noInt)
```
```{r exclitgee2}
gee.byI <- geeglm(
  inter_reading.log10 ~ GP_condition * Q_condition,
  id=item,
  data=inter_item_timings
)
gee.byI.noInt<- geeglm(
  inter_reading.log10 ~ GP_condition + Q_condition,
  id=item,
  data=inter_item_timings
)
tab_model(gee.byI,gee.byI.noInt)
irt.compared<-anova(gee.byP,gee.byP.noInt)
```

The interaction model does not represent a statistically significant improvement in fit (&Chi; = `r round(irt.compared$X2[1],3)`, p < `r round(irt.compared["P(>|Chi|)"],2)`), and so does not support the primary hypothesis.

<!--chapter:end:irt-desc2.Rmd-->

---
title: "Description of Inter-Item Timings (IRTs)"
author: "Tyler Peckenpaugh"
date: "3/29/2019"
output:
  tufte::tufte_handout: 
    toc: True  
    latex_engine: xelatex
  tufte::tufte_html: 
    tufte_features: ["fonts", "italics"]


---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3)
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lattice)
library(psych)
library(geepack)
library(tidyr)
library(dplyr)
library(ggplot2)
library(stargazer)
library(forcats)

getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

# load file, set columns
inter_item_timings_new <- read_csv("csvs/irt-rvad-all-48k-2019-04-03_17h03m24s.csv")
inter_item_timings_new$GP_condition <- inter_item_timings_new$Condition_GP
inter_item_timings_new$Q_condition <- inter_item_timings_new$Condition_Q
inter_item_timings_new$Condition_Q <- NULL
inter_item_timings_new$Condition_GP <- NULL

# remove 0 irts
zeros<-subset(inter_item_timings_new,irt==0)
inter_item_timings_new<-subset(inter_item_timings_new,irt>0)

# generate condition column for ease of display
inter_item_timings_new$condition <- paste(
  ifelse(inter_item_timings_new$Q_condition,"+Q","-Q"),
  ifelse(
    inter_item_timings_new$isFiller,
    ifelse(inter_item_timings_new$GP_condition,"+PP","-PP"),
    ifelse(inter_item_timings_new$GP_condition,"+GP","-GP")
  )
)

# make lowercase columns
inter_item_timings_new$participant <- as.factor(inter_item_timings_new$Participant)
inter_item_timings_new$item <- as.factor(inter_item_timings_new$Item)

# basic outlier removal
descrip <- describe(inter_item_timings_new$irt)
gmean <- round(descrip$mean,2)
gsd <- round(descrip$sd,2)
gmax <- 25000
gmin <- 200
numOver <- nrow(inter_item_timings_new[inter_item_timings_new$irt > gmax,])
numUnder <- nrow(inter_item_timings_new[inter_item_timings_new$irt < gmin,])

data <- droplevels(subset(
  inter_item_timings_new, 
  isFiller==F & irt > gmin & irt < gmax
))

# OR winsorize all irt by participant?
data<-transform(
  data,
  winsrdIRT = ave(irt,participant,FUN=winsor)
)

# for Martin...
# write_csv2(data,"csvs/irt-working.csv")

# preserve data before attrition
irt_no_excl <-data

# attritionize prep
expdata <- subset(data, !isFiller)
mitable <- aggregate(irt ~ condition + item, data=na.omit(expdata), mean)
sbjmean <- aggregate(irt ~ participant, data=na.omit(expdata), mean)
maxmiss = 1
misstab<-with(expdata, table(participant))
exclude_miss<-names(misstab[misstab<16-maxmiss])
exclude_mean<-sbjmean[sbjmean$irt<2400|sbjmean$irt>10000,]$participant
exclude_items<-mitable[mitable$`-Q -GP` > 7000,]$item
exclude<-append(exclude_miss,exclude_mean)
# attritionize do
irt_data <- droplevels(subset(
  expdata, 
  !participant %in% exclude
))

irt_data_itemsExcluded <- droplevels(subset(
  irt_data, 
  !item %in% exclude_items
))

# name swap!
inter_item_timings <- irt_data
inter_item_timings$inter_reading <- inter_item_timings$winsrdIRT
# transform!
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading)

# set order/group vals
order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))
morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)
inter_item_timings$Sorder <- 2
inter_item_timings$Sorder[inter_item_timings$Participant %in% order1] <- 1
inter_item_timings$Iorder <- getIOrd(
  inter_item_timings$item,inter_item_timings$Sorder
)
inter_item_timings$Sorder <- as.factor(inter_item_timings$Sorder)
inter_item_timings$list <- inter_item_timings$Participant %% 4
inter_item_timings$grp <- paste(
  inter_item_timings$Sorder,
  inter_item_timings$list,
  sep="-"
)
```

# Inter-item timing

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. Inter-reading time (IRT) is a measure of the amount of time between when a subject stops speaking after a cold reading and when they begin speaking for a previewed reading. 

> IRT = delay after the end of a cold reading and before the start of a previewed reading

Practically, this was done over `r nrow(inter_item_timings_new)` recordings (33 participants, 48 items = `r 33 * 48` pairs, with `r  33 * 48 - nrow(inter_item_timings_new)` missing data). This was measured using Google's WebRTC Voice Activity Detection (VAD) over .wav files that had been subjected to a high-pass filter with a low threshold of 0 to 500Hz[^hum] using the highest aggressiveness that yielded good results, depending on the noise level in the recording.

[^hum]: a low hum in the room needed to be accounted for; the exact algorithm is available at [github](https://gist.github.com/moui72/4ebc4eb8f69eb9fdb1cab160ce299675) (URL: bit.ly/2uMrcrG)

## Description and cleanup

The following section details the IRT data and the outlier removal and resulting participant attrition. 

## Distribution of IRTs, all participants

The overal mean IRT for all participants, all items (including fillers), and all conditions is `r gmean`ms (sd = `r gsd`). The highest IRT was `r paste(round(descrip$max,2))`ms.

The following histograms show the distribution of IRT across all items and all participants. In the second graph, overly short IRTs (shorter than `r gmin`ms; `r numUnder`[^lo] such data) are excluded. In the third, overly long (longer than `r gmax/1000`s; `r numOver` such data) and overly short IRTs are excluded.

The third graph represent what I will call data that has undergone "basic outlier removal."

[^lo]: This is ??% of the `r nrow(inter_item_timings_new)` total available data

```{r allhist}
allparts <- inter_item_timings_new
hist(na.omit(allparts$irt), breaks=16,xlab="Raw IRT",main="Raw IRT, all Parts")
```
```{r nolowhist}
hist(
  subset(allparts, irt > gmin)$irt, 
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short excluded"
)
```
```{r nolownohighhist}
hist(
  subset(allparts, irt > gmin & irt < gmax)$irt,
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short and long excluded"
)
```

IRTs were finally winsorized to lessen the impact of outliers.

> A question for DCB: should the IRTs be winsorized by a participant's mean/sd for all items (including fillers), or only by experimental item mean/sd? I assume the former in this document. Should this be done before or after basic outlier removal? I assume after in this document.

```{r winshist}
hist(
  data$winsrdIRT,
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short and long excluded"
)
```

## Missing data and attrition

Due to noise in recordings and/or technical difficulties during data collection, a number of IRTs are missing for experimental items in the data. The following table shows which participants are missing how many IRTs; ideally each would have 48 IRTs and 16 experimental IRTs.

```{r missingData}
kable(
  caption="Missing data, by participant",
  align="r",
  cbind(
    with(inter_item_timings_new, 48-table(participant)),
    with(
      inter_item_timings_new, 
      paste(round(100 * (table(participant)/48),2),"%",sep="")
    ),
    with(irt_no_excl, 16-table(participant)),
    with(irt_no_excl, paste(100 * (table(participant)/16),"%",sep=""))
  ), 
  col.names = c(
    "Missing IRTs", "Available % of IRTs", 
    "Missing experimental IRTs", 
    "Available % of experimental IRTs"
  )
)
np <- nrow(levels(inter_item_timings$Participant))
```

The `r length(exclude)` participants missing more than `r maxmiss` experimental IRTs (`r exclude_miss`) are excluded.

Subjects with overall mean IRTs that are very short (< 2200) or very long (> 10000) are also excluded (`r setdiff(exclude_mean,exclude_miss)`)

## Group sizes after attrition

The following table[^g1] shows how the participants are distributed across groupsafter attrition. Ideally, there would be 4 per group-order cell, but because of attrition the cells are uneven. Because regression is able to account for uneven groups, this defect will hopefully not play an important role in the analyses that follow.

[^g1]: There are 5 particpiants in Group 1, Split BA because I ran four participants per group-order, and then one extra who happened to be assigned to group 1, split BA; and by happenstance, none of the participants from that cell needed to be excluded.

```{r groupses}
groupses<-addmargins(with(inter_item_timings[!duplicated(inter_item_timings$Participant),],table(list,Sorder)))
row.names(groupses) <- c(paste("Group",1:4),"Split Total")
kable(groupses, caption="Group/order totals after attrition", 
  col.names = c("Split AB","Split BA","Group Total"))
```

## Distribution of experimental item IRT after attrition

The following histograms show the distribution of experimental item IRTs after attrition, and then the Winsorized IRTs, and finally the common log of winsorized IRTs, which are the shape of the data most suited to regression analyses.

```{r attritionhists}

hist(inter_item_timings$irt, breaks=8,xlab="raw IRT",main="Raw IRT")

hist(inter_item_timings$inter_reading, breaks=8,xlab="IRT",main="Winsorized IRT")

hist(inter_item_timings$inter_reading.log10, breaks=8,xlab="log10 IRT",main="Common log of winsorized IRT")
```

## Mean and SD of winsorized IRT by condition

If we assume that interrogative PP-attachment garden paths are easier to process as an interrogative than in the declarative, and that IRT represents how difficult a sentence is to process, we would expect the difference in mean IRT to be larger for declarative garden paths compared to declarative controls than for the same comparison of interrogatives.

The means of the Winsorized IRT by condition indeed show this pattern.

```{r gmeans}
groupedMeans<-inter_item_timings %>%
  group_by(GP_condition,Q_condition) %>%
  summarise(mean(irt))

decl <- diff(groupedMeans$`mean(irt)`[groupedMeans$Q_condition == FALSE])
int <- diff(groupedMeans$`mean(irt)`[groupedMeans$Q_condition ])
diffGPQ <- decl-int

groupedMeans$GP_condition <- ifelse(
  groupedMeans$GP_condition, "Garden path", "Non-garden path"
)
groupedMeans$Q_condition <- ifelse(
  groupedMeans$Q_condition, "Interrogative", "Declarative"
)
gm <- groupedMeans %>% spread(GP_condition,`mean(irt)`)
names(gm)[1] <- ""
kable(gm,caption="Mean experimental IRT by condition")
```

Boop

```{r interactionPlot, fig.fullwidth=TRUE}
ggplot(
  groupedMeans, 
  aes(x=fct_rev(GP_condition),y=`mean(irt)`,group=Q_condition,linetype=Q_condition)
) + 
  #s cale_x_discrete(limits=(levels(groupedMeans$GP_condition))) +
  ylim(4000,5000) +
  geom_line() +
  geom_point(stat="identity") +
  theme_classic(base_family = "Palatino",base_size = 12) + 
  theme(
    axis.title=element_text(size = "14",face="bold"),
    legend.title =element_text(size = "14",face="bold")
  ) +
  labs(x="", y="Mean IRT",linetype="Interrogative")

```
The difference in mean IRT acriss &plusmn; for declaratives is `r decl`; for interrogatives, it's `r int`. This is a difference of `r diffGPQ`, representing the impact of &plusmn;GP for +Q compared to -Q. This supports the hypothesis that garden paths are easier to comprehend when presented as interrogative. It is strange that the garden-path interrogatives appear to be comprehended more quickly than the non-garden path interrogatives. A possible explanation will be explored in the discussion section.

## Item and subject variation

There is variation across participants in terms of whether or not they show this pattern.

```{r meantable, echo=FALSE}
mstable <- aggregate(inter_reading ~ condition + participant, data=inter_item_timings, mean)
mitable <- aggregate(inter_reading ~ condition + item, data=na.omit(inter_item_timings), mean)

mitable<-spread(mitable, key=condition, value=inter_reading, fill = NA, convert = FALSE)
mstable<-spread(mstable, key=condition, value=inter_reading, fill = NA, convert = FALSE)

mstable$pattern <- mstable$`-Q +GP` - mstable$`-Q -GP` > mstable$`+Q -GP` - mstable$`+Q -GP` 
mitable$pattern <- mitable$`-Q +GP` - mitable$`-Q -GP` > mitable$`+Q -GP` - mitable$`+Q -GP`

binP <- binom.test(table(mstable$pattern)["TRUE"],nrow(mstable),alternative="less")
binI <- binom.test(table(mitable$pattern)["TRUE"],nrow(mitable),alternative="less")

```


## Number of participants who show predicted pattern

In the analyzed data,`r table(mstable$pattern)["TRUE"]` of `r nrow(mstable)` participants show the expected pattern. 

```{r meansbyp}
kable(mstable, caption="Mean IRT by condition and participant")
```

## Number of items that show predicted pattern

For items, `r table(mitable$pattern)["TRUE"]` of `r nrow(mitable)` show the pattern. 

```{r meansbyi}
kable(mitable, caption="Mean IRT by condition and item")
```

# Analyses

The following models explore the effect of garden path (&plusmn;GP) and interrogativeness (&plusmn;Q) on IRT.

## Regression analyses

Regression models with fixed effects of &plusmn;GP and &plusmn;Q were run, one including the interaction of &plusmn;GP and &plusmn;Q and one without the interaction term. Both included random effects for item and participant.

Models with random slopes for GP, Q, and their interaction for both error terms fails to converge. A model with random slopes for just GP and Q ain effects likewise fails to converge. Models without random slopes of fixed effects were used.

```{r lmerfull}
full <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | item) +
  (1  | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | item) +
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
irt.compared <- anova(full,no_interaction)
```
```{r results="asis",fig.fullwidth=TRUE}
stargazer(full,no_interaction,header=F,type="latex",covariate.labels = c("Garden path","Interrogative","Interaction"),dep.var.labels = "Common log of IRT",title = "Mixed effects model")
```

The interaction model represents a better fit; the non-interaction model represents a singular fit that is worse overall  (&Chi;^2^ = `r round(irt.compared$Chisq[2],3)`, p < `r round(irt.compared["Pr(>Chisq)"],2)[2,1]`). This supports the hypothesis and the earlier observation over the means that garden paths are more difficult as declaratives than interrogatives.

The relevance of random effects were also tested, by comparing models that exclude each to the model with both random effects (I call this the "full model" in what follows).

```{r lmernorand}
no_item <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_item_no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_participant <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | item),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_participant_no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | item),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_random = lm(  
  inter_reading.log10 ~ 
  GP_condition + Q_condition,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
irt.noParticipant.compared <- anova(full,no_participant)
irt.noItem.compared <-anova(full,no_item)
irt.norandom.compared <-anova(full,no_random)
irt.norandom2noitem.compared <-anova(no_item,no_random)
```

Removing the random effect of item does not degrade the model in a stastically significant way (AIC~full model~ = -305; AIC~no item error~ = -307; -&Chi;^2^ = `r round(irt.noItem.compared$Chisq[2],2)`, p = `r round( irt.noItem.compared["Pr(>Chisq)"][2,1],2)`), but removing the random effect of participant does (AIC~full model~ = -305; AIC~no participant error~ = 47; &Chi;^2^ = `r round(irt.noParticipant.compared$Chisq[2],2)`, p = `r round( irt.noParticipant.compared["Pr(>Chisq)"][2,1],2)`). The model with no random effects is worse than both the full model and the model with only item removed. Ultimately, it's difficult to select between the full model and the "no item" model, as both offer strong fits with more or less the same outcome.

<!--chapter:end:irt-desc3-notoc.Rmd-->

---
title: "Description of Inter-Item Timings (IRTs)"
author: "Tyler Peckenpaugh"
date: "3/29/2019"
output:
  tufte::tufte_html: 
    tufte_features: ["fonts", "italics"]
    toc: True
  tufte::tufte_handout: 
    toc: True  
    latex_engine: xelatex

---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3)
library(readr)
library(knitr)
library(kableExtra)
library(pander)
library(lme4)
library(lmerTest)
library(sjPlot) # table functions
library(lattice)
library(psych)
library(geepack)
library(tidyr)
library(dplyr)
library(ggplot2)

getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

# load file, set columns
inter_item_timings_new <- read_csv("csvs/irt-rvad-all-48k-2019-04-03_17h03m24s.csv")
inter_item_timings_new$GP_condition <- inter_item_timings_new$Condition_GP
inter_item_timings_new$Q_condition <- inter_item_timings_new$Condition_Q
inter_item_timings_new$Condition_Q <- NULL
inter_item_timings_new$Condition_GP <- NULL

# remove 0 irts
zeros<-subset(inter_item_timings_new,irt==0)
inter_item_timings_new<-subset(inter_item_timings_new,irt>0)

# generate condition column for ease of display
inter_item_timings_new$condition <- paste(
  ifelse(inter_item_timings_new$Q_condition,"+Q","-Q"),
  ifelse(
    inter_item_timings_new$isFiller,
    ifelse(inter_item_timings_new$GP_condition,"+PP","-PP"),
    ifelse(inter_item_timings_new$GP_condition,"+GP","-GP")
  )
)

# make lowercase columns
inter_item_timings_new$participant <- as.factor(inter_item_timings_new$Participant)
inter_item_timings_new$item <- as.factor(inter_item_timings_new$Item)

# basic outlier removal
descrip <- describe(inter_item_timings_new$irt)
gmean <- round(descrip$mean,2)
gsd <- round(descrip$sd,2)
QS<-quantile(inter_item_timings_new$irt,c(.02,.05,.1,.9,.95,.98))
cutoff=5
gmax <- QS[paste(100-cutoff,"%",sep="")]
gmin <- QS[paste(cutoff,"%",sep="")]
numOver <- nrow(inter_item_timings_new[inter_item_timings_new$irt > gmax,])
numUnder <- nrow(inter_item_timings_new[inter_item_timings_new$irt < gmin,])

data <- droplevels(subset(
  inter_item_timings_new, 
  !isFiller==T & irt > gmin & irt < gmax
))

# get only experimental items
allparts <- droplevels(subset(inter_item_timings_new, !isFiller==T))

# OR winsorize all irt by participant?
data<-transform(
  data,
  winsrdIRT = ave(irt,participant,FUN=winsor)
)

# for Martin...
# write_csv2(data,"csvs/irt-working.csv")

# preserve data before attrition
irt_no_excl <-data

# attritionize prep
expdata <- subset(data, !isFiller)
mitable <- aggregate(irt ~ condition + item, data=na.omit(expdata), mean)
sbjmean <- aggregate(irt ~ participant, data=na.omit(expdata), mean)
maxmiss = 3
misstab<-with(expdata, table(participant))
exclude_miss<-names(misstab[misstab<16-maxmiss])
exclude_mean<-sbjmean[sbjmean$irt<2400|sbjmean$irt>10000,]$participant
exclude_items<-mitable[mitable$`-Q -GP` > 7000,]$item
exclude<-append(exclude_miss,exclude_mean)
# attritionize do
irt_data <- droplevels(subset(
  expdata, 
  !participant %in% exclude
))

irt_data_itemsExcluded <- droplevels(subset(
  irt_data, 
  !item %in% exclude_items
))

# name swap!
inter_item_timings <- irt_data
inter_item_timings$inter_reading <- inter_item_timings$winsrdIRT
# transform!
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading)

# set order/group vals
order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))
morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)
inter_item_timings$Sorder <- 2
inter_item_timings$Sorder[inter_item_timings$Participant %in% order1] <- 1
inter_item_timings$Iorder <- getIOrd(
  inter_item_timings$item,inter_item_timings$Sorder
)
inter_item_timings$Sorder <- as.factor(inter_item_timings$Sorder)
inter_item_timings$list <- inter_item_timings$Participant %% 4
inter_item_timings$grp <- paste(
  inter_item_timings$Sorder,
  inter_item_timings$list,
  sep="-"
)
```

# Inter-item timing

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. Inter-reading time (IRT) is a measure of the amount of time between when a subject stops speaking after a cold reading and when they begin speaking for a previewed reading. 

> IRT = delay after the end of a cold reading and before the start of a previewed reading

Practically, this was done over `r nrow(inter_item_timings_new)` recordings (33 participants, 48 items = `r 33 * 48` pairs, with `r  33 * 48 - nrow(inter_item_timings_new)` missing data). This was measured using Google's WebRTC Voice Activity Detection (VAD) over .wav files that had been subjected to a high-pass filter with a low threshold of 0 to 500Hz[^hum] using the highest aggressiveness that yielded good results, depending on the noise level in the recording.

[^hum]: a low hum in the room needed to be accounted for; the exact algorithm is available at [github](https://gist.github.com/moui72/4ebc4eb8f69eb9fdb1cab160ce299675) (URL: bit.ly/2uMrcrG)

## Description and cleanup

The following section details the IRT data and the outlier removal and resulting participant attrition. 

## Distribution of IRTs, all participants

The overal mean IRT for all participants, all items (including fillers), and all conditions is `r gmean`ms (sd = `r gsd`). The highest IRT was `r paste(round(descrip$max,2))`ms.

The following histograms show the distribution of IRT across all items and all participants. In the second graph, overly short IRTs (shorter than `r gmin`ms; `r numUnder`[^lo] such data) are excluded. In the third, overly long (longer than `r paste(gmax)`; `r numOver` such data) and overly short IRTs are excluded.

The third graph represent what I will call data that has undergone "basic outlier removal."

[^lo]: This is `r cutoff`% of the `r nrow(inter_item_timings_new)` total data

```{r allhist}
allparts <- inter_item_timings_new
hist(na.omit(allparts$irt), breaks=16,xlab="Raw IRT",main="Raw IRT, all Parts")
```
```{r nolowhist}
hist(
  subset(allparts, irt > gmin)$irt, 
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short excluded"
)
```
```{r nolownohighhist}
hist(
  subset(allparts, irt > gmin & irt < gmax)$irt,
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short and long excluded"
)
```


IRTs were finally winsorized to lessen the impact of outliers[^wins].

[^wins]: A question for DCB: should the IRTs be winsorized by a participant's mean/sd for all items (including fillers), or only by experimental item mean/sd? I assume the former in this document. Should this be done before or after basic outlier removal? I assume after in this document.

```{r winshist}
hist(
  data$winsrdIRT,
  breaks=16,
  xlab="Raw IRT",
  main="Raw IRT, all Parts, short and long excluded"
)
```

## Missing data and attrition

Due to noise in recordings and/or technical difficulties during data collection, a number of IRTs are missing for experimental items in the data. The following table shows which participants are missing how many IRTs; ideally each would have 48 IRTs and 16 experimental IRTs.

```{r missingData}
kable(
  caption="Missing data, by participant",
  align="r",
  cbind(
    with(inter_item_timings_new, 48-table(participant)),
    with(
      inter_item_timings_new, 
      paste(round(100 * (table(participant)/48),2),"%",sep="")
    ),
    with(irt_no_excl, 16-table(participant)),
    with(irt_no_excl, paste(100 * (table(participant)/16),"%",sep=""))
  ), 
  col.names = c(
    "Missing IRTs", "Available % of IRTs", 
    "Missing experimental IRTs", 
    "Available % of experimental IRTs"
  )
)
np <- nrow(levels(inter_item_timings$Participant))
```

The `r length(exclude)` participants missing more than `r maxmiss` experimental IRTs (`r exclude_miss`) are excluded.

Subjects with overall mean IRTs that are very short (< 2200) or very long (> 10000) are also excluded (`r setdiff(exclude_mean,exclude_miss)`)

## Group sizes after attrition

The following table[^g1] shows how the participants are distributed across groupsafter attrition. Ideally, there would be 4 per group-order cell, but because of attrition the cells are uneven. Because regression is able to account for uneven groups, this defect will hopefully not play an important role in the analyses that follow.

[^g1]: There are 5 particpiants in Group 1, Split BA because I ran four participants per group-order, and then one extra who happened to be assigned to group 1, split BA; and by happenstance, none of the participants from that cell needed to be excluded.

```{r groupses}
groupses<-addmargins(with(inter_item_timings[!duplicated(inter_item_timings$Participant),],table(list,Sorder)))
row.names(groupses) <- c(paste("Group",1:4),"Split Total")
kable(groupses, caption="Group/order totals after attrition", 
  col.names = c("Split AB","Split BA","Group Total"))
```
## Distribution of experimental item IRT after attrition

The following histograms show the distribution of experimental item IRTs after attrition, and then the Winsorized IRTs, and finally the common log of winsorized IRTs, which are the shape of the data most suited to regression analyses.

```{r attritionhists}

hist(inter_item_timings$irt, breaks=8,xlab="raw IRT",main="Raw IRT")

hist(inter_item_timings$inter_reading, breaks=8,xlab="IRT",main="Winsorized IRT")

hist(inter_item_timings$inter_reading.log10, breaks=8,xlab="log10 IRT",main="Common log of winsorized IRT")
```

## Mean and SD of winsorized IRT by condition

If we assume that interrogative PP-attachment garden paths are easier to process as an interrogative than in the declarative, and that IRT represents how difficult a sentence is to process, we would expect the difference in mean IRT to be larger for declarative garden paths compared to declarative controls than for the same comparison of interrogatives.
```{r sdtable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

sdtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, sd))

ctable <- rbind(mtable,sdtable)
row.names(ctable) <- c("Mean", "SD")
decl <- round(mtable["-Q +GP"] - mtable["-Q -GP"],2)
int <- round(mtable["+Q +GP"] - mtable["+Q -GP"],2)
diffGPQ <- decl - int
```
```{r sdtableOut}
kable(t(ctable), caption="Condition means")
```

The means of the Winsorized IRT by condition indeed show this pattern.

```{r interactionPlot, fig.cap="Mean experimental IRT by condition"}
groupedMeans<-inter_item_timings %>%
  group_by(GP_condition,Q_condition) %>%
  summarise(mean(irt))
groupedMeans$GP_condition <- ifelse(
  groupedMeans$GP_condition, "Garden path", "Non-garden path"
)
groupedMeans$Q_condition <- ifelse(
  groupedMeans$Q_condition, "Interrogative", "Declarative"
)
ggplot(
  groupedMeans, 
  aes(x=GP_condition,y=`mean(irt)`,group=Q_condition,linetype=Q_condition)
) + ylim(4000,6000) +
  geom_line() +
  geom_point(stat="identity") +
  theme_classic(base_family = "Palatino",base_size = 12) + 
  theme(
    axis.title=element_text(size = "14",face="bold"),
    legend.title =element_text(size = "14",face="bold")
  ) +
  labs(x="", y="Mean IRT",linetype="Interrogative")

```
The difference in mean IRT acriss &plusmn; for declaratives is `r decl`; for interrogatives, it's `r int`. This is a difference of `r diffGPQ`, representing the impact of &plusmn;GP for +Q compared to -Q. This supports the hypothesis that garden paths are easier to comprehend when presented as interrogative. It is strange that the garden-path interrogatives appear to be comprehended more quickly than the non-garden path interrogatives. A possible explanation will be explored in the discussion section.

## Item and subject variation

There is variation across participants in terms of whether or not they show this pattern.

```{r meantable, echo=FALSE}
mstable <- aggregate(inter_reading ~ condition + participant, data=inter_item_timings, mean)
mitable <- aggregate(inter_reading ~ condition + item, data=na.omit(inter_item_timings), mean)

mitable<-spread(mitable, key=condition, value=inter_reading, fill = NA, convert = FALSE)
mstable<-spread(mstable, key=condition, value=inter_reading, fill = NA, convert = FALSE)

mstable$pattern <- mstable$`-Q +GP` - mstable$`-Q -GP` > mstable$`+Q -GP` - mstable$`+Q -GP` 
mitable$pattern <- mitable$`-Q +GP` - mitable$`-Q -GP` > mitable$`+Q -GP` - mitable$`+Q -GP`

binP <- binom.test(table(mstable$pattern)["TRUE"],nrow(mstable),alternative="less")
binI <- binom.test(table(mitable$pattern)["TRUE"],nrow(mitable),alternative="less")

```


## Number of participants who show predicted pattern

In the analyzed data,`r table(mstable$pattern)["TRUE"]` of `r nrow(mstable)` participants show the expected pattern. 

<!--A one-tailed exact binomial test against the null hyopthesis that the true probability of the pattern holding across participants is less than 50% is not significant is not significant at the p < 0.05 level (p = `r round(1-binP$p.value,2)`).-->

```{r meansbyp}
kable(mstable, caption="Mean IRT by condition and participant")
```

## Number of items that show predicted pattern

For items, `r table(mitable$pattern)["TRUE"]` of `r nrow(mitable)` show the pattern. 
<!--A binomial against the null hyopthesis that the true probability of the pattern holding across items is less than 50% is satistically significant (p = `r round( 1-binI$p.value,2)`).-->


```{r meansbyi}
kable(mitable, caption="Mean IRT by condition and item")
```
# Analyses

The following models explore the effect of garden path (&plusmn;GP) and interrogativeness (&plusmn;Q) on IRT.

## Regression analyses

Regression models with fixed effects of &plusmn;GP and &plusmn;Q were run, one including the interaction of &plusmn;GP and &plusmn;Q and one without the interaction term. Both included random effects for item and participant.

Models with random slopes for GP, Q, and their interaction for both error terms fails to converge. A model with random slopes for just GP and Q ain effects likewise fails to converge. Models without random slopes of fixed effects were used.

```{r lmerfull}
full <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | item) +
  (1  | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | item) +
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
tab_model(full,no_interaction)
irt.compared <- anova(full,no_interaction)
```

The interaction model represents a better fit; the non-interaction model represents a singular fit that is worse overall  (&Chi;^2^ = `r round(irt.compared$Chisq[2],3)`, p < `r round(irt.compared["Pr(>Chisq)"],2)[2,1]`). This supports the hypothesis and the earlier observation over the means that garden paths are more difficult as declaratives than interrogatives.

The relevance of random effects were also tested, by comparing models that exclude each to the model with both random effects (I call this the "full model" in what follows).

```{r lmernorand}
no_item <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_item_no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | participant),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_participant <- lmer(
  inter_reading.log10 ~ 
  GP_condition * Q_condition + 
  (1 | item),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_participant_no_interaction <- lmer(
  inter_reading.log10 ~ 
  GP_condition + Q_condition + 
  (1 | item),
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
no_random = lm(  
  inter_reading.log10 ~ 
  GP_condition + Q_condition,
  REML=F,
  data = inter_item_timings,
  control = lmerControl(optCtrl = list(maxfun=2e20))
)
irt.noParticipant.compared <- anova(full,no_participant)
irt.noItem.compared <-anova(full,no_item)
irt.norandom.compared <-anova(full,no_random)
irt.norandom2noitem.compared <-anova(no_item,no_random)
```

```{r lmertable}
tab_model(no_item)
```

Removing the random effect of item does not degrade the model in a stastically significant way (AIC~full model~ = -305; AIC~no item error~ = -307; -&Chi;^2^ = `r round(irt.noItem.compared$Chisq[2],2)`, p = `r round( irt.noItem.compared["Pr(>Chisq)"][2,1],2)`), but removing the random effect of participant does (AIC~full model~ = -305; AIC~no participant error~ = 47; &Chi;^2^ = `r round(irt.noParticipant.compared$Chisq[2],2)`, p = `r round( irt.noParticipant.compared["Pr(>Chisq)"][2,1],2)`). The model with no random effects is worse than both the full model and the model with only item removed. Ultimately, it's difficult to select between the full model and the "no item" model, as both offer strong fits with more or less the same outcome.

<!--chapter:end:irt-desc3.Rmd-->

---
title: "LME Inter-Item Timing (winsorized)"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)
library(psych)


mean.sd <- function(x) c(mean = mean(x), sd = sd(x))
# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = TRUE
inter_item_timings_all <- read_csv("csvs/irt-20190318-151704.csv")


inter_item_timings_all$condition <- paste(ifelse(inter_item_timings_all$is_filler,ifelse(inter_item_timings_all$GP_condition,"+PP","-PP"),ifelse(inter_item_timings_all$GP_condition,"+GP","-GP")),ifelse(inter_item_timings_all$Q_condition,"+Q","-Q"))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading < 0] <- NA
inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading < 1] <- 1
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings_all$participant[inter_item_timings_all$participant == 108] <- 8

inter_item_timings_all<-transform(inter_item_timings_all,winsrdIRT = ave(inter_reading,participant,FUN=winsor))

inter_item_timings_all$raw_irt <- inter_item_timings_all$inter_reading
inter_item_timings_all$inter_reading <- inter_item_timings_all$winsrdIRT

inter_item_timings <- subset(inter_item_timings_all, Exp)

inter_item_timings$inter_reading_shift <- 1 + inter_item_timings$inter_reading 
inter_item_timings$inter_reading.ln <- log(inter_item_timings$inter_reading_shift)
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading_shift)
inter_item_timings$inter_reading.inverse <- 1/(inter_item_timings$inter_reading_shift)
inter_item_timings$inter_reading.sqred <- (inter_item_timings$inter_reading_shift)^2

gpInsensitive <- paste(c(1,12,14,15,19,2,20,203,21,210,22,4,6))

```



# Inter-item timing analyses

Mean inter-reading time (IRT) is a measure of the amount of time in ms between when a subject stops speaking during a cold reading and when they begin speaking for a previewed reading.

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. IRT is meant to represent their chosen preview time for the second reading.

## Mean and SD of IRT by condition

Mean inter-reading time (IRT) in ms

```{r meantable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

kable(mtable, align="r",col.names = c("mean")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

Standard deviation inter-reading time (IRT) in ms

```{r sdtable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, list("+GP"=GP_condition,"+Q"=Q_condition), sd))
row.names(mtable) <- c("-GP","+GP")
kable(mtable, align="r",col.names = c("-Q","+Q")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## boxplot of mean inter-item time by condition

Inter reading time (IRT) in ms

```{r echo=FALSE}
boxplot(inter_reading ~condition, main="plain IRT", col=c("white","lightgray"),inter_item_timings)

boxplot(inter_reading.ln ~ condition, main="natural log of IRT", col=c("white","lightgray"),inter_item_timings)
boxplot(inter_reading.inverse ~ condition,main="inverse of IRT", col=c("white","lightgray"),inter_item_timings)
boxplot(inter_reading.log10 ~ condition,main="common log of IRT", col=c("white","lightgray"),inter_item_timings)
boxplot(inter_reading.sqred ~ condition,main="IRT squared", col=c("white","lightgray"),inter_item_timings)

```
# Models

```{r lmerModel,echo=FALSE,include=FALSE}
if(refresh | !exists("models.timing")){
  models.timing <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt")){
  models.timingNoInt <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}

if(refresh | !exists("models.timing.Sense")){
  models.timing.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt.Sense")){
  models.timingNoInt.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingLn")){
  models.timingLn <- lmer(inter_reading.ln ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingInv")){
  models.timingInv <- lmer(inter_reading.inverse ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingLg10")){
  models.timingLg10 <- lmer(inter_reading.log10 ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingSq")){
  models.timingSq <- lmer(inter_reading.sqred ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
```
```{r assumptionChecks, include=FALSE, echo=FALSE}
# residuals
inter_item_timings$resids_main <- NA
inter_item_timings$resids_main[!is.na(inter_item_timings$inter_reading)] <- residuals(models.timing)
inter_item_timings$resids_main.abs <- abs(inter_item_timings$resids_main)
inter_item_timings$resids_main.sq <-inter_item_timings$resids_main.abs^2

# residuals (squared)
inter_item_timings$resids_mainSq <- NA
inter_item_timings$resids_mainSq[!is.na(inter_item_timings$inter_reading.sqred)] <- residuals(models.timingSq)
inter_item_timings$resids_mainSq.abs <- abs(inter_item_timings$resids_mainSq)
inter_item_timings$resids_mainSq.sq <-inter_item_timings$resids_mainSq.abs^2

# residuals (ln)
inter_item_timings$resids_mainLn <- NA
inter_item_timings$resids_mainLn[!is.na(inter_item_timings$inter_reading.ln)] <- residuals(models.timingLn)
inter_item_timings$resids_mainLn.abs <- abs(inter_item_timings$resids_mainLn)
inter_item_timings$resids_mainLn.sq <-inter_item_timings$resids_mainLn.abs^2

# residuals (inverse)
inter_item_timings$resids_mainInv <- NA
inter_item_timings$resids_mainInv[!is.na(inter_item_timings$inter_reading.inverse)] <- residuals(models.timingInv)
inter_item_timings$resids_mainInv.abs <- abs(inter_item_timings$resids_mainInv)
inter_item_timings$resids_mainInv.sq <-inter_item_timings$resids_mainInv.abs^2

# residuals (log10)
inter_item_timings$resids_mainLg10 <- NA
inter_item_timings$resids_mainLg10[!is.na(inter_item_timings$inter_reading.inverse)] <- residuals(models.timingLg10)
inter_item_timings$resids_mainLg10.abs <- abs(inter_item_timings$resids_mainLg10)
inter_item_timings$resids_mainLg10.sq <-inter_item_timings$resids_mainLg10.abs^2

# gp sense
sensitive_timings <- subset(inter_item_timings, !(participant %in% gpInsensitive))
sensitive_timings$resids_main[!is.na(sensitive_timings$inter_reading)] <- residuals(models.timing.Sense)
sensitive_timings$resids_main.abs <- abs(sensitive_timings$resids_main)
sensitive_timings$resids_main.sq <- sensitive_timings$resids_main.abs^2

# ANOVA of the squared residuals
timings_sq_resid <- lm(resids_main.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (Log10)
timings_sq_resid_log10 <- lm(resids_mainLg10.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (squared)
timings_sq_resid_sq <- lm(resids_mainSq.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (inverse)
timings_sq_resid_inv <- lm(resids_mainInv.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (ln)
timings_sq_resid_ln <- lm(resids_mainLn.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (gp-sensitive)
sens_timings_sq_resid <- lm(resids_main.sq ~ participant, data=sensitive_timings)
```



## All participants

These models use all 32 participants

### Full model

```{r full}
summary(models.timing)
```

### Full model (natural log)

```{r fullln}
summary(models.timingLn)
```

### Full model (common log)

```{r fulll10}
summary(models.timingLg10)
```

### Full model (inverse)

```{r fullinv}
summary(models.timingInv)
```

### Full model (squared)

```{r fullsq}
summary(models.timingSq)
```

### Without interacton 

```{r noInt}
summary(models.timingNoInt)
```

## Only "gp-sensitive"
The following models exclude all participants whose mean inter-item reading time for `+GP` items is less than for `-GP` items

### With interaction
```{r gpSense}
summary(models.timing.Sense)
```

### Without interaction
```{r gpSenseNoInt}
summary(models.timingNoInt.Sense)

```

# Checking assumptions

The following checks assumptions about the data

## Homogeneity of variance

Anova of squared residuals (full model) by participant. If the data fit the assumption, we expect no statistical significance.

### All Ps

```{r homovar}
# all participants
anova(timings_sq_resid) 
```

### All Ps (natural log)

```{r homovarLn}
# all participants
anova(timings_sq_resid_ln) 
```

### All Ps (squared)

```{r homovarSq}
# all participants
anova(timings_sq_resid_sq) 
```

### All Ps (inverse)

```{r homovarInv}
# all participants
anova(timings_sq_resid_inv) 
```

### All Ps (Log10)

```{r homovarLg10}
# all participants
anova(timings_sq_resid_log10) 
```

### Only GP-sense

```{r homovarSense}
# GP-sensitive only
anova(sens_timings_sq_resid)
```

## Normal distribution of residuals

QQ plots of models with interation

### All participants

Outcome is plain IRT
```{r normdres}
qqmath(models.timing, id=0.05)
```

### All participants (Natural log)

Outcome is plain natural log of IRT
```{r normdresLn}
qqmath(models.timingLn, id=0.05)
```

### All participants (Log 10)

Outcome is common log of IRT
```{r normdresLg10}
qqmath(models.timingLg10, id=0.05)
```

### All participants (Inverse)

Outcome is inverse of IRT (i.e. 1/IRT)
```{r normdresInverse}
qqmath(models.timingInv, id=0.05)
```

### All participants (Squared)

Outcome is IRT squared
```{r normdresSq}
qqmath(models.timingSq, id=0.05)
```

### Only GP-sensitive participants

Outcome is plain IRT, but uses subset of participants sensitive to GP
```{r normdresSense}
qqmath(models.timing.Sense, id=0.05)
```

## Linearity

Plots of residuals vs. observed

### All Ps

Plain IRT
```{r lin}
plot(resid(models.timing),na.omit(inter_item_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

### All Ps (nautral log)

Natural log of IRT
```{r linLn}
plot(resid(models.timingLn),na.omit(inter_item_timings$inter_reading.ln),xlab="Residuals",ylab="Observed values")
```

### All Ps (log10)

Common log of IRT
```{r linLg10}
plot(resid(models.timingLg10),na.omit(inter_item_timings$inter_reading.log10),xlab="Residuals",ylab="Observed values")
```

### All Ps (squared)

IRT squared
```{r linSq}
plot(resid(models.timingSq),na.omit(inter_item_timings$inter_reading.sqred),xlab="Residuals",ylab="Observed values")
```

### All Ps (Inverse)

1/IRT
```{r linInv}
plot(resid(models.timingInv),na.omit(inter_item_timings$inter_reading.inverse),xlab="Residuals",ylab="Observed values")
```

### GP-sensitive only

Subset of subjects sensitive to GP
```{r linSense}
plot(resid(models.timing.Sense),na.omit(sensitive_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

<!--chapter:end:lmer-combined-winsorized.Rmd-->

---
title: "LME Inter-Item Timing (winsorized)"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)
library(psych)


mean.sd <- function(x) c(mean = mean(x), sd = sd(x))
# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = TRUE
inter_item_timings_all <- read_csv("csvs/irt-20190318-151704.csv")


inter_item_timings_all$condition <- paste(ifelse(inter_item_timings_all$is_filler,ifelse(inter_item_timings_all$GP_condition,"+PP","-PP"),ifelse(inter_item_timings_all$GP_condition,"+GP","-GP")),ifelse(inter_item_timings_all$Q_condition,"+Q","-Q"))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading < 0] <- NA
inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading < 1] <- 1
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings_all$participant[inter_item_timings_all$participant == 108] <- 8

# inter_item_timings_all<-transform(inter_item_timings_all,winsrdIRT = ave(inter_reading,participant,FUN=winsor))
# 
# inter_item_timings_all$raw_irt <- inter_item_timings_all$inter_reading
# inter_item_timings_all$inter_reading <- inter_item_timings_all$winsrdIRT

inter_item_timings <- subset(inter_item_timings_all, Exp)

inter_item_timings$inter_reading_shift <- 1 + inter_item_timings$inter_reading 
inter_item_timings$inter_reading.ln <- log(inter_item_timings$inter_reading_shift)
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading_shift)
inter_item_timings$inter_reading.inverse <- 1/(inter_item_timings$inter_reading_shift)
inter_item_timings$inter_reading.sqred <- (inter_item_timings$inter_reading_shift)^2

gpInsensitive <- paste(c(1,12,14,15,19,2,20,203,21,210,22,4,6))

```



# Inter-item timing analyses

Mean inter-reading time (IRT) is a measure of the amount of time in ms between when a subject stops speaking during a cold reading and when they begin speaking for a previewed reading.

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. IRT is meant to represent their chosen preview time for the second reading.

## Mean and SD of IRT by condition

Mean inter-reading time (IRT) in ms

```{r meantable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

kable(mtable, align="r",col.names = c("mean")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

Standard deviation inter-reading time (IRT) in ms

```{r sdtable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, list("+GP"=GP_condition,"+Q"=Q_condition), sd))
row.names(mtable) <- c("-GP","+GP")
kable(mtable, align="r",col.names = c("-Q","+Q")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## boxplot of mean inter-item time by condition

Inter reading time (IRT) in ms

```{r echo=FALSE}
boxplot(inter_reading ~condition, main="plain IRT", col=c("white","lightgray"),inter_item_timings)

boxplot(inter_reading.ln ~ condition, main="natural log of IRT", col=c("white","lightgray"),inter_item_timings)
boxplot(inter_reading.inverse ~ condition,main="inverse of IRT", col=c("white","lightgray"),inter_item_timings)
boxplot(inter_reading.log10 ~ condition,main="common log of IRT", col=c("white","lightgray"),inter_item_timings)
boxplot(inter_reading.sqred ~ condition,main="IRT squared", col=c("white","lightgray"),inter_item_timings)

```
# Models

```{r lmerModel,echo=FALSE,include=FALSE}
if(refresh | !exists("models.timing")){
  models.timing <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt")){
  models.timingNoInt <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}

if(refresh | !exists("models.timing.Sense")){
  models.timing.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt.Sense")){
  models.timingNoInt.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingLn")){
  models.timingLn <- lmer(inter_reading.ln ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingInv")){
  models.timingInv <- lmer(inter_reading.inverse ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingLg10")){
  models.timingLg10 <- lmer(inter_reading.log10 ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingSq")){
  models.timingSq <- lmer(inter_reading.sqred ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
```
```{r assumptionChecks, include=FALSE, echo=FALSE}
# residuals
inter_item_timings$resids_main <- NA
inter_item_timings$resids_main[!is.na(inter_item_timings$inter_reading)] <- residuals(models.timing)
inter_item_timings$resids_main.abs <- abs(inter_item_timings$resids_main)
inter_item_timings$resids_main.sq <-inter_item_timings$resids_main.abs^2

# residuals (squared)
inter_item_timings$resids_mainSq <- NA
inter_item_timings$resids_mainSq[!is.na(inter_item_timings$inter_reading.sqred)] <- residuals(models.timingSq)
inter_item_timings$resids_mainSq.abs <- abs(inter_item_timings$resids_mainSq)
inter_item_timings$resids_mainSq.sq <-inter_item_timings$resids_mainSq.abs^2

# residuals (ln)
inter_item_timings$resids_mainLn <- NA
inter_item_timings$resids_mainLn[!is.na(inter_item_timings$inter_reading.ln)] <- residuals(models.timingLn)
inter_item_timings$resids_mainLn.abs <- abs(inter_item_timings$resids_mainLn)
inter_item_timings$resids_mainLn.sq <-inter_item_timings$resids_mainLn.abs^2

# residuals (inverse)
inter_item_timings$resids_mainInv <- NA
inter_item_timings$resids_mainInv[!is.na(inter_item_timings$inter_reading.inverse)] <- residuals(models.timingInv)
inter_item_timings$resids_mainInv.abs <- abs(inter_item_timings$resids_mainInv)
inter_item_timings$resids_mainInv.sq <-inter_item_timings$resids_mainInv.abs^2

# residuals (log10)
inter_item_timings$resids_mainLg10 <- NA
inter_item_timings$resids_mainLg10[!is.na(inter_item_timings$inter_reading.inverse)] <- residuals(models.timingLg10)
inter_item_timings$resids_mainLg10.abs <- abs(inter_item_timings$resids_mainLg10)
inter_item_timings$resids_mainLg10.sq <-inter_item_timings$resids_mainLg10.abs^2

# gp sense
sensitive_timings <- subset(inter_item_timings, !(participant %in% gpInsensitive))
sensitive_timings$resids_main[!is.na(sensitive_timings$inter_reading)] <- residuals(models.timing.Sense)
sensitive_timings$resids_main.abs <- abs(sensitive_timings$resids_main)
sensitive_timings$resids_main.sq <- sensitive_timings$resids_main.abs^2

# ANOVA of the squared residuals
timings_sq_resid <- lm(resids_main.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (Log10)
timings_sq_resid_log10 <- lm(resids_mainLg10.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (squared)
timings_sq_resid_sq <- lm(resids_mainSq.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (inverse)
timings_sq_resid_inv <- lm(resids_mainInv.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (ln)
timings_sq_resid_ln <- lm(resids_mainLn.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals (gp-sensitive)
sens_timings_sq_resid <- lm(resids_main.sq ~ participant, data=sensitive_timings)
```



## All participants

These models use all 32 participants

### Full model

```{r full}
summary(models.timing)
```

### Full model (natural log)

```{r fullln}
summary(models.timingLn)
```

### Full model (common log)

```{r fulll10}
summary(models.timingLg10)
```

### Full model (inverse)

```{r fullinv}
summary(models.timingInv)
```

### Full model (squared)

```{r fullsq}
summary(models.timingSq)
```

### Without interacton 

```{r noInt}
summary(models.timingNoInt)
```

## Only "gp-sensitive"
The following models exclude all participants whose mean inter-item reading time for `+GP` items is less than for `-GP` items

### With interaction
```{r gpSense}
summary(models.timing.Sense)
```

### Without interaction
```{r gpSenseNoInt}
summary(models.timingNoInt.Sense)

```

# Checking assumptions

The following checks assumptions about the data

## Homogeneity of variance

Anova of squared residuals (full model) by participant. If the data fit the assumption, we expect no statistical significance.

### All Ps

```{r homovar}
# all participants
anova(timings_sq_resid) 
```

### All Ps (natural log)

```{r homovarLn}
# all participants
anova(timings_sq_resid_ln) 
```

### All Ps (squared)

```{r homovarSq}
# all participants
anova(timings_sq_resid_sq) 
```

### All Ps (inverse)

```{r homovarInv}
# all participants
anova(timings_sq_resid_inv) 
```

### All Ps (Log10)

```{r homovarLg10}
# all participants
anova(timings_sq_resid_log10) 
```

### Only GP-sense

```{r homovarSense}
# GP-sensitive only
anova(sens_timings_sq_resid)
```

## Normal distribution of residuals

QQ plots of models with interation

### All participants

Outcome is plain IRT
```{r normdres}
qqmath(models.timing, id=0.05)
```

### All participants (Natural log)

Outcome is plain natural log of IRT
```{r normdresLn}
qqmath(models.timingLn, id=0.05)
```

### All participants (Log 10)

Outcome is common log of IRT
```{r normdresLg10}
qqmath(models.timingLg10, id=0.05)
```

### All participants (Inverse)

Outcome is inverse of IRT (i.e. 1/IRT)
```{r normdresInverse}
qqmath(models.timingInv, id=0.05)
```

### All participants (Squared)

Outcome is IRT squared
```{r normdresSq}
qqmath(models.timingSq, id=0.05)
```

### Only GP-sensitive participants

Outcome is plain IRT, but uses subset of participants sensitive to GP
```{r normdresSense}
qqmath(models.timing.Sense, id=0.05)
```

## Linearity

Plots of residuals vs. observed

### All Ps

Plain IRT
```{r lin}
plot(resid(models.timing),na.omit(inter_item_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

### All Ps (nautral log)

Natural log of IRT
```{r linLn}
plot(resid(models.timingLn),na.omit(inter_item_timings$inter_reading.ln),xlab="Residuals",ylab="Observed values")
```

### All Ps (log10)

Common log of IRT
```{r linLg10}
plot(resid(models.timingLg10),na.omit(inter_item_timings$inter_reading.log10),xlab="Residuals",ylab="Observed values")
```

### All Ps (squared)

IRT squared
```{r linSq}
plot(resid(models.timingSq),na.omit(inter_item_timings$inter_reading.sqred),xlab="Residuals",ylab="Observed values")
```

### All Ps (Inverse)

1/IRT
```{r linInv}
plot(resid(models.timingInv),na.omit(inter_item_timings$inter_reading.inverse),xlab="Residuals",ylab="Observed values")
```

### GP-sensitive only

Subset of subjects sensitive to GP
```{r linSense}
plot(resid(models.timing.Sense),na.omit(sensitive_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

<!--chapter:end:lmer-combined.Rmd-->

---
title: "LME Inter-Item Timing"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)

# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = TRUE

inter_item_timings_all <- read_csv("dissertation/csvs/inter_item_timings.csv", 
    col_types = cols(item = col_character(), 
        participant = col_character()))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading <0] <- NA
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings <- subset(inter_item_timings_all, Exp & participant != "108")

gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```



# Inter-item timing analyses

## boxplot of mean inter-item time by condition
```{r echo=FALSE}
boxplot(inter_reading ~ GP_condition*Q_condition, col=c("white","lightgray"),inter_item_timings,names=c("-GP -Q", "+GP -Q", "-GP +Q", "+GP +Q"))
```
```{r lmerModel,echo=FALSE}
if(refresh | !exists("models.timing")){
  models.timing <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt")){
  models.timingNoInt <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}

if(refresh | !exists("models.timing.Sense")){
  models.timing.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt.Sense")){
  models.timingNoInt.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
```
```{r assumptionChecks, include=FALSE, echo=FALSE}
inter_item_timings$resids_main <- NA
inter_item_timings$resids_main[!is.na(inter_item_timings$inter_reading)] <- residuals(models.timing)
inter_item_timings$resids_main.abs <- abs(inter_item_timings$resids_main)
inter_item_timings$resids_main.sq <-inter_item_timings$resids_main.abs^2
sensitive_timings <- subset(inter_item_timings, !(participant %in% gpInsensitive))
sensitive_timings$resids_main[!is.na(sensitive_timings$inter_reading)] <- residuals(models.timing.Sense)
sensitive_timings$resids_main.abs <- abs(sensitive_timings$resids_main)
sensitive_timings$resids_main.sq <- sensitive_timings$resids_main.abs^2

# ANOVA of the squared residuals
timings_sq_resid <- lm(resids_main.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals
sens_timings_sq_resid <- lm(resids_main.sq ~ participant, data=sensitive_timings)
```

# Models

## All participants
These models use all 32 participants

### Full model
```{r full}
summary(models.timing)
```

### Without interacton 
```{r noInt}
summary(models.timingNoInt)
```

## Only "gp-sensitive"
The following models exclude all participants whose mean inter-item reading time for `+GP` items is less than for `-GP` items

### With interaction
```{r gpSense}
summary(models.timing.Sense)
```

### Without interaction
```{r gpSenseNoInt}
summary(models.timingNoInt.Sense)

```
# Checking assumptions
The following checks assumptions about the data

## Homogeneity of variance
Anova of squared residuals (full model) by participant 

### All Ps
```{r homovar}
# all participants
anova(timings_sq_resid) 
```

### Only GP-sense
```{r homovarSense}
# GP-sensitive only
anova(sens_timings_sq_resid)
```

## Normal distribution of residuals
QQ plots of full models

### All participants
```{r normdres}
qqmath(models.timing, id=0.05)
```

### Only GP-sensitive participants
```{r normdresSense}
qqmath(models.timing.Sense, id=0.05)
```

## Linearity
Plots of residuals vs. observed

### All Ps
```{r lin}
plot(resid(models.timing),na.omit(inter_item_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

### GP-sensitive only
```{r linsense}
plot(resid(models.timing.Sense),na.omit(sensitive_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

<!--chapter:end:lmer.Rmd-->

---
title: "LME Inter-Item Timing (winsorized)"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)
library(psych)
library(geepack)
library(tidyr)
getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

mean.sd <- function(x) c(mean = mean(x), sd = sd(x))
# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = TRUE
inter_item_timings_all <- read_csv("csvs/irt-20190320-142840.csv")


inter_item_timings_all$condition <- paste(ifelse(inter_item_timings_all$is_filler,ifelse(inter_item_timings_all$GP_condition,"+PP","-PP"),ifelse(inter_item_timings_all$GP_condition,"+GP","-GP")),ifelse(inter_item_timings_all$Q_condition,"+Q","-Q"))


inter_item_timings_all<-transform(inter_item_timings_all,winsrdIRT = ave(inter_reading,participant,FUN=winsor))

inter_item_timings_all$raw_irt <- inter_item_timings_all$inter_reading
inter_item_timings_all$inter_reading <- inter_item_timings_all$winsrdIRT

inter_item_timings <- subset(inter_item_timings_all, inter_reading > 150 & !is_filler & participant != 206)

inter_item_timings$inter_reading.ln <- log(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.inverse <- 1/(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.sqred <- (inter_item_timings$inter_reading)^2


order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))

morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)
inter_item_timings$Sorder <- 2
inter_item_timings$Sorder[inter_item_timings$participant %in% order1] <- 1
inter_item_timings$Iorder <- getIOrd(inter_item_timings$item,inter_item_timings$Sorder)
inter_item_timings$item <- as.factor(inter_item_timings$item)
inter_item_timings$participant <- as.factor(inter_item_timings$participant)
inter_item_timings$Iorder <- as.factor(inter_item_timings$Iorder)
inter_item_timings$Sorder <- as.factor(inter_item_timings$Sorder)
```

# Inter-item timing analyses

Mean inter-reading time (IRT) is a measure of the amount of time in ms between when a subject stops speaking during a cold reading and when they begin speaking for a previewed reading.

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. IRT is meant to represent their chosen preview time for the second reading.

## histograms
```{r hist}
hist(inter_item_timings$raw_irt, breaks=50,xlab="raw IRT",main=" Raw IRT)")

hist(inter_item_timings$inter_reading, breaks=50,xlab="IRT",main="HWinsorized IRT")

hist(inter_item_timings$inter_reading.log10, breaks=50,xlab="log10 IRT",main="Common log of winsorized IRT")
```

## Mean and SD of winsorized IRT by condition

Mean and SD winsorized inter-reading time (IRT) in ms


```{r sdtable, echo=FALSE}
mtable <- with(na.omit(subset(inter_item_timings,!is_filler)),tapply(inter_reading, condition, mean))

sdtable <- with(na.omit(subset(inter_item_timings,!is_filler)),tapply(inter_reading, condition, sd))

ctable <- rbind(mtable,sdtable)
row.names(ctable) <- c("Mean", "SD")

kable(t(ctable), align="r") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```
## Means by conidtion and item/subject
```{r meantable, echo=FALSE}

mstable <-  aggregate(inter_reading ~ condition + participant, data=inter_item_timings, mean)
mitable <- aggregate(inter_reading ~ condition + item, data=inter_item_timings, mean)

mitable<-spread(mitable, key=condition, value=inter_reading, fill = NA, convert = FALSE)
mstable<-spread(mstable, key=condition, value=inter_reading, fill = NA, convert = FALSE)

mstable$pattern <- mstable$`+GP +Q` - mstable$`-GP +Q` < mstable$`+GP -Q` - mstable$`-GP -Q` 
mitable$pattern <- mitable$`+GP +Q` - mitable$`-GP +Q` < mitable$`+GP -Q` - mitable$`-GP -Q` 
```
### Number of participants who show predicted pattern
```{r PmatchesPatterns}
summary(mstable$pattern)
```
### Number of items that show predicted pattern
```{r ImatchesPat}
summary(mitable$pattern)
```

```{r meansbyp}
kable(mstable, align="r") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```
```{r meansbyi}
kable(mitable, align="r") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```


## boxplot of mean inter-item time by condition

Inter reading time (IRT) in ms

```{r echo=FALSE}
boxplot(inter_reading ~condition, main="plain IRT", col=c("white","lightgray"),inter_item_timings)

boxplot(inter_reading.log10 ~ condition,main="common log of IRT", col=c("white","lightgray"),inter_item_timings)

```

# Models

```{r lmerModel,echo=F}

if(refresh | !exists("models.timing.simple")){
  models.timing.simple <- lmer(
    inter_reading.log10 ~ GP_condition * Q_condition + (1 | participant) + (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
}
if(refresh | !exists("models.timing.orderCheck")){
  models.timing.orderCheck <- lmer(
    inter_reading.log10 ~ Iorder + GP_condition * Q_condition + (1 | participant) + (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
}


if(refresh | !exists("models.timing.simple.noint")){
  models.timing.simple.noint <- lmer(
    inter_reading.log10 ~ GP_condition + Q_condition + (1 | participant) + (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
}

if(refresh | !exists("models.timing.simple.noGP")){
  models.timing.simple.noQ <- lmer(
    inter_reading.log10 ~  Q_condition + (1 | participant) + (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
}
summary(models.timing.simple)
summary(models.timing.orderCheck)
summary(models.timing.simple.noint)
summary(models.timing.simple.noQ)
anova(models.timing.simple.noint,models.timing.simple)
anova(models.timing.simple,models.timing.orderCheck)
anova(models.timing.simple,models.timing.simple.noQ)
```
```{r gee}
gee.byP <- geeglm(inter_reading.log10 ~ GP_condition * Q_condition,id=participant,data=inter_item_timings)
gee.byI <- geeglm(inter_reading.log10 ~ GP_condition * Q_condition,id=item,data=inter_item_timings)
```
```{r geeSums}
summary(inter_item_timings)
summary(gee.byP)
summary(gee.byI)
```

<!--chapter:end:lmer2.Rmd-->

---
title: "LME VAD Inter-Item Timing (winsorized)"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)
library(psych)
library(geepack)
library(tidyr)
getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

mean.sd <- function(x) c(mean = mean(x), sd = sd(x))
# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = TRUE
inter_item_timings_new <- read_csv("csvs/src/vad-irt-all-48k_agg-3_2019-03-26_131537.csv")
inter_item_timings_new$GP_condition <- inter_item_timings_new$Condition_GP
inter_item_timings_new$Q_condition <- inter_item_timings_new$Condition_Q
inter_item_timings_new$Condition_Q <- NULL
inter_item_timings_new$Condition_GP <- NULL


inter_item_timings_new$condition <- paste(
  ifelse(inter_item_timings_new$Q_condition,"+Q","-Q"),
  ifelse(
    inter_item_timings_new$isFiller,
    ifelse(inter_item_timings_new$GP_condition,"+PP","-PP"),
    ifelse(inter_item_timings_new$GP_condition,"+GP","-GP")
  )
)

inter_item_timings_new$participant <- as.factor(inter_item_timings_new$Participant)

inter_item_timings <- subset(
  inter_item_timings_new, 
   !isFiller
  # exclude ps where any of the following is true
  # have mean irt < 1100 (7,9,13,17)
  # missing more than 25 irts (7,12,13,17,21)
  # lack a mean for some condition (22)
  & !Participant %in% c(7,9,12,13,17,21,22) 
  # & irt < 20000
  & irt > 150
)
inter_item_timings$item <- as.factor(inter_item_timings$Item)

inter_item_timings<-transform(inter_item_timings,winsrdIRT = ave(irt,participant,FUN=winsor))

inter_item_timings$inter_reading <- inter_item_timings$winsrdIRT

inter_item_timings$inter_reading.ln <- log(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.inverse <- 1/(inter_item_timings$inter_reading)
inter_item_timings$inter_reading.sqred <- (inter_item_timings$inter_reading)^2


order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))

morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)
inter_item_timings$Sorder <- 2
inter_item_timings$Sorder[inter_item_timings$Participant %in% order1] <- 1
inter_item_timings$Iorder <- getIOrd(inter_item_timings$item,inter_item_timings$Sorder)

inter_item_timings$Sorder <- as.factor(inter_item_timings$Sorder)
```

# Inter-item timing analyses

Mean inter-reading time (IRT) is a measure of the amount of time in ms between when a subject stops speaking during a cold reading and when they begin speaking for a previewed reading.

Subjects were asked to read each sentence twice, once with no preview at all, and then again after unlimited preview. IRT is meant to represent their chosen preview time for the second reading.

## histograms
```{r hist}
hist(inter_item_timings$irt, breaks=50,xlab="raw IRT",main="Raw IRT)",xlim=c(0,20000))

hist(inter_item_timings$inter_reading, breaks=50,xlab="IRT",main="Winsorized IRT",xlim=c(0,20000))

hist(inter_item_timings$inter_reading.log10, breaks=50,xlab="log10 IRT",main="Common log of winsorized IRT",xlim=c(2.5,4.5))
```

## Mean and SD of winsorized IRT by condition

Mean and SD winsorized inter-reading time (IRT) in ms.


```{r sdtable, echo=FALSE}
mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

sdtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, sd))

ctable <- rbind(mtable,sdtable)
row.names(ctable) <- c("Mean", "SD")

kable(t(ctable), align="r") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

Difference for declaratives: `r round(mtable[2] - mtable[1],2)`; for interrogatives: `r round(mtable[4]-mtable[3],2)`.

## Means by conidtion and item/subject
```{r meantable, echo=FALSE}
mstable <- aggregate(inter_reading ~ condition + participant, data=na.omit(inter_item_timings), mean)
mitable <- aggregate(inter_reading ~ condition + item, data=na.omit(inter_item_timings), mean)

mitable<-spread(mitable, key=condition, value=inter_reading, fill = NA, convert = FALSE)
mstable<-spread(mstable, key=condition, value=inter_reading, fill = NA, convert = FALSE)

mstable$pattern <- mstable$`-Q +GP` - mstable$`-Q -GP` > mstable$`+Q -GP` - mstable$`+Q -GP` 
mitable$pattern <- mitable$`-Q +GP` - mitable$`-Q -GP` > mitable$`+Q -GP` - mitable$`+Q -GP`
```

### Number of participants who show predicted pattern
```{r PmatchesPatterns}
summary(mstable$pattern)
```
### Number of items that show predicted pattern
```{r ImatchesPat}
summary(mitable$pattern)
```

```{r meansbyp}
kable(mstable, align="r") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```
```{r meansbyi}
kable(mitable, align="r") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```


## boxplot of mean inter-item time by condition

Inter reading time (IRT) in ms

```{r echo=FALSE}
boxplot(inter_reading ~condition, main="plain IRT", col=c("white","lightgray"),inter_item_timings)

boxplot(inter_reading.log10 ~ condition,main="common log of IRT", col=c("white","lightgray"),inter_item_timings)

```

# Models
```{r lmerNoIfull,echo=F}
noI.full <- lmer(
    inter_reading.log10 ~ GP_condition * Q_condition + 
      (1 + GP_condition * Q_condition | participant),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
noI.simple <- lmer(
    inter_reading.log10 ~ GP_condition * Q_condition + 
      (1 + GP_condition + Q_condition | participant),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)

noI.simplest <- lmer(
    inter_reading.log10 ~ GP_condition * Q_condition + 
      (1 | participant),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)

noI.simple.noInt <- lmer(
    inter_reading.log10 ~ GP_condition + Q_condition + 
      (1 | participant),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
```
```{r lmerNoI,echo=F}
noP.full <- lmer(
    inter_reading.log10 ~ GP_condition * Q_condition + 
      (1 + GP_condition * Q_condition | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(optimizer="bobyqa",maxfun=2e12))
  )
noP.simple <- lmer(
    inter_reading.log10 ~ GP_condition * Q_condition + 
      (1 + GP_condition + Q_condition | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(optimizer="bobyqa",maxfun=2e12))
)

noP.simplest <- lmer(
    inter_reading.log10 ~ GP_condition * Q_condition + 
      (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(optimizer="bobyqa",maxfun=2e12))
    
    )

noP.simplest.noInt <- lmer(
    inter_reading.log10 ~ GP_condition + Q_condition + 
      (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(optimizer="bobyqa",maxfun=2e12))
    )
```
```{r lmerNoI_nolog,echo=F}
noI.full <- lmer(
    inter_reading ~ GP_condition * Q_condition + 
      (1 + GP_condition * Q_condition | participant),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
noI.simple <- lmer(
    inter_reading ~ GP_condition * Q_condition + 
      (1 + GP_condition + Q_condition | participant),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)

noI.simplest <- lmer(
    inter_reading ~ GP_condition * Q_condition + 
      (1 | participant),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)

noI.simple.noInt <- lmer(
    inter_reading ~ GP_condition + Q_condition + 
      (1 + GP_condition + Q_condition  | participant),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
```
```{r lmerModel,echo=F}

if(refresh | !exists("models.timing.simple")){
  models.timing.simple <- lmer(
    inter_reading.log10 ~ GP_condition * Q_condition + (1 | participant) + (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
}
if(refresh | !exists("models.timing.orderCheck")){
  models.timing.orderCheck <- lmer(
    inter_reading.log10 ~ Iorder + GP_condition * Q_condition + (1 | participant) + (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
}


if(refresh | !exists("models.timing.simple.noint")){
  models.timing.simple.noint <- lmer(
    inter_reading.log10 ~ GP_condition + Q_condition + (1 | participant) + (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
}

if(refresh | !exists("models.timing.simple.noGP")){
  models.timing.simple.noQ <- lmer(
    inter_reading.log10 ~  Q_condition + (1 | participant) + (1 | item),
    data=inter_item_timings,
    control=lmerControl(optCtrl=list(maxfun=2e12)), 
    REML=FALSE)
}
summary(models.timing.simple)
summary(models.timing.orderCheck)
summary(models.timing.simple.noint)
summary(models.timing.simple.noQ)
anova(models.timing.simple.noint,models.timing.simple)
anova(models.timing.simple,models.timing.orderCheck)
anova(models.timing.simple,models.timing.simple.noQ)
```
```{r gee}
gee.byP <- geeglm(inter_reading.log10 ~ GP_condition * Q_condition,id=participant,data=inter_item_timings)
gee.byI <- geeglm(inter_reading.log10 ~ GP_condition * Q_condition,id=item,data=inter_item_timings)
```
```{r geeSums}
summary(inter_item_timings)
summary(gee.byP)
summary(gee.byI)
```

<!--chapter:end:lmer3.Rmd-->

---
title: "LME Inter-Item Timing, Inverse transform"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)

# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = TRUE

inter_item_timings_all <- read_csv("dissertation/csvs/inter_item_timings.csv", 
    col_types = cols(item = col_character(), 
        participant = col_character()))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading < 0] <- NA
inter_item_timings_all$inter_reading <- inter_item_timings_all$inter_reading + 1
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings_all$participant[inter_item_timings_all$participant == 108] <- 8
inter_item_timings <- subset(inter_item_timings_all, Exp)

inter_item_timings$inter_reading_raw <- inter_item_timings$inter_reading
inter_item_timings$inter_reading <- 1/(inter_item_timings$inter_reading)
  
gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```



# Inter-item timing analyses

## boxplot of mean inter-item time by condition
```{r echo=FALSE}
boxplot(inter_reading ~ GP_condition*Q_condition, col=c("white","lightgray"),inter_item_timings,names=c("-GP -Q", "+GP -Q", "-GP +Q", "+GP +Q"))
```
```{r lmerModel,echo=FALSE}
if(refresh | !exists("models.timing")){
  models.timing <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt")){
  models.timingNoInt <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}

if(refresh | !exists("models.timing.Sense")){
  models.timing.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt.Sense")){
  models.timingNoInt.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
```
```{r assumptionChecks, include=FALSE, echo=FALSE}
inter_item_timings$resids_main <- NA
inter_item_timings$resids_main[!is.na(inter_item_timings$inter_reading)] <- residuals(models.timing)
inter_item_timings$resids_main.abs <- abs(inter_item_timings$resids_main)
inter_item_timings$resids_main.sq <-inter_item_timings$resids_main.abs^2
sensitive_timings <- subset(inter_item_timings, !(participant %in% gpInsensitive))
sensitive_timings$resids_main[!is.na(sensitive_timings$inter_reading)] <- residuals(models.timing.Sense)
sensitive_timings$resids_main.abs <- abs(sensitive_timings$resids_main)
sensitive_timings$resids_main.sq <- sensitive_timings$resids_main.abs^2

# ANOVA of the squared residuals
timings_sq_resid <- lm(resids_main.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals
sens_timings_sq_resid <- lm(resids_main.sq ~ participant, data=sensitive_timings)
```

# Models

## All participants
These models use all 32 participants

### Full model
```{r full}
summary(models.timing)
```

### Without interacton 
```{r noInt}
summary(models.timingNoInt)
```

## Only "gp-sensitive"
The following models exclude all participants whose mean inter-item reading time for `+GP` items is less than for `-GP` items

### With interaction
```{r gpSense}
summary(models.timing.Sense)
```

### Without interaction
```{r gpSenseNoInt}
summary(models.timingNoInt.Sense)

```
# Checking assumptions
The following checks assumptions about the data

## Homogeneity of variance
Anova of squared residuals (full model) by participant 

### All Ps
```{r homovar}
# all participants
anova(timings_sq_resid) 
```

### Only GP-sense
```{r homovarSense}
# GP-sensitive only
anova(sens_timings_sq_resid)
```

## Normal distribution of residuals
QQ plots of full models

### All participants
```{r normdres}
qqmath(models.timing, id=0.05)
```

### Only GP-sensitive participants
```{r normdresSense}
qqmath(models.timing.Sense, id=0.05)
```

## Linearity
Plots of residuals vs. observed

### All Ps
```{r lin}
plot(resid(models.timing),na.omit(inter_item_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

### GP-sensitive only
```{r linsense}
plot(resid(models.timing.Sense),na.omit(sensitive_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

<!--chapter:end:lmerInverse.Rmd-->

---
title: "LME Inter-Item Timing, Natural log transform"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)

# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = TRUE

inter_item_timings_all <- read_csv("dissertation/csvs/inter_item_timings.csv", 
    col_types = cols(item = col_character(), 
        participant = col_character()))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading < 0] <- NA
inter_item_timings_all$inter_reading <- inter_item_timings_all$inter_reading + 1
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings_all$participant[inter_item_timings_all$participant == 108] <- 8
inter_item_timings <- subset(inter_item_timings_all, Exp)

inter_item_timings$inter_reading_raw <- inter_item_timings$inter_reading
inter_item_timings$inter_reading <- log(inter_item_timings$inter_reading)
  
gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```



# Inter-item timing analyses

## boxplot of mean inter-item time by condition
```{r echo=FALSE}
boxplot(inter_reading ~ GP_condition*Q_condition, col=c("white","lightgray"),inter_item_timings,names=c("-GP -Q", "+GP -Q", "-GP +Q", "+GP +Q"))
```
```{r lmerModel,echo=FALSE}
if(refresh | !exists("models.timing")){
  models.timing <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt")){
  models.timingNoInt <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}

if(refresh | !exists("models.timing.Sense")){
  models.timing.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt.Sense")){
  models.timingNoInt.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
```
```{r assumptionChecks, include=FALSE, echo=FALSE}
inter_item_timings$resids_main <- NA
inter_item_timings$resids_main[!is.na(inter_item_timings$inter_reading)] <- residuals(models.timing)
inter_item_timings$resids_main.abs <- abs(inter_item_timings$resids_main)
inter_item_timings$resids_main.sq <-inter_item_timings$resids_main.abs^2
sensitive_timings <- subset(inter_item_timings, !(participant %in% gpInsensitive))
sensitive_timings$resids_main[!is.na(sensitive_timings$inter_reading)] <- residuals(models.timing.Sense)
sensitive_timings$resids_main.abs <- abs(sensitive_timings$resids_main)
sensitive_timings$resids_main.sq <- sensitive_timings$resids_main.abs^2

# ANOVA of the squared residuals
timings_sq_resid <- lm(resids_main.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals
sens_timings_sq_resid <- lm(resids_main.sq ~ participant, data=sensitive_timings)
```

# Models

## All participants
These models use all 32 participants

### Full model
```{r full}
summary(models.timing)
```

### Without interacton 
```{r noInt}
summary(models.timingNoInt)
```

## Only "gp-sensitive"
The following models exclude all participants whose mean inter-item reading time for `+GP` items is less than for `-GP` items

### With interaction
```{r gpSense}
summary(models.timing.Sense)
```

### Without interaction
```{r gpSenseNoInt}
summary(models.timingNoInt.Sense)

```
# Checking assumptions
The following checks assumptions about the data

## Homogeneity of variance
Anova of squared residuals (full model) by participant 

### All Ps
```{r homovar}
# all participants
anova(timings_sq_resid) 
```

### Only GP-sense
```{r homovarSense}
# GP-sensitive only
anova(sens_timings_sq_resid)
```

## Normal distribution of residuals
QQ plots of full models

### All participants
```{r normdres}
qqmath(models.timing, id=0.05)
```

### Only GP-sensitive participants
```{r normdresSense}
qqmath(models.timing.Sense, id=0.05)
```

## Linearity
Plots of residuals vs. observed

### All Ps
```{r lin}
plot(resid(models.timing),na.omit(inter_item_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

### GP-sensitive only
```{r linsense}
plot(resid(models.timing.Sense),na.omit(sensitive_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

<!--chapter:end:lmerLn.Rmd-->

---
title: "LME Inter-Item Timing, Log10 transform"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    theme: journal
    toc: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)

# set to true to re-run modelsqqnorm(myModel.lme, ~ranef(., level=2))
refresh = FALSE

inter_item_timings_all <- read_csv("dissertation/csvs/inter_item_timings.csv", 
    col_types = cols(item = col_character(), 
        participant = col_character()))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading < 0] <- NA
inter_item_timings_all$inter_reading <- inter_item_timings_all$inter_reading + 1
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings_all$participant[inter_item_timings_all$participant == 108] <- 8
inter_item_timings <- subset(inter_item_timings_all, Exp)

inter_item_timings$inter_reading_raw <- inter_item_timings$inter_reading
inter_item_timings$inter_reading <- log10(inter_item_timings$inter_reading)
  
gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```



# Inter-item timing analyses

## boxplot of mean inter-item time by condition
```{r echo=FALSE}
boxplot(inter_reading ~ GP_condition*Q_condition, col=c("white","lightgray"),inter_item_timings,names=c("-GP -Q", "+GP -Q", "-GP +Q", "+GP +Q"))
```
```{r lmerModel,echo=FALSE}
if(refresh | !exists("models.timing")){
  models.timing <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt")){
  models.timingNoInt <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}

if(refresh | !exists("models.timing.Sense")){
  models.timing.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(refresh | !exists("models.timingNoInt.Sense")){
  models.timingNoInt.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
```
```{r assumptionChecks, include=FALSE, echo=FALSE}
inter_item_timings$resids_main <- NA
inter_item_timings$resids_main[!is.na(inter_item_timings$inter_reading)] <- residuals(models.timing)
inter_item_timings$resids_main.abs <- abs(inter_item_timings$resids_main)
inter_item_timings$resids_main.sq <-inter_item_timings$resids_main.abs^2
sensitive_timings <- subset(inter_item_timings, !(participant %in% gpInsensitive))
sensitive_timings$resids_main[!is.na(sensitive_timings$inter_reading)] <- residuals(models.timing.Sense)
sensitive_timings$resids_main.abs <- abs(sensitive_timings$resids_main)
sensitive_timings$resids_main.sq <- sensitive_timings$resids_main.abs^2

# ANOVA of the squared residuals
timings_sq_resid <- lm(resids_main.sq ~ participant, data=inter_item_timings) 
# ANOVA of the squared residuals
sens_timings_sq_resid <- lm(resids_main.sq ~ participant, data=sensitive_timings)
```

# Models

## All participants
These models use all 32 participants

### Full model
```{r full}
summary(models.timing)
```

### Without interacton 
```{r noInt}
summary(models.timingNoInt)
```

## Only "gp-sensitive"
The following models exclude all participants whose mean inter-item reading time for `+GP` items is less than for `-GP` items

### With interaction
```{r gpSense}
summary(models.timing.Sense)
```

### Without interaction
```{r gpSenseNoInt}
summary(models.timingNoInt.Sense)

```
# Checking assumptions
The following checks assumptions about the data

## Homogeneity of variance
Anova of squared residuals (full model) by participant 

### All Ps
```{r homovar}
# all participants
anova(timings_sq_resid) 
```

### Only GP-sense
```{r homovarSense}
# GP-sensitive only
anova(sens_timings_sq_resid)
```

## Normal distribution of residuals
QQ plots of full models

### All participants
```{r normdres}
qqmath(models.timing, id=0.05)
```

### Only GP-sensitive participants
```{r normdresSense}
qqmath(models.timing.Sense, id=0.05)
```

## Linearity
Plots of residuals vs. observed

### All Ps
```{r lin}
plot(resid(models.timing),na.omit(inter_item_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

### GP-sensitive only
```{r linsense}
plot(resid(models.timing.Sense),na.omit(sensitive_timings$inter_reading),xlab="Residuals",ylab="Observed values")
```

<!--chapter:end:lmerLog10.Rmd-->

---
title: "Summary"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  pdf_document: default
  html_document:
    highlight: tango
    theme: journal
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)

got_prosody <- read_csv("dissertation/csvs/got_prosody.csv")

mdata <- read_csv("dissertation/csvs/got_prosody.csv")
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$goodProsody <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")

inter_item_timings_all <- read_csv("dissertation/csvs/inter_item_timings.csv", 
    col_types = cols(item = col_character(), 
        participant = col_character()))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading <0] <- NA
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings <- subset(inter_item_timings_all, Exp & participant != "108")

gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```

# Logit models
```{r logitModels}
# models.full <- glmer(PP1~V*OBJ+Condition_Q*Condition_GP+Reading + (1+V*OBJ+Condition_Q*Condition_GP+Reading | SID) + (1+V*OBJ+Condition_Q*Condition_GP+Reading | IID),data=mdata,family = binomial, control = glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=2e8)))
# summary(models.full)
if(!exists("models.goodP")){
  models.goodP <- glmer(goodProsody~Condition_Q*Condition_GP*Reading + (1+Condition_Q*Condition_GP*Reading | SID) + (1+Condition_Q*Condition_GP*Reading | IID),data=mdata,family = binomial, control = glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=2e8)))
}
summary(models.goodP)
```

<!--chapter:end:logit.Rmd-->

---
title: "Prosodic descriptions"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  html_document:
    highlight: pygments
    number_sections: yes
    theme: journal
    toc: yes
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(lme4)
library(lmerTest)


refresh = FALSE # set to true to re-run models
order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))
gpInsensitive <- paste(c(1,12,14,15,19,2,20,203,21,210,22,4,6))

morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)

getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

mdata <- read_csv("csvs/got_prosody.csv")

mdata$Sorder <- 2
mdata$Sorder[mdata$SID %in% order1] <- 1
mdata$Iorder <- getIOrd(mdata$IID,mdata$Sorder)

mdata<-subset(mdata,!is.na(PP1) & !is.na(two_level_prosody))
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$lowAttach <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$IID[mdata$IID == 108] <- 8
mdata$LQI <- mdata$QI == "YES"
mdata$HtOrMs_QI <- mdata$LQI == mdata$Condition_Q

mdata$condition <- paste(ifelse(mdata$Condition_GP, "+GP", "-GP")," ",ifelse(mdata$Condition_Q, "+Q", "-Q"))



```

# Crosstabs

## Struggle 

Note that struggle does not show good cross-rater reliability

```{r strug}
label = "struggle:"
f <- ~STRUG + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption = paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## V break

Note that V break does not show good cross-rater reliability

```{r v}
label = "v break:"
f <- ~V + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption = paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## PP1 break

```{r pp1}
label = "pp1 break:"
f <- ~PP1 + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption = paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## OBJ break

```{r obj}
label <- "obj:"
f <- ~OBJ + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption =paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

## Question intonation hit/miss

```{r qihit}
label <- "QI hit:"
f <- ~HtOrMs_QI + condition
full <- xtabs(f, mdata)
r1 <- xtabs(f, subset(mdata,Reading==1))
r2 <- xtabs(f, subset(mdata,Reading==2))
kable(full, caption = paste(label,"both readings")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r1, caption = paste(label,"reading 1")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(r2, caption = paste(label,"reading 2")) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

# 3-level prosodic pattern
```{r 3lvlxtabs}
f <- ~ prosody + condition
prosodies.full <- xtabs(f, mdata)
prosodies.r1 <- xtabs(f, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(f, subset(mdata,Reading==2))
kable(prosodies.full, caption = "both readings") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(prosodies.r1, caption = "reading 1") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(prosodies.r2, caption = "reading 2") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
```

# 2-level prosodic pattern
```{r 2lvlxtabs}
form <- ~ condition+ two_level_prosody
prosodies.full <- xtabs(form, mdata)
prosodies.r1 <- xtabs(form, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(form, subset(mdata,Reading==2))
kable(prosodies.full) %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(prosodies.r1, caption = "reading 1") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T)
kable(prosodies.r2, caption = "reading 2") %>%
  kable_styling(bootstrap_options = c("striped",full_width=F,position="left")) %>%
  column_spec(1,bold=T) 
```

<!--chapter:end:pros-xtabs.Rmd-->

---
title: "Prosody description"
author: "Tyler Peckenpaugh"
date: "4/15/2019"
output: 
  bookdown::tufte_html2:
    toc: false
---

```{r setup2, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(sjPlot)
library(lattice)
library(ggplot2)
library(dplyr)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3,fig.pos = 'H')
mdata <- read_csv("~/dissertation/csvs/got_prosody.csv")
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$condition <- with(mdata,
  paste(
    ifelse(Condition_Q,"+Q","-Q"),
    ifelse(Condition_GP,"+GP","-GP")
  )
)
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$pdom <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$odom <- mdata$two_level_prosody %in% c("OBJ", "OBJ > PP1")
gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```

# Breaks by condition

## PP1 Break

```{r pp1breaks, fig.cap="PP1 Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + condition, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + condition, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + condition, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings")
kable(pp1br.r1, caption="Reading 1")
kable(pp1br.r2, caption="Reading 2")
```

## OBJ Break

```{r objbreaks, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + condition, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + condition, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + condition, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings")
kable(pp1br.r1, caption="Reading 1")
kable(pp1br.r2, caption="Reading 2")
```

# Breaks by &plusmn;Q

## PP1 Break by &plusmn;Q

```{r gpp1, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + Condition_Q, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + Condition_Q, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + Condition_Q, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-Q","+Q"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-Q","+Q"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-Q","+Q"))
```

## OBJ Break by &plusmn;Q

```{r gpobj, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + Condition_Q, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + Condition_Q, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + Condition_Q, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-Q","+Q"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-Q","+Q"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-Q","+Q"))
```

# Breaks by &plusmn;GP

## PP1 Break by &plusmn;GP

```{r qpp1, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + Condition_GP, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + Condition_GP, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + Condition_GP, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-GP","+GP"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-GP","+GP"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-GP","+GP"))
```

## OBJ Break by &plusmn;GP

```{r qobj, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + Condition_GP, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + Condition_GP, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + Condition_GP, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-GP","+GP"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-GP","+GP"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-GP","+GP"))
```

# 3-level prosodic pattern

```{r 3lvlxtabs}
prosodies.full <- xtabs(~ prosody +condition, mdata)
prosodies.r1 <- xtabs(~ prosody +condition, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ prosody +condition, subset(mdata,Reading==2))
kable(prosodies.full, caption = "Both readings")
kable(prosodies.r1, caption = "Reading 1")
kable(prosodies.r2, caption = "Reading 2")
```

# 2-level prosodic pattern

```{r 2lvlxtabs}
prosodies.full <- xtabs(~ two_level_prosody +condition, mdata)
prosodies.r1 <- xtabs(~ two_level_prosody +condition, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ two_level_prosody +condition, subset(mdata,Reading==2))
kable(prosodies.full, caption = "Both readings")
kable(prosodies.r1, caption = "Reading 1")
kable(prosodies.r2, caption = "Reading 2")
```

# PP1 or PP1 > OBJ

```{r pdom}
pdom <- xtabs(~condition+pdom,data=mdata)
pdom.r1 <- xtabs(~condition+pdom,data=subset(mdata,Reading==1))
pdom.r2 <- xtabs(~condition+pdom,data=subset(mdata,Reading==2))


kable(
  pdom, caption="Both readings",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
kable(
  pdom.r1, caption="Reading 1",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
kable(
  pdom.r2, caption="Reading 2",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
```

# OBJ or OBJ > PP1

```{r odom}
odom <- xtabs(~condition + odom ,data=mdata)
odom.r1 <- xtabs(~condition + odom,data=subset(mdata,Reading==1))
odom.r2 <- xtabs(~condition + odom,data=subset(mdata,Reading==2))

kable(odom, caption="Both readings",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
kable(odom.r1, caption="Reading 1",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
kable(odom.r2, caption="Reading 2",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
```

# Logistic regression models

The interaction between &plusmn;GP and &plusmn;Q approaches significance (p < 0.06) as a predictor of the object break, but not the PP1 break.

```{r models}
obj <- glmer(OBJ~Condition_GP*Condition_Q+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)
pp <- glmer(PP1~Condition_GP*Condition_Q+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)

tab_model(obj,pp)
```

<!--chapter:end:prosody-data.Rmd-->

---
title: "Prosodic patterns"
author: "Tyler Peckenpaugh"
date: "4/2/2019"
output:
  tufte::tufte_handout: 
    toc: True  
    latex_engine: xelatex
  tufte::tufte_html: 
    tufte_features: ["fonts", "italics"]
    toc: True
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(stargazer)
library(lattice)
library(ggplot2)
library(dplyr)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3)
mdata <- read_csv("~/dissertation/csvs/got_prosody.csv")
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$condition <- with(mdata,
  paste(
    ifelse(Condition_Q,"+Q","-Q"),
    ifelse(Condition_GP,"+GP","-GP")
  )
)
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$pdom <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$odom <- mdata$two_level_prosody %in% c("OBJ", "OBJ > PP1")
gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```

# Breaks by condition

## PP1 Break

```{r pp1breaks, fig.cap="PP1 Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + condition, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + condition, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + condition, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings")
kable(pp1br.r1, caption="Reading 1")
kable(pp1br.r2, caption="Reading 2")
```

## OBJ Break

```{r objbreaks, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + condition, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + condition, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + condition, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings")
kable(pp1br.r1, caption="Reading 1")
kable(pp1br.r2, caption="Reading 2")
```

# Breaks by &plusmn;Q

## PP1 Break by &plusmn;Q

```{r gpp1, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + Condition_Q, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + Condition_Q, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + Condition_Q, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-Q","+Q"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-Q","+Q"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-Q","+Q"))
```

## OBJ Break by &plusmn;Q

```{r gpobj, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + Condition_Q, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + Condition_Q, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + Condition_Q, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-Q","+Q"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-Q","+Q"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-Q","+Q"))
```

# Breaks by &plusmn;GP

## PP1 Break by &plusmn;GP

```{r qpp1, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + Condition_GP, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + Condition_GP, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + Condition_GP, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-GP","+GP"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-GP","+GP"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-GP","+GP"))
```

## OBJ Break by &plusmn;GP

```{r qobj, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + Condition_GP, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + Condition_GP, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + Condition_GP, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-GP","+GP"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-GP","+GP"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-GP","+GP"))
```

# 3-level prosodic pattern

```{r 3lvlxtabs}
prosodies.full <- xtabs(~ prosody +condition, mdata)
prosodies.r1 <- xtabs(~ prosody +condition, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ prosody +condition, subset(mdata,Reading==2))
kable(prosodies.full, caption = "Both readings")
kable(prosodies.r1, caption = "Reading 1")
kable(prosodies.r2, caption = "Reading 2")
```

# 2-level prosodic pattern

```{r 2lvlxtabs}
prosodies.full <- xtabs(~ two_level_prosody +condition, mdata)
prosodies.r1 <- xtabs(~ two_level_prosody +condition, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ two_level_prosody +condition, subset(mdata,Reading==2))
kable(prosodies.full, caption = "Both readings")
kable(prosodies.r1, caption = "Reading 1")
kable(prosodies.r2, caption = "Reading 2")
```

# PP1 or PP1 > OBJ

```{r pdom}
pdom <- xtabs(~condition+pdom,data=mdata)
pdom.r1 <- xtabs(~condition+pdom,data=subset(mdata,Reading==1))
pdom.r2 <- xtabs(~condition+pdom,data=subset(mdata,Reading==2))


kable(
  pdom, caption="Both readings",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
kable(
  pdom.r1, caption="Reading 1",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
kable(
  pdom.r2, caption="Reading 2",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
```

# OBJ or OBJ > PP1

```{r odom}
odom <- xtabs(~condition + odom ,data=mdata)
odom.r1 <- xtabs(~condition + odom,data=subset(mdata,Reading==1))
odom.r2 <- xtabs(~condition + odom,data=subset(mdata,Reading==2))

kable(odom, caption="Both readings",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
kable(odom.r1, caption="Reading 1",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
kable(odom.r2, caption="Reading 2",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
```


```{r}
  
```


# Logistic regression models

The interaction between &plusmn;GP and &plusmn;Q approaches significance (p < 0.06) as a predictor of the object break, but not the PP1 break.

```{r models,results="asis"}
obj <- glmer(OBJ~Condition_GP*Condition_Q+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)
pp <- glmer(PP1~Condition_GP*Condition_Q+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)

stargazer(obj,pp)
```

<!--chapter:end:prosody-desc.Rmd-->

---
title: "Prosodic properties"
author: "Tyler Peckenpaugh"
date: "4/2/2019"
output:
output:
  tufte::tufte_html: 
    tufte_features: ["fonts", "italics"]
    toc: True
  tufte::tufte_handout: 
    toc: True  
    latex_engine: xelatex
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(lme4)
library(lmerTest)

refresh = FALSE # set to true to re-run models
order1<-paste(c(1,2,3,4,5,6,7,8,9,22,201,202,203,204,205,206))
gpInsensitive <- paste(c(1,12,14,15,19,2,20,203,21,210,22,4,6))

morder<-c(3,8,4,9,14,13,12,2,7,10,1,16,5,15,11,6)
sorder<-c(7,10,1,16,5,15,11,6,3,8,4,9,14,13,12,2)

getIOrd<-function (x,s){
  if(s==1){
    return (match(x,morder))
  } else {
    return (match(x,sorder))
  }
}

mdata <- read_csv("csvs/got_prosody.csv")

mdata$Sorder <- 2
mdata$Sorder[mdata$SID %in% order1] <- 1
mdata$Iorder <- getIOrd(mdata$IID,mdata$Sorder)

mdata<-subset(mdata,!is.na(PP1) & !is.na(two_level_prosody))
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$lowAttach <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$IID[mdata$IID == 108] <- 8
mdata$LQI <- mdata$QI == "YES"
mdata$HtOrMs_QI <- mdata$LQI == mdata$Condition_Q

mdata$condition <- paste(ifelse(mdata$Condition_GP, "+GP", "-GP")," ",ifelse(mdata$Condition_Q, "+Q", "-Q"))




```

# Logit models

```{r pp1logit}
# model failse to converge
# if(F & !exists("models.logi.attach.full") | refresh){
#   models.logi.pp1.full <- glmer(
#     PP1~OBJ + Condition_Q * Condition_GP + Reading + 
#       (OBJ+Condition_Q*Condition_GP+Reading | SID) + 
#       (OBJ+Condition_Q*Condition_GP+Reading | IID),
#     family = binomial, 
#     data = mdata,
#     control = glmerControl(optimizer = "bobyqa",
#                            optCtrl=list(maxfun=2e8)),
#     verbose = 2
#   )
# }
```
```{r attachment,echo=FALSE}
if(!exists("models.logi.attach.full.wD") | refresh){
  models.logi.attach.full.wD <- glmer(
    lowAttach~Condition_Q*Condition_GP*Reading + 
      (1+Condition_Q*Condition_GP*Reading | SID) + 
      (1+Condition_Q*Condition_GP*Reading | IID),
    data = mdata,
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```
```{r attachment_noRint}
if(!exists("models.logi.attach.noRint") | refresh){
  models.logi.attach.noRint <- glmer(
    lowAttach~Condition_Q*Condition_GP+Reading + 
      (1+Condition_Q*Condition_GP+Reading | SID) + 
      (1+Condition_Q*Condition_GP+Reading | IID),
    data = mdata,
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```
```{r attachment_noR}
if(!exists("models.logi.attach.noR") | refresh){
  models.logi.attach.noR <- glmer(
    lowAttach~Condition_Q*Condition_GP + 
      (1+Condition_Q*Condition_GP | SID) + 
      (1+Condition_Q*Condition_GP | IID),
    data = mdata,
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```
```{r attachment_noR_r2}
if(!exists("models.logi.attach.noR.r2") | refresh){
  models.logi.attach.noR.r2 <- glmer(
    lowAttach~Condition_Q*Condition_GP + 
      (1+Condition_Q*Condition_GP | SID) + 
      (1+Condition_Q*Condition_GP | IID),
    data = subset(mdata, Reading == 2),
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e8)),
    verbose = 2
  )
}
```


## Predicting PP1 as strongest or only break

Is PP1 being the strongest or only break predicted by condition * reading?

# Full model

```{r summarizeAttach}
summary(models.logi.attach.full.wD)
```

# Model with no interaction of reading
Simplified model and comparison to full model

```{r sumNoRInt}
summary(models.logi.attach.noRint)
anova(models.logi.attach.full.wD,models.logi.attach.noRint)
```

# Model with no fixed effect of reading

Simplified model and comparison to full model

```{r sumNoR}
summary(models.logi.attach.noR)
anova(models.logi.attach.full.wD,models.logi.attach.noR)
```

# Model with just reading 2

Simplified model and comparison to full model

```{r sumR2}
summary(models.logi.attach.noR.r2)
#anova(models.logi.attach.full.wD,models.logi.attach.noR.r2)
```

<!--chapter:end:prosody.Rmd-->

---
title: "Prosody description"
author: "Tyler Peckenpaugh"
date: "4/15/2019"
output: 
  bookdown::tufte_handout2: 
    toc: True
    latex_engine: xelatex
---

```{r setup2, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(stargazer)
library(lattice)
library(ggplot2)
library(dplyr)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.height = 3)
mdata <- read_csv("~/dissertation/csvs/got_prosody.csv")
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$condition <- with(mdata,
  paste(
    ifelse(Condition_Q,"+Q","-Q"),
    ifelse(Condition_GP,"+GP","-GP")
  )
)
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$pdom <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$odom <- mdata$two_level_prosody %in% c("OBJ", "OBJ > PP1")
gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```

# Breaks by condition

## PP1 Break

```{r pp1breaks, fig.cap="PP1 Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + condition, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + condition, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + condition, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings")
kable(pp1br.r1, caption="Reading 1")
kable(pp1br.r2, caption="Reading 2")
```

## OBJ Break

```{r objbreaks, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + condition, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + condition, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + condition, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings")
kable(pp1br.r1, caption="Reading 1")
kable(pp1br.r2, caption="Reading 2")
```

# Breaks by &plusmn;Q

## PP1 Break by &plusmn;Q

```{r gpp1, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + Condition_Q, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + Condition_Q, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + Condition_Q, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-Q","+Q"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-Q","+Q"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-Q","+Q"))
```

## OBJ Break by &plusmn;Q

```{r gpobj, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + Condition_Q, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + Condition_Q, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + Condition_Q, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-Q","+Q"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-Q","+Q"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-Q","+Q"))
```

# Breaks by &plusmn;GP

## PP1 Break by &plusmn;GP

```{r qpp1, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~PP1 + Condition_GP, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~PP1 + Condition_GP, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~PP1 + Condition_GP, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-GP","+GP"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-GP","+GP"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-GP","+GP"))
```

## OBJ Break by &plusmn;GP

```{r qobj, fig.cap="OBJ Break"}
br_rows <- c("No break", "Break")
pp1br <- xtabs(~OBJ + Condition_GP, mdata)
row.names(pp1br) <- br_rows
pp1br.r1 <- xtabs(~OBJ + Condition_GP, subset(mdata, Reading==1))
row.names(pp1br.r1) <- br_rows        
pp1br.r2 <- xtabs(~OBJ + Condition_GP, subset(mdata, Reading==2))
row.names(pp1br.r2) <- br_rows

kable(pp1br, caption="Both readings",col.names=c("-GP","+GP"))
kable(pp1br.r1, caption="Reading 1",col.names=c("-GP","+GP"))
kable(pp1br.r2, caption="Reading 2",col.names=c("-GP","+GP"))
```

# 3-level prosodic pattern

```{r 3lvlxtabs}
prosodies.full <- xtabs(~ prosody +condition, mdata)
prosodies.r1 <- xtabs(~ prosody +condition, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ prosody +condition, subset(mdata,Reading==2))
kable(prosodies.full, caption = "Both readings")
kable(prosodies.r1, caption = "Reading 1")
kable(prosodies.r2, caption = "Reading 2")
```

# 2-level prosodic pattern

```{r 2lvlxtabs}
prosodies.full <- xtabs(~ two_level_prosody +condition, mdata)
prosodies.r1 <- xtabs(~ two_level_prosody +condition, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ two_level_prosody +condition, subset(mdata,Reading==2))
kable(prosodies.full, caption = "Both readings")
kable(prosodies.r1, caption = "Reading 1")
kable(prosodies.r2, caption = "Reading 2")
```

# PP1 or PP1 > OBJ

```{r pdom}
pdom <- xtabs(~condition+pdom,data=mdata)
pdom.r1 <- xtabs(~condition+pdom,data=subset(mdata,Reading==1))
pdom.r2 <- xtabs(~condition+pdom,data=subset(mdata,Reading==2))


kable(
  pdom, caption="Both readings",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
kable(
  pdom.r1, caption="Reading 1",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
kable(
  pdom.r2, caption="Reading 2",
  col.names = c("PP1 Not Dominant", "PP1 Dominant")
)
```

# OBJ or OBJ > PP1

```{r odom}
odom <- xtabs(~condition + odom ,data=mdata)
odom.r1 <- xtabs(~condition + odom,data=subset(mdata,Reading==1))
odom.r2 <- xtabs(~condition + odom,data=subset(mdata,Reading==2))

kable(odom, caption="Both readings",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
kable(odom.r1, caption="Reading 1",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
kable(odom.r2, caption="Reading 2",
      col.names = c("OBJ Not Dominant", "OBJ Dominant"))
```

# Logistic regression models

The interaction between &plusmn;GP and &plusmn;Q approaches significance (p < 0.06) as a predictor of the object break, but not the PP1 break.

```{r models,results="asis"}
obj <- glmer(OBJ~Condition_GP*Condition_Q+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)
pp <- glmer(PP1~Condition_GP*Condition_Q+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)

stargazer(obj,pp,header=F)
```

<!--chapter:end:prosoy-data.Rmd-->


```{r combobreaksPre}
pdata <- subset(mdata,OBJ|PP1)
allpros <- table(pdata$simple2lvl) %>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Combined breaks", "Percent of all data"))

r2pros<-table(
  subset(pdata,Reading==2)$simple2lvl
) %>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Pattern", "r2")) 

r1pros<-table(
  subset(pdata,Reading==1)$simple2lvl
) %>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Pattern", "r1")) 

allpros$`Cold readings` <- r1pros$r1
allpros$`Previewed readings` <- r2pros$r2
```

```{r combobreaks}
kable(allpros,caption="Combined breaks by reading") %>%
  kable_styling(latex_options = "hold_position")
```
<!--
## Generalized Estimating Equation

Generalized Estimating Equation (GEE) analyses with participant as the error term show much the same results.

```{r gee1}
gee.byP <- geeglm(
  inter_reading.log10 ~ GP_condition * Q_condition,
  id=participant,
  data=inter_item_timings
)
gee.byP.noInt<- geeglm(
  inter_reading.log10 ~ GP_condition + Q_condition,
  id=participant,
  data=inter_item_timings
)
tab_model(gee.byP,gee.byP.noInt)
irt.compared<-anova(gee.byP,gee.byP.noInt)
```

The interaction model does not represent a statistically significant improvement in fit (&Chi; = `r round(irt.compared$X2[1],3)`, p < `r round(irt.compared["P(>|Chi|)"],2)`), but the improvement it does approach significance.

<!--
# Excluding items

If we exclude items where the IRT for the control condition (-Q, -GP) is longer than 7s, we get the following:
```{r gee2, echo=FALSE}
inter_item_timings<-irt_data_itemsExcluded
inter_item_timings$inter_reading <- inter_item_timings$irt
inter_item_timings$inter_reading.log10 <- log10(inter_item_timings$irt)

mtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, mean))

sdtable <- with(na.omit(inter_item_timings),tapply(inter_reading, condition, sd))

ctable <- rbind(mtable,sdtable)
row.names(ctable) <- c("Mean", "SD")
decl <- round(mtable["-Q +GP"] - mtable["-Q -GP"],2)
int <- round(mtable["+Q +GP"] - mtable["+Q -GP"],2)
diffGPQ <- decl - int
```

Difference for declaratives: `r decl`; for interrogatives: `r int`; difference of differences: `r diffGPQ`.

```{r exclit}
kable(t(ctable), caption="Condition means")
```

## GEE Analyses

Generalized Estimating Equation (GEE) analyses with participant as the error term show much the same results.

```{r exclitgee}
gee.byP <- geeglm(
  inter_reading.log10 ~ GP_condition * Q_condition,
  id=participant,
  data=inter_item_timings
)
gee.byP.noInt<- geeglm(
  inter_reading.log10 ~ GP_condition + Q_condition,
  id=participant,
  data=inter_item_timings
)
tab_model(gee.byP,gee.byP.noInt)
irt.compared<-anova(gee.byP,gee.byP.noInt)
```
```{r exclitgee2}
gee.byI <- geeglm(
  inter_reading.log10 ~ GP_condition * Q_condition,
  id=item,
  data=inter_item_timings
)
gee.byI.noInt<- geeglm(
  inter_reading.log10 ~ GP_condition + Q_condition,
  id=item,
  data=inter_item_timings
)
tab_model(gee.byI,gee.byI.noInt)
irt.compared<-anova(gee.byP,gee.byP.noInt)
```

The interaction model does not represent a statistically significant improvement in fit (&Chi; = `r round(irt.compared$X2[1],3)`, p < `r round(irt.compared["P(>|Chi|)"],2)`), and so does not support the primary hypothesis. -->

<!--chapter:end:salvage-irt-desc3.Rmd-->

---
title: "Summary"
author: "Tyler Peckenpaugh"
date: "3/5/2019"
output:
  pdf_document: default
  html_document:
    highlight: tango
    theme: journal
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(pander)
library(lme4)
library(lmerTest)
library(lattice)

got_prosody <- read_csv("dissertation/csvs/got_prosody.csv")

mdata <- read_csv("dissertation/csvs/got_prosody.csv")
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$goodProsody <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")

inter_item_timings_all <- read_csv("dissertation/csvs/inter_item_timings.csv", 
    col_types = cols(item = col_character(), 
        participant = col_character()))

inter_item_timings_all$inter_reading[inter_item_timings_all$inter_reading <0] <- NA
inter_item_timings_all$Exp <- FALSE == grepl("F",inter_item_timings_all$filename)
inter_item_timings <- subset(inter_item_timings_all, Exp & participant != "108")

gpInsensitive <- paste(c(1,
12,
14,
15,
19,
2,
20,
203,
21,
210,
22,
4,
6))

```

# 3-level prosodic pattern
```{r 3lvlxtabs}
prosodies.full <- xtabs(~ prosody + Condition_Q + Condition_GP, mdata)
prosodies.r1 <- xtabs(~ prosody + Condition_Q + Condition_GP, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ prosody + Condition_Q + Condition_GP, subset(mdata,Reading==2))
pander(prosodies.full, caption = "both readings")
pander(prosodies.r1, caption = "reading 1")
pander(prosodies.r2, caption = "reading 2")
```

# 2-level prosodic pattern
```{r 2lvlxtabs}
prosodies.full <- xtabs(~ two_level_prosody + Condition_Q + Condition_GP, mdata)
prosodies.r1 <- xtabs(~ two_level_prosody + Condition_Q + Condition_GP, subset(mdata,Reading==1))
prosodies.r2 <- xtabs(~ two_level_prosody + Condition_Q + Condition_GP, subset(mdata,Reading==2))
pander(prosodies.full)
pander(prosodies.r1, caption = "reading 1")
pander(prosodies.r2, caption = "reading 2")
```


# Timing models (ME Linear Regression)
```{r lmerModel,echo=FALSE}
if(!exists("models.timing")){
  models.timing <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(!exists("models.timingNoInt")){
  models.timingNoInt <- lmer(inter_reading ~ GP_condition * Q_condition + (1 + GP_condition * Q_condition | participant) + (1 + GP_condition * Q_condition | item), data=inter_item_timings, control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}

if(!exists("models.timing.Sense")){
  models.timing.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
if(!exists("models.timingNoInt.Sense")){
  models.timingNoInt.Sense <- lmer(inter_reading ~ GP_condition + Q_condition + (1 + GP_condition + Q_condition | participant) + (1 + GP_condition + Q_condition | item), data=subset(inter_item_timings, !(participant %in% gpInsensitive)), control=lmerControl(optCtrl=list(maxfun=2e12) ), REML=FALSE)
}
```
```{r assumptionChecks}
inter_item_timings$resids_main[!is.na(inter_item_timings$inter_reading)] <- residuals(models.timing)
inter_item_timings$resids_main.abs <- abs(inter_item_timings$resids_main)
inter_item_timings$resids_main.sq <-inter_item_timings$resids_main.abs^2
sensitive_timings <- subset(inter_item_timings, !(participant %in% gpInsensitive))

timings_sq_resid <- lm(inter_item_timings$resids_main.sq ~ inter_item_timings$participant, data=inter_item_timings) #ANOVA of the squared residuals
sens_timings_sq_resid <- lm(resids_main.sq ~ participant, data=sensitive_timings) #ANOVA of the squared residuals
```
# Homogeneity of variance
Anova of squared residuals ~ participant for full data and "GP-sensitive" subset
```{r homovar}
anova(timings_sq_resid) #displays the results
anova(sens_timings_sq_resid) #displays the results
```
# Normal distribution of residuals
All participants
`r qqmath(models.timing, id=0.05)`
Only GP-sensitive participants
`r qqmath(models.timing.Sense, id=0.05)`
```
# Models
## Full model
```{r full}
summary(models.timing)
```
## Without interacton 
```{r noInt}
summary(models.timingNoInt)
```
## Only "gp-sensitive"
The following excludes all participants whose mean inter-item reading time for `+GP` items is less than for `-GP` items
### With interaction
```{r gpSense}
summary(models.timing.Sense)
```
## Without interaction
```{r gpSenseNoInt}
summary(models.timingNoInt.Sense)

```

<!--chapter:end:summary.Rmd-->

