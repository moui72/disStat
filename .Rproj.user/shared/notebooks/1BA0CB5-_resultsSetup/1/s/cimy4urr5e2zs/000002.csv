"0","itemsDf <- read_csv("
"0","  ""../csvs/src/items.csv"", "
"0","  col_types = cols("
"0","    OBJ = col_skip(), "
"0","    `P>NP1` = col_skip(), "
"0","    `P>NP2+GP` = col_skip(), "
"0","    `P>NP2-GP` = col_skip(), "
"0","    target = col_character()"
"0","  )"
"0",")"
"0","itemsDf$Item<-itemsDf$target"
"0","itemsDf$target <- NULL"
"0","### load files"
"0","use_old <- FALSE"
"0","old<-""../csvs/irt-rvad-4_11.csv"""
"0","new<-""../csvs/irt-merged.csv"""
"0","raw_file <- read_csv(ifelse(use_old,old,new), "
"0","  col_types = cols("
"0","    Item = col_factor(levels = seq(1,48)), "
"0","    Participant = col_character()"
"0","  )"
"0",")"
"0",""
"0","irt_data <- raw_file"
"0",""
"0","### P 8 is messed up"
"0","irt_data<-subset(irt_data,Participant != 8)"
"0",""
"0","### demographics"
"0","pmeta <- read_csv(""../csvs/p-meta.csv"")"
"2","Parsed with column specification:
cols(
  ID = [32mcol_double()[39m,
  Gender = [31mcol_character()[39m,
  lightReading = [32mcol_double()[39m,
  bookReading = [32mcol_double()[39m,
  Monolingual = [32mcol_double()[39m,
  ease = [32mcol_double()[39m,
  Semester = [31mcol_character()[39m,
  DOTW = [31mcol_character()[39m,
  timeslot = [32mcol_double()[39m,
  DATE = [31mcol_character()[39m
)
"
"0","pmeta$Participant <- pmeta$ID"
"0","irt_data<-merge(pmeta,irt_data,by=""Participant"")"
"0","irt_data$wkd <- ifelse(irt_data$DOTW == ""MONDAY"", 1,"
"0","                ifelse(irt_data$DOTW == ""TUESDAY"", 2, "
"0","                ifelse(irt_data$DOTW == ""WEDNESDAY"", 3, "
"0","                ifelse(irt_data$DOTW == ""THURSDAY"", 4, "
"0","                5))))"
"0",""
"0",""
"0",""
"0","  "
"0","irt_data$cond <- paste("
"0","  ifelse(irt_data$Condition_Q,""Q"",""D""),"
"0","  ifelse("
"0","    irt_data$isFiller,"
"0","    ifelse(irt_data$Condition_GP,""+PP"",""-PP""),"
"0","    ifelse(irt_data$Condition_GP,""+GP"",""-GP"")"
"0","  )"
"0",")"
"0",""
"0","irt_data$Q <- ifelse("
"0","  irt_data$Condition_Q,"
"0","  ""Q"","
"0","  ""D"""
"0",")"
"0","irt_data$GP <- ifelse("
"0","  irt_data$Condition_GP,"
"0","  ""+GP"","
"0","  ""-GP"""
"0",")"
"0",""
"0","irt_data_all <- irt_data ### data before trimming"
"0",""
"0","### exclude 250 < IRTs > 25000"
"0","irt_min <- 250"
"0","irt_max <- 25000"
"0",""
"0","### note how many IRTs are excluded for implausibility"
"0","irt_lo <- subset(irt_data, irt < irt_min)"
"0","irt_hi <- subset(irt_data, irt > irt_max)"
"0",""
"0","### subset to trimmed items"
"0","irt_data <- subset("
"0","  irt_data, "
"0","  irt > irt_min & irt < irt_max"
"0",")"
"0",""
"0","### with fillers"
"0","irt_data_allitems <- irt_data"
"0","irt_fillers <- subset(irt_data,isFiller)"
"0",""
"0","### experimental only"
"0","irt_data <- subset(irt_data,!isFiller)"
"0","irt_data <- (merge(itemsDf, irt_data, by = 'Item'))"
"0",""
"0","### make Participant and Item factors with specified ref levels "
"0","irt_data$Participant<-relevel(as.factor(irt_data$Participant),ref=5)"
"0","irt_data$Item<-relevel(as.factor(irt_data$Item),ref=1)"
"0",""
"0","### winsorize top/bottom 2.5% of data (for normal distrbution, this is +/- 2sd)"
"0","### see: https://sciencing.com/relationship-between-standard-deviations-percentiles-8768703.html"
"0","win_trim=0.025"
"0","irt_data <- irt_data %>% group_by(Participant) %>% mutate(win_irt = winsor(irt, trim=win_trim))"
"0","irt_data$wirt<-irt_data$win_irt"
"0",""
"0","### log 10 transform"
"0","irt_data$wirt.log10 <- log10(irt_data$win_irt)"
"0",""
"0",""
"0","### meta "
"0","json <- read_file(""../meta-4_11.json"")"
"0","meta<-fromJSON(json)"
"0","handset <- read.csv(""../csvs/_SITA_SET_VALUES.csv"")"
"0","meta[meta$file %in% handset$Filename,]$agg <- NA"
"0","meta[meta$file %in% handset$Filename,]$hpf <- NA"
"0","hscount <- sum(handset$Filename %in% meta$file)"
"0",""
"0",""
"0","write_csv(irt_data_allitems,""export/all_data.csv"")"
