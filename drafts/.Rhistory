ccombo <- read_csv("export/ccombo.csv")
kable(ccombo,caption="Combined breaks by condition in reading 2 only") %>%
add_header_above(c(" "=1,"Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T) %>% kable_styling(latex_options = "hold_position")
ccombo
kable(ccombo,caption="Combined breaks by condition in reading 2 only") %>%
add_header_above(c("Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T) %>% kable_styling(latex_options = "hold_position")
kable(ccombo,caption="Combined breaks by condition in reading 2 only", col.names=c("D","Q","D","Q")) %>%
add_header_above(c("Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T) %>% kable_styling(latex_options = "hold_position")
kable(ccombo,caption="Combined breaks by condition in reading 2 only", col.names=c("D","Q","D","Q"),align="c") %>%
add_header_above(c("Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T) %>% kable_styling(latex_options = "hold_position")
rownames(ccombo)<-c("Both", "OBJ", "PP1")
kable(ccombo,caption="Combined breaks by condition in reading 2 only", col.names=c("D","Q","D","Q"),align="c") %>%
add_header_above(c("Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T) %>% kable_styling(latex_options = "hold_position")
kable(ccombo,caption="Combined breaks by condition in reading 2 only", col.names=c("D","Q","D","Q"),align="c") %>%
add_header_above(c(""=1,Non-garden path" = 2, "Garden path"=2)) %>%
kable(ccombo,caption="Combined breaks by condition in reading 2 only", col.names=c("D","Q","D","Q"),align="c") %>%
add_header_above(c(" "=1,"Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T) %>% kable_styling(latex_options = "hold_position")
r2pdata<-droplevels(subset(mdata,Reading==2 & simple2lvl != "NEITHER"))
qdata <- subset(r2pdata,Condition_GP)
ddata <- subset(r2pdata,!Condition_GP)
qpros<-table(qdata$simple2lvl,qdata$Condition_Q) %>%
prop.table(margin=2) %>% `*`(100) %>%
round(1)
colnames(qpros)<-c("D","Q")
dpros<-table(ddata$simple2lvl,ddata$Condition_Q) %>%
prop.table(margin=2) %>% `*`(100) %>%
round(1)
colnames(dpros)<-c("D","Q")
rownames(ccombo)<-c("Both", "OBJ", "PP1")
ccombo<-cbind(dpros,qpros)
write_csv(as.data.frame(ccombo),"export/ccombo.csv")
r2pdata<-droplevels(subset(mdata,Reading==2 & simple2lvl != "NEITHER"))
qdata <- subset(r2pdata,Condition_GP)
ddata <- subset(r2pdata,!Condition_GP)
qpros<-table(qdata$simple2lvl,qdata$Condition_Q) %>%
prop.table(margin=2) %>% `*`(100) %>%
round(1)
colnames(qpros)<-c("D","Q")
dpros<-table(ddata$simple2lvl,ddata$Condition_Q) %>%
prop.table(margin=2) %>% `*`(100) %>%
round(1)
colnames(dpros)<-c("D","Q")
ccombo<-as.data.frame(cbind(dpros,qpros))
rownames(ccombo)<-c("Both", "OBJ", "PP1")
write_csv(,"export/ccombo.csv")
r2pdata<-droplevels(subset(mdata,Reading==2 & simple2lvl != "NEITHER"))
qdata <- subset(r2pdata,Condition_GP)
ddata <- subset(r2pdata,!Condition_GP)
qpros<-table(qdata$simple2lvl,qdata$Condition_Q) %>%
prop.table(margin=2) %>% `*`(100) %>%
round(1)
colnames(qpros)<-c("D","Q")
dpros<-table(ddata$simple2lvl,ddata$Condition_Q) %>%
prop.table(margin=2) %>% `*`(100) %>%
round(1)
colnames(dpros)<-c("D","Q")
ccombo<-as.data.frame(cbind(dpros,qpros))
rownames(ccombo)<-c("Both", "OBJ", "PP1")
write_csv(ccombo,"export/ccombo.csv")
kable(ccombo,caption="Combined breaks by condition in reading 2 only") %>%
add_header_above(c(" "=1,"Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T)%>% kable_styling(latex_options = "hold_position")
kable(ccombo,caption="Combined breaks by condition in reading 2 only",align="c") %>%
add_header_above(c(" "=1,"Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T)%>% kable_styling(latex_options = "hold_position")
knitr::opts_chunk$set(
echo=FALSE,
warning=FALSE,
message=FALSE,
fig.height = 3,
fig.pos="H"
)
options(tinytex.verbose = TRUE)
bgcolor <- "#ffffff"
par(bg = bgcolor)
kable <- function(data,...) {
knitr::kable(data, booktabs = TRUE,...)
}
library(readr)
library(huxtable)
library(dplyr)
library(tidyr)
library(knitr)
library(ggplot2)
library(ggthemes)
library(jsonlite)
library(kableExtra)
library(psych)
library(lme4)
### global plot themeing
theme_set(
theme_tufte() +
theme(
plot.background = element_rect(fill = bgcolor,color=bgcolor),
panel.border = element_blank()
)
)
ccombo <- read_csv("export/ccombo.csv")
rownames(ccombo)<-c("Both", "OBJ", "PP1")
kable(ccombo,caption="Combined breaks by condition in reading 2 only", col.names=c("D","Q","D","Q"),align="c") %>%
add_header_above(c(" "=1,"Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T) %>% kable_styling(latex_options = "hold_position")
kable(ccombo,caption="Combined breaks by condition in reading 2 only", col.names=c("D","Q","D","Q"),align="c") %>%
add_header_above(c(" "=1,"Non-garden path" = 2, "Garden path"=2)) %>%
column_spec(1,bold=T) %>% kable_styling(latex_options = "hold_position")
25.8-25.6
27-14.8
25.8-25.6
27-14.8
bookdown::render_book()
bookdown::render_book('drafts/')
bookdown::render_book('drafts/')
bookdown::render_book('drafts/')
setwd("drafts/")
bookdown::render_book('drafts/')
### counts
irt_data$Participant <- as.factor(irt_data$Participant)
irt_data$Participant <- relevel(irt_data$Participant,ref=9)
recs<-nrow(irt_data)
subjs<-length(levels(irt_data$Participant))
items<-length(levels(irt_data$Item))
expectN <- subjs * items
### utterance lengths
if(!use_old){
### only available in newer files
uls <- append(irt_data$`R1 UL`,irt_data$`R2 UL`)
uls_desc <- describe(uls)
uls_r1_desc <- describe(irt_data$`R1 UL`)
uls_r2_desc <- describe(irt_data$`R2 UL`)
}
knitr::opts_chunk$set(
echo=FALSE,
warning=FALSE,
message=FALSE,
fig.height = 3,
fig.pos="H"
)
options(tinytex.verbose = TRUE)
bgcolor <- "#ffffff"
par(bg = bgcolor)
kable <- function(data,...) {
knitr::kable(data, booktabs = TRUE,...)
}
library(readr)
library(huxtable)
library(dplyr)
library(tidyr)
library(knitr)
library(ggplot2)
library(ggthemes)
library(jsonlite)
library(kableExtra)
library(psych)
library(lme4)
### global plot themeing
theme_set(
theme_tufte() +
theme(
plot.background = element_rect(fill = bgcolor,color=bgcolor),
panel.border = element_blank()
)
)
knitr::opts_chunk$set(
echo=FALSE,
warning=FALSE,
message=FALSE,
fig.height = 3,
fig.pos="H"
)
options(tinytex.verbose = TRUE)
bgcolor <- "#ffffff"
par(bg = bgcolor)
kable <- function(data,...) {
knitr::kable(data, booktabs = TRUE,...)
}
library(readr)
library(huxtable)
library(dplyr)
library(tidyr)
library(knitr)
library(ggplot2)
library(ggthemes)
library(jsonlite)
library(kableExtra)
library(psych)
library(lme4)
### global plot themeing
theme_set(
theme_tufte() +
theme(
plot.background = element_rect(fill = bgcolor,color=bgcolor),
panel.border = element_blank()
)
)
mdata_raw <- read_csv("../csvs/got_prosody.csv")
### remove items where STRONG == NA (these are the items Sita didn't respond to)
mdata <- mdata_raw[!is.na(mdata_raw$STRONG),]
### code for pairs of SUBJ-ITEM
mdata$pair<-paste(mdata$SID,mdata$IID,sep="-")
n1 <- nrow(mdata)
### filter out rows missing its pair
mdata<-mdata %>% group_by(pair) %>% filter(n()>1)
n2<- nrow(mdata)
missingPairs <- n1-n2
mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$condition <- with(mdata,
paste(
ifelse(Condition_Q,"Q","D"),
ifelse(Condition_GP,"+GP","-GP")
)
)
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$pdom <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$odom <- mdata$two_level_prosody %in% c("OBJ", "OBJ > PP1")
mdata$simple2lvl <- ifelse(
mdata$OBJ & mdata$PP1,
"BOTH", ifelse(
mdata$OBJ,
"OBJ",
ifelse(
mdata$PP1,
"PP1",
"NEITHER"
)
)
)
mdata$simple2lvl <- as.factor(mdata$simple2lvl)
mdata<-subset(mdata,SID!=8)
mdata <- droplevels(mdata)
mdata <- subset(mdata,!is.na(OBJ)|!is.na(PP1))
itemsDf <- read_csv(
"../csvs/src/items.csv",
col_types = cols(
OBJ = col_skip(),
`P>NP1` = col_skip(),
`P>NP2+GP` = col_skip(),
`P>NP2-GP` = col_skip(),
target = col_character()
)
)
itemsDf$Item<-itemsDf$target
itemsDf$target <- NULL
### load files
use_old <- FALSE
old<-"../csvs/irt-rvad-4_11.csv"
new<-"../csvs/irt-merged.csv"
raw_file <- read_csv(ifelse(use_old,old,new),
col_types = cols(
Item = col_factor(levels = seq(1,48)),
Participant = col_character()
)
)
irt_data <- raw_file
### P 8 is messed up
irt_data<-subset(irt_data,Participant != 8)
### demographics
pmeta <- read_csv("../csvs/p-meta.csv")
pmeta$Participant <- pmeta$ID
irt_data<-merge(pmeta,irt_data,by="Participant")
irt_data$wkd <- ifelse(irt_data$DOTW == "MONDAY", 1,
ifelse(irt_data$DOTW == "TUESDAY", 2,
ifelse(irt_data$DOTW == "WEDNESDAY", 3,
ifelse(irt_data$DOTW == "THURSDAY", 4,
5))))
irt_data$cond <- paste(
ifelse(irt_data$Condition_Q,"Q","D"),
ifelse(
irt_data$isFiller,
ifelse(irt_data$Condition_GP,"+PP","-PP"),
ifelse(irt_data$Condition_GP,"+GP","-GP")
)
)
irt_data$Q <- ifelse(
irt_data$Condition_Q,
"Q",
"D"
)
irt_data$GP <- ifelse(
irt_data$Condition_GP,
"+GP",
"-GP"
)
irt_data_all <- irt_data ### data before trimming
### exclude 250 < IRTs > 25000
irt_min <- 250
irt_max <- 25000
### note how many IRTs are excluded for implausibility
irt_lo <- subset(irt_data, irt < irt_min)
irt_hi <- subset(irt_data, irt > irt_max)
### subset to trimmed items
irt_data <- subset(
irt_data,
irt > irt_min & irt < irt_max
)
### with fillers
irt_data_allitems <- irt_data
irt_fillers <- subset(irt_data,isFiller)
### experimental only
irt_data <- subset(irt_data,!isFiller)
irt_data <- (merge(itemsDf, irt_data, by = 'Item'))
### make Participant and Item factors with specified ref levels
irt_data$Participant<-relevel(as.factor(irt_data$Participant),ref=5)
irt_data$Item<-relevel(as.factor(irt_data$Item),ref=1)
### winsorize top/bottom 2.5% of data (for normal distrbution, this is +/- 2sd)
### see: https://sciencing.com/relationship-between-standard-deviations-percentiles-8768703.html
win_trim=0.025
irt_data <- irt_data %>% group_by(Participant) %>% mutate(win_irt = winsor(irt, trim=win_trim))
irt_data$wirt<-irt_data$win_irt
### log 10 transform
irt_data$wirt.log10 <- log10(irt_data$win_irt)
### meta
json <- read_file("../meta-4_11.json")
meta<-fromJSON(json)
handset <- read.csv("../csvs/_SITA_SET_VALUES.csv")
meta[meta$file %in% handset$Filename,]$agg <- NA
meta[meta$file %in% handset$Filename,]$hpf <- NA
hscount <- sum(handset$Filename %in% meta$file)
write_csv(irt_data_allitems,"export/all_data.csv")
irt_data$ID <- paste0(irt_data$Participant,"-",irt_data$Item)
mdata$ID <- paste0(mdata$SID,"-",mdata$IID)
irt_data <- subset(irt_data, ID %in% mdata$ID)
mdata <- subset(mdata,ID %in% irt_data$ID)
### counts
irt_data$Participant <- as.factor(irt_data$Participant)
irt_data$Participant <- relevel(irt_data$Participant,ref=9)
recs<-nrow(irt_data)
subjs<-length(levels(irt_data$Participant))
items<-length(levels(irt_data$Item))
expectN <- subjs * items
### utterance lengths
if(!use_old){
### only available in newer files
uls <- append(irt_data$`R1 UL`,irt_data$`R2 UL`)
uls_desc <- describe(uls)
uls_r1_desc <- describe(irt_data$`R1 UL`)
uls_r2_desc <- describe(irt_data$`R2 UL`)
}
### note properties
irt_props_all <- describe(irt_data$irt)
irt_props <- describe(irt_data$irt)
wirt_props <- describe(irt_data$win_irt)
### sd by condition table
sdByConditionLong <- aggregate(
irt_data$win_irt,
by=list(
"Q"=irt_data$Q,
"GP"=irt_data$GP
),
FUN=sd
)
### means by condition table
meansByConditionLong <- aggregate(
irt_data$win_irt,
by=list(
"Q"=irt_data$Q,
"GP"=irt_data$GP
),
FUN=mean
)
names(meansByConditionLong)[3] <- "mean"
### concise means by condition table
meansByCondition <- meansByConditionLong %>% spread(Q,mean)
names(meansByCondition)[1] <- "Condition"
### add sd and se to meansByConditionLong
meansByConditionLong$sd<-sdByConditionLong$x
meansByConditionLong$se<-sdByConditionLong$x/sqrt(irt_props$n)
### difference in condition means
diffs<-list(Condition="Increase", `D`=diff(meansByCondition$`D`), `Q`= diff(meansByCondition$`Q`))
meansByCondition<-rbind(meansByCondition, diffs)
cdiff <- meansByCondition$`D`[3]-meansByCondition$`Q`[3]
### participant means by condition
pmeansByCondition <- aggregate(
irt_data$irt,
by=list(
"Condition"=irt_data$cond,
"Participant"=irt_data$Participant
),
FUN=mean
) %>% spread(Condition,x)
pmeansByCondition$pattern <- (
pmeansByCondition$`Q +GP` - pmeansByCondition$`Q -GP` <
pmeansByCondition$`D +GP` - pmeansByCondition$`D -GP`
)
### simple P means
spm <- aggregate(
irt_data$irt,
by=list(
"Participant"=irt_data$Participant
),
FUN=mean
)
prosDescrip <- describe(mdata)
tot<-as.data.frame(xtabs( ~ Condition_GP + Condition_Q, data=mdata))
orderMap <- read_csv(
"../csvs/src/order-p-map.csv",
col_types = cols(
ID = col_character(),
Order = col_character(),
LIST = col_character()
)
)
orderMap$Participant <- orderMap$ID
orderMap$ID <- NULL
mdata<-merge(mdata,orderMap,by="Participant")
mdata$Participant <- mdata$SID
### counts
irt_data$Participant <- as.factor(irt_data$Participant)
irt_data$Participant <- relevel(irt_data$Participant,ref=9)
recs<-nrow(irt_data)
subjs<-length(levels(irt_data$Participant))
items<-length(levels(irt_data$Item))
expectN <- subjs * items
### utterance lengths
if(!use_old){
### only available in newer files
uls <- append(irt_data$`R1 UL`,irt_data$`R2 UL`)
uls_desc <- describe(uls)
uls_r1_desc <- describe(irt_data$`R1 UL`)
uls_r2_desc <- describe(irt_data$`R2 UL`)
}
### note properties
irt_props_all <- describe(irt_data$irt)
irt_props <- describe(irt_data$irt)
wirt_props <- describe(irt_data$win_irt)
### sd by condition table
sdByConditionLong <- aggregate(
irt_data$win_irt,
by=list(
"Q"=irt_data$Q,
"GP"=irt_data$GP
),
FUN=sd
)
### means by condition table
meansByConditionLong <- aggregate(
irt_data$win_irt,
by=list(
"Q"=irt_data$Q,
"GP"=irt_data$GP
),
FUN=mean
)
names(meansByConditionLong)[3] <- "mean"
### concise means by condition table
meansByCondition <- meansByConditionLong %>% spread(Q,mean)
names(meansByCondition)[1] <- "Condition"
### add sd and se to meansByConditionLong
meansByConditionLong$sd<-sdByConditionLong$x
meansByConditionLong$se<-sdByConditionLong$x/sqrt(irt_props$n)
### difference in condition means
diffs<-list(Condition="Increase", `D`=diff(meansByCondition$`D`), `Q`= diff(meansByCondition$`Q`))
meansByCondition<-rbind(meansByCondition, diffs)
cdiff <- meansByCondition$`D`[3]-meansByCondition$`Q`[3]
### participant means by condition
pmeansByCondition <- aggregate(
irt_data$irt,
by=list(
"Condition"=irt_data$cond,
"Participant"=irt_data$Participant
),
FUN=mean
) %>% spread(Condition,x)
pmeansByCondition$pattern <- (
pmeansByCondition$`Q +GP` - pmeansByCondition$`Q -GP` <
pmeansByCondition$`D +GP` - pmeansByCondition$`D -GP`
)
### simple P means
spm <- aggregate(
irt_data$irt,
by=list(
"Participant"=irt_data$Participant
),
FUN=mean
)
prosDescrip <- describe(mdata)
tot<-as.data.frame(xtabs( ~ Condition_GP + Condition_Q, data=mdata))
orderMap <- read_csv(
"../csvs/src/order-p-map.csv",
col_types = cols(
ID = col_character(),
Order = col_character(),
LIST = col_character()
)
)
orderMap$Participant <- orderMap$ID
orderMap$ID <- NULL
mdata<-merge(mdata,orderMap,by="Participant")
write_csv(mdata,"export/prosody_data.csv")
versiontab <- mdata %>%
filter(!duplicated(Participant)) %>%
with(table("Version"=LIST,Order)) %>%
addmargins()
rownames(versiontab)[1:4]<-paste("Version", rownames(versiontab))
bookdown::render_book()
bookdown::render_book(".")
