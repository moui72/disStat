```{r results, echo=F}
library(ggplot2)
library(ggthemes)
library(extrafont)
library(psych)

loadfonts("pdf")
knitr::opts_chunk$set(
  echo=FALSE, 
  warning=FALSE, 
  message=FALSE, 
  fig.height = 3, 
  fig.pos="H"
)

bgcolor <- "#ffffff"
par(bg = bgcolor)

kable <- function(...) {
  knitr::kable(booktab = TRUE,...)
}

### global plot themeing
theme_set(
  theme_tufte(base_size = 12, base_family="Georgia") + 
    theme(
      plot.background = element_rect(fill = bgcolor,color=bgcolor),
      panel.border = element_blank()
    )
)
```
# Results and discussion

This section reports various descriptions and analyses of the recordings obtained. The reported results include the effect of Speech Act (declarative/D vs. interrogative/Q) and PP2 Status (argument/Arg vs. modifier/Mod) on the location of prosodic breaks, as well as on time spent reflecting upon a sentence between readings, which I call inter-reading time (IRT). In order to evaluate the extent to which participants adhered to the protocol as intended, i.e., began to read immediately for Reading 1 as opposed to producing a considered reading in Reading 2, the delay for which a sentence is displayed before a participant begins to read it is compared for Reading 1  (R1 delay) vs. Reading 2 (R2 delay[^r2d]). The prosodic patterns for participants with especially fast and especially slow R1 delays are presented as a way of investigating the extent to which individual differences might impact those patterns, and as a further exploration of the success of the protocol instructions in producing the intended behavior.

[^r2d]: Note that R2 delay is subsumed by but not synonymous with IRT; IRT includes lag time after R1 is completed but before the recording for R2 begins. This distinction is laid out in more detail in Section \@ref(irtRes).

## Data for analysis

Data for 32 total participants were analyzed. Given 4 versions of the experiment and 2 possible orderings there would ideally be 4 participants per version-order combination. Ultimately, 3 participants had to be excluded for different reasons, resulting in the distribution is as shown in Table \@ref(tab:vtab)[^xtra]. Participants were removed for the following reasons: one for use of a non-standard dialect, one for extremely disfluent oral reading, and one who was missing more than half of the expected recordings because of a system crash during the procedure.

[^xtra]: The two 5-count cells include 2 additional participants whose data were collected in pursuit of another full set (i.e., towards an expansion to 40 participants) that was not completed due to a lack of participant sign-ups.

```{r vtab, echo=F}
library(kableExtra)
library(readr)
library(dplyr)


mdata <- read_csv("export/prosody_data.csv")

versiontab <- mdata %>% 
  filter(!duplicated(Participant)) %>%
  with(table("Version"=LIST,Order)) %>%
  addmargins() 

rownames(versiontab)[1:4]<-paste("Version", rownames(versiontab))
versiontab %>% kable(
  caption="No. of participants per version-order combination",
  col.names = c("1", "2", "Sum"),
  align="c"
) %>% kable_styling() %>% 
  add_header_above(c(" "=1, "Order"=2, " "=1)) %>%
  kable_styling(latex_options = c("hold_position"))
```

Some of the expected 3072 recordings (32 participants x 48 items (16 experimental and 32 filler) x 2 readings) were not used due to intrusive noise duringthe recording session. Additionally, data were also excluded from analysis if any (Reading 1/Reading 2 pair) was missing; there were 9 such incomplete pairs excluded. Without analyzable data from both members of a pair, it is difficult to determine the extent to which the elicitation protocol was executed as intended (i.e., the extent of preview for Reading 1 vs. Reading 2). 

For experimental items, 978 recordings were subjected to prosodic analysis, constituting 95.6% of the utterances elicited. Because IRT data considered utterances in pairs (Reading 1/Reading 2) rather than separately, the database for response timing took in 489 datapoints.

```{r rvtab, echo=F}
library(tidyr)
tot<-as.data.frame(xtabs( ~ PP2Status + SpeechAct, data=mdata))
gtot <- tot

totDisp <- gtot %>% as.data.frame() %>%
  spread(SpeechAct,Freq) 


kable(
  totDisp,
  caption="Number of recordings analyzed, as a function of Speech Act and PP2 Status",
  align="c",
  col.names=c(" ","D","Q")
) %>% kable_styling(latex_options = c("hold_position"))
```

## Prosodic break patterns {#results-prosody}

```{r byGPr2}
library(scales)
### r2
r2data <- subset(mdata,Reading==2)

pp1tab<-xtabs(PP1 ~ PP2Status + SpeechAct, data=r2data)
objtab<-xtabs(OBJ ~  PP2Status + SpeechAct, data=r2data)
tot<-as.data.frame(xtabs( ~  PP2Status + SpeechAct, data=r2data))


pp1<-as.data.frame(pp1tab)
pp1$tot<-tot$Freq
pp1$pct <- pp1$Freq/pp1$tot
pp1$pretty <- paste0(
  pp1$Freq, 
  " (", 
  sprintf("%.1f",pp1$pct * 100), 
  "%)"
)
pp1disp <- pp1 %>%
  subset(select=c(
    "PP2Status",
    "SpeechAct",
    "pretty"
  )) %>% 
  spread(SpeechAct,pretty)

obj<-as.data.frame(objtab)
obj$tot<-tot$Freq
obj$pct <- obj$Freq/obj$tot
obj$pretty <- sprintf("%s (%d)",percent(obj$pct),obj$Freq)
objdisp <- obj %>%
  subset(select=c(
    "PP2Status",
    "SpeechAct",
    "pretty"
  )) %>% 
  spread(SpeechAct,pretty)

pp1obj <- cbind(pp1disp,objdisp[2:3])

r2pp1<-pp1disp
r2obj<-objdisp


### r1
r1data <- subset(mdata,Reading==1)

pp1tab<-xtabs(PP1 ~ PP2Status + SpeechAct, data=r1data)
objtab<-xtabs(OBJ ~  PP2Status + SpeechAct, data=r1data)
tot<-as.data.frame(xtabs( ~  PP2Status + SpeechAct, data=r1data))



pp1<-as.data.frame(pp1tab)
pp1$tot<-tot$Freq
pp1$pct <- pp1$Freq/pp1$tot
pp1$pretty <- paste0(
  pp1$Freq, 
  " (", 
  sprintf("%.1f",pp1$pct * 100), 
  "%)"
)
pp1disp <- pp1 %>%
  subset(select=c(
    "PP2Status",
    "SpeechAct",
    "pretty"
  )) %>% 
  spread(SpeechAct,pretty)

obj<-as.data.frame(objtab)
obj$tot<-tot$Freq
obj$pct <- obj$Freq/obj$tot
obj$pretty <- sprintf("%s (%d)",percent(obj$pct),obj$Freq)
objdisp <- obj %>%
  subset(select=c(
    "PP2Status",
    "SpeechAct",
    "pretty"
  )) %>% 
  spread(SpeechAct,pretty)

pp1objr1 <- cbind(pp1disp,objdisp[2:3])

r1pp1<-pp1disp
r1obj<-objdisp

pp1<-cbind(r1pp1,r2pp1[2:3])


obj<-cbind(r1obj,r2obj[2:3])

```

In what follows, the distrbution of OBJ breaks and PP1 breaks are reported as a function of the four sentence types created by the materials design (D/Q x Arg/Mod), for each of Reading 1 and Reading 2. Then, the patterns of breaks over the two positions are considered, before moving to statistical analysis. Note that while breaks after the construction verb were reported, these breaks were exceptionally rare and occured in only 8% of recordings, so they have been set aside. The break locations are indicated with a % symbol in (@breakpos).

  (@breakpos) !["... stick the letter % in the mailbox % into the proper stack."](breakpos.png)

As noted in section \@ref(sec:sita), the results reported are based on the subjective judgements of a trained linguist who was naive to the purposes and hypotheses underlying the research.

### Individual break patterns

```{r obj}
kable(
  obj,
  caption="Percent occurance of OBJ break (frequency of occurence in parenthesis) as a function of sentence type and Reading",
  col.names = c("", "D", "Q","D", "Q"),
  align="c"
) %>% 
  add_header_above(c(" "=1,"Reading 1"=2,"Reading 2"=2)) %>% 
  kable_styling(latex_options = c("hold_position"))
```

The presence of the OBJ break was sensitive to both Speech Act and reading, with Reading 2 showing a different distribution across the D vs. Q distinction than the Reading 1 recordings. 

```{r pp1}
kable(
  pp1,
  caption="PP1 break by condition and reading",
  col.names = c("", "D", "Q","D", "Q"),
  align="c"
) %>% 
  add_header_above(c(" "=1,"Reading 1"=2,"Reading 2"=2)) %>% 
  kable_styling(latex_options = c("hold_position"))
```

The PP1 break was almost always present for cases where PP2 was an argument; and it was present substantially less often, but still there a majority of the time, for cases where PP2 could be interpreted as a modifier. Speech act and reading did not appear to impact the overall distribution of the PP1 break.

### Combined break patterns{#bbr}

When looking at both breaks together, a sentence could have one of four patterns: both the OBJ and PP1 break present; only OBJ present; only PP1 present; or neither break present. There were only 5 cases where neither was present, and those were omitted in the tables of prosodic patterns.

```{r r2combobreaksBycondpre}
r2pdata<-droplevels(subset(mdata,Reading==2 & simple2lvl != "NEITHER"))
qdata <- subset(r2pdata,PP2Status=="Arg")
ddata <- subset(r2pdata,PP2Status=="Mod")
qpros<-table(qdata$simple2lvl,qdata$SpeechAct) %>%
  prop.table(margin=2) %>% apply(2,percent)

dpros<-table(ddata$simple2lvl,ddata$SpeechAct) %>%
  prop.table(margin=2) %>% apply(2,percent)

ccombo<-as.data.frame(cbind(dpros,qpros))


r1pdata<-droplevels(subset(mdata,Reading==1 & simple2lvl != "NEITHER"))
qdata <- subset(r1pdata,PP2Status=="Arg")
ddata <- subset(r1pdata,PP2Status=="Mod")
qpros<-table(qdata$simple2lvl,qdata$SpeechAct) %>%
  prop.table(margin=2) %>% apply(2,percent)


dpros<-table(ddata$simple2lvl,ddata$SpeechAct) %>%
  prop.table(margin=2) %>% apply(2,percent)

cccombo<-as.data.frame(cbind(dpros,qpros))


bothrbothb <- cbind(ccombo,cccombo)
bothrbothb <- bothrbothb %>% as_tibble(.name_repair = "unique")
row.names(bothrbothb) <- c("2Both","1OBJ","3PP1")
bothrbothb<-arrange(bothrbothb,row.names(bothrbothb))
row.names(bothrbothb) <- c("OBJ only","Both","PP1 only")

```


```{r bothbreaks}
kable(
  bothrbothb,
  caption="Percent occurence of both breaks as a function of sentence type and Reading",
  align="c",
  col.names=rep(c("D","Q"),4)
) %>%
  add_header_above(c(" "=1,rep(c("Mod" = 2, "Arg"=2),2))) %>%
  add_header_above(c(" "=1, "Reading 1" = 4, "Reading 2" = 4)) %>%
  column_spec(1,bold=T)%>% kable_styling(latex_options = "hold_position")

```

Table \@ref(tab:bothbreaks) shows that for Arg sentences, there are very few instances with the OBJ-only pattern (0.8% in declaratives, 2.5% in interrogatives); whereas that pattern is fairly frequent for Mod sentences (31.1% in declaratives, 31.4% in interrogatives). The pattern with both breaks is somewhat more common for Arg sentences (72.1% in declaratives, 71.7% in interrogatives) than Mod (54.1% in declaratives, 43.0% in interrogatives). The PP1-only pattern occurs at about the same rate in Arg interrogatives (25.8%) as in Mod interrogatives (25.6%) and Arg declaratives (27%), but is noticeably less common for Mod declaratives (14.8%). These proportions are visually represented in figure \@ref(fig:bothbreaks2).

```{r bothbreaks2, fig.cap="Break pattern as a function of sentence type and Reading",fig.pos="!H", fig.height=3.5}
mdata$SentenceType <- paste(mdata$SpeechAct,mdata$PP2Status)
adata <- subset(mdata,simple2lvl!="NEITHER")
adata$reading <- paste("Reading", adata$Reading)

ggplot(adata,    
    aes(
      x=reorder(SentenceType,
                ifelse(SentenceType=="D Arg",1,
                       ifelse(SentenceType=="Q Arg",2,
                              ifelse(SentenceType=="Q Arg",3,4)))
      ),
      y=..count..,
      fill=reorder(
        simple2lvl,
        ifelse(simple2lvl=="PP1", 3, ifelse(simple2lvl=="OBJ",1,2))
      )
    )) +
  geom_bar(position="fill",color="black",width=0.5) +
  labs(fill="Pattern",x=" ",y=" ") +
  facet_grid(cols = vars(reading)) +
  scale_y_continuous(labels=scales::percent) + 
  scale_fill_brewer(breaks=c("OBJ", "BOTH", "PP1"), palette="Greys")
```

### Break Dominance

The relative strength of the PP1 and OBJ breaks was also collected. Figure \@ref(fig:bdom) incorporates this information, where “PP1 dominance” means that the PP1 break was reported to be stronger than the OBJ break; “OBJ” dominance means the opposite; and “Equal strength” means that neither break was reported to be stronger than the other (the 5 instances with no breaks were again omitted).

When looking at the combined break patterns, one can think of there being three bins: the PP1 bin, the OBJ bin, and a neutral bin between them. In Section \@ref(sec:bbr), the neutral bin containing instances of both breaks occuring is robust. This break dominance analysis distributes most of those cases that have both breaks into either the OBJ or PP1 bin, depending on which break is more prominent. When the breaks are of equal strength, they remain in the middle bin, but there are much fewer such cases when looking at dominance instead of simple occurence. 

```{r bdom, fig.cap="Percent break dominance occurence as a function of sentence type and Reading",fig.pos="H", fig.height=3.5}
library(ggplot2)
library(ggthemes)
library(extrafont)
adata <- subset(mdata,simple2lvl!="NEITHER")
adata$reading <- paste("Reading", adata$Reading)
adata$dom <- ifelse(adata$pdom,"PP1",ifelse(adata$odom,"OBJ","Equal strength"))

ggplot(adata,    
    aes(
      x=reorder(SentenceType,
                ifelse(SentenceType=="D Arg",1,
                       ifelse(SentenceType=="Q Arg",2,
                              ifelse(SentenceType=="Q Arg",3,4)))
      ),
      y=..count..,
      fill=reorder(
        dom,
        ifelse(simple2lvl=="OBJ", 1, ifelse(simple2lvl=="PP1",3,2))
      )
    )) +
  geom_bar(position="fill",color="black",width=0.5) +
  labs(fill="Dominant break",x="Sentence Type",y="Percent where dominant") +
  facet_grid(cols = vars(reading)) +
  scale_y_continuous(labels=scales::percent) + 
  scale_fill_brewer(breaks=c("PP1", "Equal strength", "OBJ"), palette="Greys") 
```

Figure \@ref(fig:bdom) clearly shows a robust effect of PP2 status on break dominance, and little to no impact of reading or speech act.

### Regression models of prosodic break patterns

A number of mixed effects logistic regression models support the general observations above. Models predicting PP1 break, OBJ break, PP1 break dominance and OBJ break dominance are reported. All models include crossed random effect intercepts (participant and item), but due to convergence errors, no random slopes are included. 

The intercept always represents the Mod sentence type, which is not expected to present any particular difficulty to the reader, since the Mod PP2 Status is compatible with what is assumed to be the running parse when it is encountered (i.e., PP1 has been interpreted as the goal argument of the verb, and PP2 does not disrupt that interpretation). When Speech Act is included in the model, the intercept represents the declarative sentence type. In this way, the more complex sentence types are compared to the simplest available in the model.

In each case, the model with the lowest reported AIC was selected from a set of models. Model comparisons did not always find significant differences between the more complex models. In each case, the selected model was compared to a minimal model where  where fixed effect variables were removed, leaving only an intercept, and all reported models represent improvement over the minimal model to a statistically significant degree. That comparison is reported for each model. All regression models were run using the lme4 R package (@R-lme4), with p-values calculated via the lmerTest R package (@R-lmerTest).

#### Break occurence

Table \@ref(tab:objMod) shows a model predicting the occurrence of an OBJ break with estimates for the coefficients of the fixed effects of Reading 2, PP2 and the interaction between Reading and PP2 status. A comparison between the reported model and a minimal one found that the reported model was better with a high level of confidence (AIC~MIN~=1068.0, AIC~BEST~=1031.6, $\chi^2$(2)=30.5, p < 0.001).

```{r objMod}
csv <- 'Outcome: OBJ break,Estimate,Std. Error,p
"D Mod, Reading 1 (Intercept)",1.39,0.45,< 0.01
Reading 2,0.11,0.23,0.62
Arg,-1.98,0.5,< 0.001
Reading 2 x Arg,0.81,0.32,< 0.05'

tab <- read_csv(csv)

tab %>% kable(
  align="rccc", 
  caption="Mixed effects logistic regression model predicting OBJ break occurrence"
) %>% 
  row_spec(0,align="c") %>%
  kable_styling(latex_options = "hold_position")
```

The log odds[^logodds] of an OBJ break for Mod Reading 1 is 1.39 (std. error = 0.45, p < 0.01). The log odds of that break increased in Reading 2 but the increase was not statistically significant. PP2 arguments reduced the log odds of an OBJ break compared to PP2 modifiers by a robust amount, but less so in Reading 2 than in Reading 1.

[^logodds]:  Log odds is, in this case, the natural log of the odds ratio, so the log odds of A is log~e~(P(A)/P(¬A)). A log odds of 1.39 translates to an odds ratio of 2.4:1 (1.39^e^=2.4) and a probability of 71% (2.4/(1+2.4)=0.71).

The best model for predicting the occurrence for the PP1 break was one where only PP2 status was included as a predictor. The chosen model was again significantly better than the minimal model (AIC~MIN~=855.6, AIC~BEST~=629.6, $\chi^2$(1)=228.0, p < 0.001).

```{r pp1Mod}
csv <- '
Outcome: PP1 break,Estimate,Std. Error,p
"Mod (Intercept)",0.96,0.3,< 0.01
Arg,4.12,0.44,< 0.001
'

tab <- read_csv(csv)

tab %>% kable(
  align="rccc",
  caption="Mixed effects logistic regression model predicting PP1 break occurrence"
) %>% 
  row_spec(0,align="c") %>%
  kable_styling(latex_options = "hold_position")
```

Sentences with argument PP2s had greatly increased log odds of a PP1 break compared to ones with modifier PP2s.

#### Break dominance

Models were also run for predicting break dominance. Table \@ref(tab:odom) reports the best model for predicting OBJ break dominance. The best model was one with fixed effects for reading and PP2 status. There was no statistically significant effect of Speech Act on OBJ break dominance.

```{r odom}
csv <- '
Outcome: OBJ dominance,Estimate,Std. Error,p
"Mod, Reading 1 (Intercept)",-0.16,0.32,0.62
Reading 2,0.4,0.16,< 0.05
Arg,-2.32,0.18,< 0.001
'

tab <- read_csv(csv)

tab %>% kable(
  align="rccc",
  caption="Mixed effects logistic regression model predicting OBJ break dominance"
) %>% 
  row_spec(0,align="c") %>%
  kable_styling(latex_options = "hold_position")
```

Table \@ref(tab:pdom) reports the best model for predicting PP1 break dominance. Unlike the model for predicting OBJ break dominance, the best model for predicting PP1 break dominance includes speech act as a predictor. The best model is one with fixed effects for reading, Speech Act, and PP2 Status.

```{r pdom}
csv <- '
Outcome: PP1 dominance,Estimate,Std. Error,p
"D Mod, Reading 1 (Intercept)",-0.19,0.33,0.57
Reading 2,-0.38,0.15,< 0.05
Q,0.31,0.15,< 0.05
Arg,2.2,0.17,< 0.001
'

tab <- read_csv(csv)

tab %>% kable(
  align="rccc",
  caption="Mixed effects logistic regression model predicting PP1 break dominance"
) %>% 
  row_spec(0,align="c") %>%
  kable_styling(latex_options = "hold_position")
```

This model was better than a minimal model  (AIC~MIN~=1290.4, AIC~BEST~=1078.8, $\chi^2$(3)=217.59, p < 0.001). PP1 break dominance was much more likely for sentence with argument PP2s than sentences with modifier PP2s, with interrogatives having slightly increased log odds of PP1 break dominance. Log odds of PP1 break dominance were slightly less in Reading 2 than Reading 1.

Because reading was a significant predictor for 3 of the 4 models reported, and there are theoretical reasons to believe that Reading 2 is more representative of the natural or intended prosody of the reader, models were also run predicting PP1 dominance and OBJ dominance for Reading 2 data only. In both cases, the best model had the same structure: fixed effects of speech act and PP2 status, with no interaction term.

```{r r2dom}
csv <- '
,Estimate,Std. Err,p,Estimate,Std. Err,p
D Mod (Intercept),0.66,0.24,< 0.01,-0.97,0.27,< 0.001
Q,-0.3,0.22,0.16,0.35,0.22,0.1
Arg,-2.07,0.24,< 0.001,2.15,0.24,< 0.001
'

tab <- read_csv(csv)

tab %>% kable(
  col.names=c("(Reading 2 only)","Estimate","Std. Err","p","Estimate","Std. Err","p"),
  align="rccc",  caption="Mixed effects logistic regression models predicting break dominance in Reading 2"
) %>% 
  add_header_above(c(" "=1, "Outcome: OBJ Dominance" = 3, "Outcome: PP1 Dominance" = 3)) %>%
  row_spec(0,align="c") %>%
  kable_styling(latex_options = "hold_position")
```

For both OBJ dominance and PP2 dominance, the main effect of speech act is non-significant at the p < 0.05 level, but its inclusion marginally improves the fit of each model.

### On Reading 1 delay

Reading 1 (R1) delay is the amount of time between the initial display of a sentence and the start of phonation. Participants' median R1 delay ranged from 0.6s to 1.6s with a standard deviation of 0.25s. As a way of analyzing the protocol, and the extent to which participants performed as expected, participants were categorized based on their median R1 delay. In what follows, a fast median R1 delay was shorter than or equal to 0.9s, and a slow one was longer than 1.05s, resulting in 12 participants per category. Ten participants had R1 delays between those values, categorized as "normal," and ignored. These calculations were done over Reading 1 of experimental items (n = 489).

```{r facet, fig.cap="Plot of pattern proportions per condition",fig.height=4,fig.pos="H"}

hidel <- 1051
lodel <- 901

catdes <- sprintf("FAST median R1 delay < %0.2fs. SLOW median R1 delay > %0.2fs",lodel/1000,hidel/1000)

adata <- read_csv("../drafts/export/prosody_with_r1delcat.csv")
adata$reading <- paste("Reading", adata$Reading)
pdata <- subset(adata, r1DelCat != "NORMAL")

ggplot(pdata,    
    aes(
      x=condition,
      y=..count..,
      fill=reorder(
        simple2lvl,
        ifelse(simple2lvl=="PP1", 1, ifelse(simple2lvl=="OBJ",3,2))
      )
    )) +
  geom_bar(position="fill",color="black",width=0.5) +
  labs(fill="Pattern",x=" ",y=" ",caption="FAST n=12, SLOW n = 12") +
  facet_grid(rows = vars(reading),cols=vars(r1DelCat)) +
  scale_y_continuous(labels=scales::percent) + 
  scale_fill_brewer(breaks=c("PP1", "BOTH", "OBJ"), palette="Greys") +
  theme_tufte(base_size = 12, base_family="Georgia")
```

```{r rsplit}

r1data<-subset(adata,Reading==1)

fast <- subset(r1data,r1DelCat == "FAST")
slow <- subset(r1data,r1DelCat == "SLOW")

fastTabN <- xtabs(~simple2lvl + condition, data=fast) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)  
slowTabN <- xtabs(~simple2lvl + condition, data=slow) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)


fastTab <- xtabs(~simple2lvl + condition, data=fast) %>% 
  prop.table(margin=2) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)
slowTab <- xtabs(~simple2lvl + condition, data=slow) %>% 
  prop.table(margin=2) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)


tab<-cbind(fastTab,slowTab[2:5])
ntab<-cbind(fastTabN,slowTabN[2:5])
tab[2:9]  <- format(tab[2:9] * 100,nsmall=1,digits=1)
ntab[2:9] <- format(ntab[2:9],digits=0)


tab$m  <- "%"
ntab$m <- "n"
tab <- rbind(tab,ntab)

colnames(tab)[1] <- "Pattern"
colnames(tab)[6:9] <- paste0(colnames(tab)[6:9],".slow")
tab <- arrange(tab,Pattern)
tab <- tab %>% select(Pattern,m,everything())

r1tab<-tab
```
```{r r2split}
r2data<-subset(adata,Reading==2)

fast <- subset(r2data,r1DelCat == "FAST")
slow <- subset(r2data,r1DelCat == "SLOW")

fastTabN <- xtabs(~simple2lvl + condition, data=fast) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)  
slowTabN <- xtabs(~simple2lvl + condition, data=slow) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)

fastTab <- xtabs(~simple2lvl + condition, data=fast) %>% 
  prop.table(margin=2) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)
slowTab <- xtabs(~simple2lvl + condition, data=slow) %>% 
  prop.table(margin=2) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)


tab<-cbind(fastTab,slowTab[2:5])
ntab<-cbind(fastTabN,slowTabN[2:5])
tab[2:9]  <- format(tab[2:9] * 100,nsmall=1,digits=1)
ntab[2:9] <- format(ntab[2:9],digits=0)


tab$m  <- "%"
ntab$m <- "n"
tab <- rbind(tab,ntab)

colnames(tab)[1] <- "Pattern"
colnames(tab)[6:9] <- paste0(colnames(tab)[6:9],".slow")
tab <- arrange(tab,Pattern)
tab <- tab %>% select(Pattern,m,everything())


tab <- rbind(r1tab,tab)

tab %>% kable(
  align="c",
  caption="Simple break pattern by condition and R1 delay category",
  col.names=c(" "," ", rep(c("D -GP","Q -GP", "D +GP", "Q +GP"),2)), 
  digits=1
) %>% kable_styling() %>%
  column_spec(6,border_right = T) %>%
  collapse_rows(columns = 1) %>%
  add_header_above(c(" " = 2,"FAST (n=12)"=4,"SLOW (n=12)"=4)) %>%
  pack_rows(index = c("Reading 1" = 6, "Reading 2" = 6))

xdata <- subset(adata,r1DelCat != "NORMAL")
r1df <- ftable(xtabs(~Participant + simple2lvl + r1DelCat, subset(xdata,Reading==1))) %>% as.data.frame
r2df <- ftable(xtabs(~Participant + simple2lvl + r1DelCat, subset(xdata,Reading==2))) %>% as.data.frame

dfs <- subset(r1df %>% spread(simple2lvl,Freq), BOTH + OBJ + PP1 > 0)
dfs <- cbind("r1"=dfs,"r2"=subset(r2df %>% spread(simple2lvl,Freq), BOTH + OBJ + PP1 > 0))
# just delete rows in df where all 3 freqs are 0
```

There appears to be a clear difference between the participants categorized as having fast or slow R1 delays in the extent to which they used both breaks, with the slow category of participants preferring more breaks than the fast category of participants. There also seems to be a larger increase in usage of both breaks from Reading 1 to Reading 2 for the fast category than for the slow.

>>> TODO add hypothesis testing and more detail for the above statements

Discussion of prosodic break patterns
Throughout the analysis of break patterns, PP2 status was the most robust predictor of OBJ and PP1 break occurrence and their relative strengths. The OBJ break was more frequent and more frequently dominant for sentences with a PP2 that was an argument than those with a PP2 that could be a modifier; inversely, the PP1 break was more frequent and more frequently dominant for sentences with a PP2 that was interpretable as a modifier than those with a PP2 that was an argument.

Essentially, the expected patterns can be described as in (@breakpat1) and (@breakpat2), where % represents a robust prosodic break, and @ represents a weaker break or no break.

  (@breakpat1) ![... stick the letter @ in the mailbox % onto the proper stack](breakpat1.png)


  (@breakpat2) ![... stick the letter % in the mailbox @ of the vice president](breakpat2.png)

This is supportive of hypothesis 1 presented in the introduction; and, in fact, of a broader formulation of it.

  *Hypothesis 1* \hfill\linebreak
  High attachment of PP2 is marked by a prosodic break between PP1 and PP2.
  
  *Broadened hypothesis 1* \hfill\linebreak
	A change in branching direction is marked by a prosodic break.
  
A change in branching direction is taken to mean the closure of the preceding phrase and attachment into its parent node; in this case, either the closure of PP1 and the attachment off PP2 into the VP or the closure of the object NP and attachment of PP1 into the VP. 

That Reading 2 is a significant predictor in 3 of the 4 analyses where it’s inclusion is possible supports, at least provisionally, hypothesis 2 and 3. 
  

  *Hypothesis 2* \linebreak
  A first reading (no preview) of a GP sentence will exhibit less natural prosody (more hesitation at and after the disambiguating region) than:
    * A first reading of a non-GP sentence.
    * A second reading of a GP sentence.


  *Hypothesis 3* \linebreak
  A first reading of a garden-path sentence will more often be produced with prosodic structure that represents an implausible or ungrammatical parse of the string (low attachment of PP2), whereas a second reading sentence will more often be pronounced with the prosodic structure that represents the intended parse (high attachment of PP2).

It is difficult to know whether a given reading represents more or less natural prosody, but given that there’s a difference, it seems most likely that Reading 2 is the more natural of the two.

It is surprising that the effect of PP2 status is generally lessened in Reading 2 when compared to Reading 1, but this can likely be explained as an epiphenomenon. There is no way to distinguish between prosodic breaks that are intentional and syntactically motivated as compared to those that represent hesitation, a need for a breath, or other factors. It’s likely that some of the effect of PP2 status is actually an increase in hesitation after PP1, and therefore more or longer pauses at that position, which is mitigated in Reading 2. If some readers are, in general, simply producing a break after every phrase, but happen to produce what’s perceived as a dominant break after PP1 in the PP2 argument condition, when they’re confused, that effect of PP2 status will go away in Reading 2 once they’ve had time to figure the sentence out. This might mean that the noise caused by readers that are simply breaking phrase-by-phrase is actually amplified in Reading 2.

That a prosodic break also frequently occurs between phrases when there is no change in branching direction is mitigated somewhat by the fact that such breaks are usually weaker than the ones that do represent such a change. It’s likely that these breaks are actually there for non-syntactic reasons; the end of a phrase represents a reasonable time for the speaker to take a breath or pause briefly for processing reasons. It’s also likely that some readers are simply producing a break after each phrase.

Speech act is a significant predictor of PP1 break dominance (β=0.31, std. error = 0.15, p < 0.05)., but not of any of the other outcomes. It’s plausible that the PP1 break is more likely to be dominant in questions than in declaratives because of the need to begin the sentence final rise of question intonation. That there is never an interaction between speech act and PP2 status is discouraging for the hypothesis that it’s the prosody of questions that make the Arg cases seem easier in the interrogative cases compared to the declarative.

## Inter-reading time {#irt}

Inter-reading time is the amount of time after the completion of Reading 1 and before the beginning of phonation of Reading 2. The details of how this was measured and defined can be found in section \@ref(method-irt).

>>> TODO Explain what I see as the importance of IRT

### Data cleanup {#irtDis}

IRTs below 0.25s (2) and above 25.0s (5) were assumed to be implausible and omitted. Experimental data were then Winsorized by participant to bring data below the 2.5% and above the 97.5% threshold to the value at those thresholds. The resulting measure is referred to as wIRT and is distributed as shown in figure \@ref(fig:wIRT) (n = 489).

```{r wIRT,fig.cap="Distribution of wIRT"}
irt_data <- read_csv("export/irt_data.csv")
ggplot(irt_data, aes(wirt/1000)) +
  geom_histogram(binwidth = 0.5,color="white",fill="#333333") + 
  xlab("wIRT (seconds)") + 
  ylab("Frequency") + 
  ggtitle(
    "Distribution of wIRT", 
    subtitle="Bin size = 0.5s"
  )
```

Overall mean for wIRT was 6.5s (sd = 3.8). The longest wIRT was 22.2s and the shortest was 0.7s. Median wIRT was 6.1s.

### IRT results {#irtRes}

Table \@ref(tab:mns) shows the mean wIRT for each experimental condition. While mean wIRT increases from modifier PP2 to argument PP2 more for declaratives than for interrogatives, the difference in that increase is very small (0.04s).

```{r}
irt_props <- describe(irt_data$irt)
wirt_props <- describe(irt_data$win_irt)
### sd by condition table
sdByConditionLong <- aggregate(
  irt_data$win_irt,
  by=list(
    "Q"=irt_data$Q,
    "GP"=irt_data$GP
  ),
  FUN=sd
)

### means by condition table
meansByConditionLong <- aggregate(
  irt_data$win_irt,
  by=list(
    "Q"=irt_data$Q,
    "GP"=irt_data$GP
  ),
  FUN=mean
)
names(meansByConditionLong)[3] <- "mean"
### concise means by condition table
meansByCondition <- meansByConditionLong %>% spread(Q,mean) 
names(meansByCondition)[1] <- "Condition"
### add sd and se to meansByConditionLong
meansByConditionLong$sd<-sdByConditionLong$x
meansByConditionLong$se<-sdByConditionLong$x/sqrt(irt_props$n)


### difference in condition means
diffs<-list(Condition="Increase", `D`=diff(meansByCondition$`D`), `Q`= diff(meansByCondition$`Q`))
meansByCondition<-rbind(meansByCondition, diffs)
cdiff <- meansByCondition$`D`[3]-meansByCondition$`Q`[3]

meansByConditionS <- meansByCondition
meansByConditionS$`D` <- meansByConditionS$`D`/1000
meansByConditionS$`Q` <- meansByConditionS$`Q`/1000

meansByConditionS$Condition <- c("Mod", "Arg", "Mod - Arg")
meansByConditionS$`Q - D` <- meansByConditionS$Q - meansByConditionS$D
```
```{r mns}
kable(
  escape=F,
  meansByConditionS, 
  caption = "Means (s) by condition",
  digits = 2
)%>% kable_styling(latex_options = "hold_position")
```

The same numbers are represented visually in figure \@ref(fig:interactionplot)

```{r interactionplot,fig.cap="Mean IRT by condition",fig.height=4}

meansByConditionLong$Qn <- ifelse(
  meansByConditionLong$Q == "Q", 
  "Interrogative", 
  "Declarative"
)

meansByConditionLong$GPn <- ifelse(
  meansByConditionLong$GP == "+GP", 
  "Arg", 
  "Mod"
)

ggplot(
  meansByConditionLong, 
  aes(mean/1000,x=reorder(GPn, desc(GPn)),y=mean/1000,group=Qn,linetype=Qn)
) + 
  geom_line() +
  geom_point() +
  ylim(5.75,7.25) +
  geom_errorbar(aes(ymin=(mean-se)/1000, ymax=(mean+se)/1000), width=.125) +
  labs(
    x="", 
    y="Mean IRT (ms)",
    linetype="",
    title="Mean IRT by condition", 
    subtitle = "Error bars represent one standard error"
  )
```

The two slopes are only very slightly divergent. Notably, both speech act and PP2 status appear to have main effects on wIRT, with interrogatives having longer IRTs than declaratives, and sentences with argument PP2s having substantially longer IRTs than those with modifier PP2s.

Regression models support the observations above. All models discussed include random intercepts for participant and item. Models with random slopes for fixed effects all resulted in singular fits and so random slopes were not included.
	
By hypothesis, the best model for predicting IRT should be one with fixed effects of speech act and PP2 stats and the interaction between them. This model is shown in table \@ref(tab:hyp).


```{r hyp}
csv <- '
FULL MODEL,Estimate,Std. Error,p
D Mod (Intercept),6.32,0.59,< 0.001
Q,0.29,0.3,0.34
Arg,0.42,0.3,0.17
Q x Arg,0.08,0.43,0.85
'

tab <- read_csv(csv)

tab %>% kable(
  align="rccc",  
  caption=
    "Linear mixed effects regression model predicting wIRT by condition with interaction term"
) %>% 
  kable_styling(latex_options = "hold_position")
```

Of the models with subset(s) of these predictors, the best (the model with the lowest AIC) was the one without the interaction term, shown in table 4.14. 


```{r redirt}
csv <- '
REDUCED MODEL,Estimate,Std. Error,p
D Mod (Intercept),6.3,0.58,< 0.001
Q,0.33,0.21,0.12
Arg,0.46,0.21,< 0.05
'

tab <- read_csv(csv)

tab %>% kable(
  align="rccc",  
  caption=
    "Linear mixed effects regression model predicting wIRT by condition"
) %>% 
  kable_styling(latex_options = "hold_position")
```

The difference between the reduced and full model was not statistically significant (AIC~FULL~=9103.5, AIC~REDUCED~=9101.6, $\chi^2$(1)=0.04, p > 0.8).

### On PP2 heads {#pp2h}

As mentioned in the items description (section 3.4), half of the items used of for the head of PP2 in the Mod condition, while half used from. In the Arg condition, half used into and half used onto to head PP2. An analysis that looks at the identity of the PP2 head found that while into and onto do not behave differently, of and from do. Starting from a very complex model that included the lexical identity of the matrix verb, the construction verb, the head of PP1, and the head of PP2, as well as speech act and PP2 status, the model that best predicted wIRT was one that is essentially the same as the reduced model just reported, except it substitutes the lexical identity of the PP2 head for the Arg vs. Mod categorization, with into and onto collapsed into one level of the PP2 factor and used as the reference level. 


```{r pp2hd}
csv <- '
PP2 head model,Estimate,Std. Error,p
D into/onto (Intercept),6.76,0.58,< 0.001
Q,0.32,0.21,0.13
from,-0.08,0.27,0.77
of,-0.84,0.27,< 0.01
'

tab <- read_csv(csv)

tab %>% kable(
  align="rccc",  
  caption=
    "Linear mixed effects regression model predicting wIRT by speech act and PP2 head"
) %>% 
  kable_styling(latex_options = "hold_position")
```

Sentences where PP2 was headed by from typically had wIRTs that were 0.84s faster than sentences where PP2 was headed by into/onto; when the PP2 head was from wIRT was only 0.08s faster than for into/onto. 

## Discussion of IRT results

It’s clear from the above that argument PP2s (ones headed by into/onto) result in longer wIRT measures. It also appears that interrogativity increases wIRT to a lesser extent, regardless of the PP2 status. Because the interaction between the two factors is not a significant predictor of wIRT, we are left to assume that either wIRT does not represent a behavioral reflex of the intuition that interrogativity makes difficult to process PP2-attachment ambiguities easier, or else the current study does not have enough power to detect it.

The difference between from and of PP2s is also potentially a source of noise. The from sentences are less clearly disambiguated than the of sentences. Where (3) has only one reading, (4) has another possible reading, albeit somewhat implausible: i.e., we could imagine that in (3) from her brother-in-law modifies the cookies, while in (4) of the minivan cannot modify the bicycle.

She had intended to put the bicycle on the roof rack of the minivan.
She had decided to cram the cookies in the basket from her brother-in-law.

This lingering ambiguity could have increased wIRT somewhat because the reader, given unlimited time, spent some of that time noticing and then eliminating that possible reading. The difference here can be explained by once again making an appeal to structural parsing vs. structural association: if we imagine that a from PP is associated rather than parsed, the reader is free to consider other possible interpretations. Because of can be seen as less a preposition and more a functional head, it stands to reason that it would be treated different, as something that must be parsed immediately, i.e. that it instantiates a primary relation. 

It could also be a simpler explanation: the fact that of is only two characters, whereas from and into/onto are all four characters, participants may have recognized a pattern, wherein they could be sure that a two character PP2 head meant the sentence did have the difficult properties of some of the ones with four character PP2 heads (most notably those pesky into/onto ones), and eliminated some of the needed study time.

A study where the modifier PP2s are more tightly controlled with regard to the head preposition, both in terms of the length and the properties of the head, might produce clearer results.

## The processing cost of interrogativity

```{r}
library(scales)
library(readr)

irt_fillers <- subset(read_csv("export/all_data.csv"), isFiller)
mean.irtByQ <- aggregate(
  irt_fillers$irt, 
  by=list("Q"=irt_fillers$Condition_Q),
  FUN=mean
)
mean.irtByPP <- aggregate(
  irt_fillers$irt, 
  by=list("+PP"=irt_fillers$Condition_GP),
  FUN=mean
)
mean.irtByQnPP <- aggregate(
  irt_fillers$irt, 
  by=list("Q"=irt_fillers$Condition_Q,"+PP"=irt_fillers$Condition_GP),
  FUN=mean
)
```
It is worth taking note of the fact that the mean wIRT for interrogative versions (6.7s) of the sentences in the reported study was longer than for the declaratives (6.4s). Similarly, @qp2 found that reading times for interrogatives were longer than for declaratives. This is perhaps representative of the processing cost of interrogativity reported by @mehler1963some who found that a so-called kernel sentence, i.e. a simple declarative, was easier to recall verbatim than was a number of sentences that he considered to be syntactic transformations of that kernel sentence (K): negative (N), polar question (Q), passive (P), and combinations thereof: NQ, NP, QP and NPQ. Mehler found that accurate recall was more frequent for K sentences (300/460, `r percent(300/460)`) than for the other sentences types, with interrogatives (210/460, `r percent(210/460)`) being recalled accurately at a lower rate than the two other individual transformations (234/460, `r percent(234/460)` for N; 243/460, `r percent(243/460)` for P).

The filler sentences in this study were designed in two versions, interrogative (Q) and declarative (D), so as to provide a diagnostic of the interrogative effect on IRT independent of the experimental question. A linear mixed effects regression model predicting wIRT for filler items by interrogativity with crossed random intercepts (participant and item) found that wIRT is increased by 0.4s for interrogatives (std. error = 0.2; p < 0.05). Half of the fillers had a sequence of two PPs at the end to mirror the experimental items: a model predicting wIRT by the presence of those PPs found minimal effect on wIRT (β=0.01, std. error = 0.22, p = 0.96).

Interrogative status itself appears to increase the time needed for participants to feel they’ve satisfactorily studied a sentence in order to read it aloud correctly. This is consistent with the @mehler1963some and @qp2 findings that interrogatives are in some way more complicated or difficult than declaratives.


\clearpage
