---
title: "Results and analyses"
author: "Tyler Peckenpaugh"
date: "April 7, 2019"
bibliography: refs.bib
biblio-style: "apalike"
tables: true
output: 
  bookdown::pdf_document2:
    toc: true
    latex_engine: xelatex
    citation_package: natbib
  bookdown::html_document2:  
    toc: true
fontsize: 12pt
mainfont: Cambria
header-includes:
- \usepackage{float}
---
<!-- Results -->
<!-- This is the fourth content sectionî¿¿ -->
<!-- Previous section: methodology -->
<!-- Following section: discussion -->
```{r setup,echo=F,warning=F,message=F}
knitr::opts_chunk$set(
  echo=FALSE, 
  warning=FALSE, 
  message=FALSE, 
  fig.height = 3, 
  fig.pos="H"
)
options(tinytex.verbose = TRUE)
bgcolor <- "#ffffff"
par(bg = bgcolor)

kable <- function(data,...) {
  knitr::kable(data, booktabs = TRUE,...)
}

library(readr)
library(huxtable)
library(dplyr)
library(tidyr)
library(knitr)
library(ggplot2)
library(ggthemes)
library(jsonlite)
library(kableExtra)
library(psych)
library(lme4)

# global plot themeing
theme_set(
  theme_tufte() + 
    theme(
      plot.background = element_rect(fill = bgcolor,color=bgcolor),
      panel.border = element_blank()
    )
)

```

This section reports various analyses of the recordings obtained.

# Prosody {#results-prosody}

```{r prosody-setup}
mdata_raw <- read_csv("../csvs/got_prosody.csv")
# remove items where STRONG == NA (these are the items Sita didn't respond to)
mdata <- mdata_raw[!is.na(mdata_raw$STRONG),]

# code for pairs of SUBJ-ITEM
mdata$pair<-paste(mdata$SID,mdata$IID,sep="-")
n1 <- nrow(mdata)
# filter out rows missing its pair
mdata<-mdata %>% group_by(pair) %>% filter(n()>1)
n2<- nrow(mdata)
missingPairs <- n1-n2

mdata$V<-mdata$V == "YES"
mdata$OBJ<-mdata$OBJ == "YES"
mdata$PP1<-mdata$PP1 == "YES"
mdata$STRUG<-mdata$STRUG == "YES"
mdata$condition <- with(mdata,
  paste(
    ifelse(Condition_Q,"+Q","-Q"),
    ifelse(Condition_GP,"+GP","-GP")
  )
)
mdata$STRONG <- as.factor(mdata$STRONG)
mdata$WEAK <- as.factor(mdata$WEAK)
mdata$Reading <- as.factor(mdata$Reading)
mdata$prosody <- as.factor(mdata$prosody)
mdata$two_level_prosody <- as.factor(mdata$two_level_prosody)
mdata$IID <- as.factor(mdata$IID)
mdata$UID <- as.factor(mdata$UID)
mdata$SID <- as.factor(mdata$SID)
mdata$STRUG_START <- as.factor(mdata$STRUG_START)
mdata$pdom <- mdata$two_level_prosody %in% c("PP1", "PP1 > OBJ")
mdata$odom <- mdata$two_level_prosody %in% c("OBJ", "OBJ > PP1")
mdata$simple2lvl <- ifelse(
  mdata$OBJ & mdata$PP1, 
  "BOTH", ifelse(
    mdata$OBJ,
    "OBJ",
    ifelse(
      mdata$PP1,
      "PP1",
      "NEITHER"
    )
  )
)

mdata<-subset(mdata,SID!=8)
mdata <- droplevels(mdata)
mdata <- subset(mdata,!is.na(OBJ)|!is.na(PP1))
prosDescrip <- describe(mdata)
tot<-as.data.frame(xtabs( ~ Condition_GP + Condition_Q, data=mdata))
write_csv(mdata,"export/prosody_data.csv")
```

This subsection presents the results of the independent rater's judgements regarding prosodic boundaries. Data are excluded if either recording from a pair of recordings (that is, the cold or previewed reading) is missing (excluded `r missingPairs` incomplete pairs) because without the other member, it can't be determined whether the delay before reading constitutes a true cold or true previewed reading. Recordings with no reported breaks are also excluded from most analyses, because these are assumed to be faulty utterances (excluded `r table(mdata$simple2lvl)["NEITHER"]` such recordings) but the paired readings of these are not excluded, because delay information is available for both items.

```{r totByCond}
totDisp <- tot %>% as.data.frame() %>%
  spread(Condition_Q,Freq) 
totDisp[[1]] <- c("-GP", "+GP")
kable(
  totDisp,
  col.names=c(" ", "-Q", "+Q"),
  caption="N by condition"
) %>% kable_styling(latex_options = c("hold_position"))
```

Table \ref{tab:totByCond} shows the number of recordings included in analyses for each condition.


## Breaks after PP1 and direct object

The garden path condition reprents the expected "correct" attachment site of PP1 and PP2. You may recall that the garden path sentences should ultimately have a PP1 that attaches low, as a modifier of the object, and a PP2 that attaches high, as an argument of the verb. To determine whether the prosody is predictive of attachment site, the distributions of breaks directly before PP1 (directly after the object; I call this the "object break") and directly before PP2 (directly after PP1; I call this the "PP1 break") are analyzed.

Across all experimental items, there was a break after the direct object in `r round(nrow(mdata[mdata$OBJ,])/nrow(subset(mdata,!is.na(OBJ)))*100,1)`% of recordings and a break after PP1 in `r round(nrow(mdata[mdata$PP1,])/nrow(subset(mdata,!is.na(PP1)))*100,1)`%.

```{r byGPall}


pp1tab<-xtabs(PP1 ~ Condition_GP + Condition_Q, data=mdata)
objtab<-xtabs(OBJ ~ Condition_GP + Condition_Q, data=mdata)
tot<-as.data.frame(xtabs( ~ Condition_GP + Condition_Q, data=mdata))


pp1<-as.data.frame(pp1tab)
pp1$tot<-tot$Freq
pp1$pct <- pp1$Freq/pp1$tot
pp1$pretty <- paste0(
  pp1$Freq, 
  " (", 
  sprintf("%.1f",pp1$pct * 100), 
  "%)"
)
pp1disp <- pp1 %>%
  subset(select=c(
    "Condition_GP",
    "Condition_Q",
    "pretty"
  )) %>% 
  spread(Condition_Q,pretty)

obj<-as.data.frame(objtab)
obj$tot<-tot$Freq
obj$pct <- obj$Freq/obj$tot
obj$pretty <- paste0(
  obj$Freq, 
  " (", 
  sprintf("%.1f",obj$pct * 100), 
  "%)"
)
objdisp <- obj %>%
  subset(select=c(
    "Condition_GP",
    "Condition_Q",
    "pretty"
  )) %>% 
  spread(Condition_Q,pretty)

pp1obj <- cbind(pp1disp,objdisp[2:3])
pp1obj[[1]] <- c("+GP","-GP")
```
```{r pp1gp}

kable(
  pp1obj,
  caption="Percentage of recordings containing PP1/OBJ break by condition",
  col.names = c("", "-Q", "+Q","-Q", "+Q")
) %>% 
  add_header_above(c(" "=1,"PP1 Break"=2,"OBJ Break"=2)) %>% kable_styling(latex_options = c("hold_position"))
```

Table \ref{tab:pp1gp} shows the presence of object and PP1 breaks by condition.

## Previewed readings only

Because "natural prosody" is likely to be less often produced in a cold reading than in a previewed one, it's important to consider the prosodic patterns for the two readings independently. This subsection describes previewed readings.

```{r byGPr2}

r2data <- subset(mdata,Reading==2)

pp1tab<-xtabs(PP1 ~ Condition_GP + Condition_Q, data=r2data)
objtab<-xtabs(OBJ ~ Condition_GP + Condition_Q, data=r2data)
tot<-as.data.frame(xtabs( ~ Condition_GP + Condition_Q, data=r2data))


pp1<-as.data.frame(pp1tab)
pp1$tot<-tot$Freq
pp1$pct <- pp1$Freq/pp1$tot
pp1$pretty <- paste0(
  pp1$Freq, 
  " (", 
  sprintf("%.1f",pp1$pct * 100), 
  "%)"
)
pp1disp <- pp1 %>%
  subset(select=c(
    "Condition_GP",
    "Condition_Q",
    "pretty"
  )) %>% 
  spread(Condition_Q,pretty)

obj<-as.data.frame(objtab)
obj$tot<-tot$Freq
obj$pct <- obj$Freq/obj$tot
obj$pretty <- paste0(
  obj$Freq, 
  " (", 
  sprintf("%.1f",obj$pct * 100), 
  "%)"
)
objdisp <- obj %>%
  subset(select=c(
    "Condition_GP",
    "Condition_Q",
    "pretty"
  )) %>% 
  spread(Condition_Q,pretty)

pp1obj <- cbind(pp1disp,objdisp[2:3])
pp1obj[[1]] <- c("-GP","+GP")
```

The prevalence of object breaks and PP1 breaks in previewed readings is described in table \ref{tab:r2pp1obj}.

```{r r2pp1obj}
kable(
  pp1obj,
  caption="Percentage of \\underline{previewed} recordings containing PP1/OBJ break by condition",
  col.names = c("", "-Q", "+Q","-Q", "+Q")
) %>% 
  add_header_above(c(" "=1,"PP1 Break"=2,"OBJ Break"=2)) %>% 
  kable_styling(latex_options = c("hold_position"))
```

## PP1 and object breaks combined

Less than 1% of the data had neither break. Those data are excluded.

```{r combobreaksPre}
pdata <- subset(mdata,OBJ|PP1)
allpros <- table(pdata$simple2lvl) %>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Combined breaks", "Percent of all data"))

r2pros<-table(
  subset(pdata,Reading==2)$simple2lvl
) %>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Pattern", "r2")) 

r1pros<-table(
  subset(pdata,Reading==1)$simple2lvl
) %>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Pattern", "r1")) 

allpros$`Cold readings` <- r1pros$r1
allpros$`Previewed readings` <- r2pros$r2
```

```{r combobreaks}
kable(allpros,caption="Combined breaks by reading") %>%
  kable_styling(latex_options = "hold_position")
```

```{r combobreaksBycondPre}
qdata <- subset(pdata,Condition_Q)
ddata <- subset(pdata,!Condition_Q)
qpros<-table(qdata$simple2lvl,qdata$Condition_GP) %>%
  prop.table(margin=2) %>% `*`(100) %>%
  round(1)
colnames(qpros)<-c("-GP","+GP")

dpros<-table(ddata$simple2lvl,ddata$Condition_GP) %>%
  prop.table(margin=2) %>% `*`(100) %>%
  round(1)
colnames(dpros)<-c("-GP","+GP")

combo<-cbind(dpros,qpros)
```

The distrbution of the combined breaks for both readings and for only previewed readings is shown in table \ref{tab:r2combobreaksBycond}.

```{r r2combobreaksBycondpre}
r2pdata<-subset(pdata,Reading==2)
qdata <- subset(r2pdata,Condition_Q)
ddata <- subset(r2pdata,!Condition_Q)
qpros<-table(qdata$simple2lvl,qdata$Condition_GP) %>%
  prop.table(margin=2) %>% `*`(100) %>%
  round(1)
colnames(qpros)<-c("-GP","+GP")

dpros<-table(ddata$simple2lvl,ddata$Condition_GP) %>%
  prop.table(margin=2) %>% `*`(100) %>%
  round(1)
colnames(dpros)<-c("-GP","+GP")

ccombo<-cbind(dpros,qpros)
cccombo<-cbind(combo,ccombo)
```
```{r r2combobreaksBycond}
kable(cccombo,caption="Combined breaks by condition for previewed readings") %>%
  add_header_above(c(" "=1,"Declarative" = 2, "Interrogative"=2,"Declarative" = 2, "Interrogative"=2)) %>%
  add_header_above(c(" "=1,"Both readings" = 4,"Previewed readings"=4)) %>%
  column_spec(1,bold=T)%>% kable_styling(latex_options = "hold_position")

```

## PP1 and object breaks and their relative prominence

Table \ref{tab:pros2lvl} presents data similar to those in the previous section, but it incorporates the rater's judgement of the relative prominence of the breaks. The &gt; symbol indicates that the rater found the break on the left of that symbol to be stronger, or more prominent, than the break on the left. When no symbol is shown between the two breaks, the rather found them to be of equal prominence. Please be aware that inter-rater reliability for relative prominence was not good, as discussed in section \ref{raterRel}.

```{r pros2lvlPre}

# TODO present this table across condition(s)

allpros<-table(mdata$two_level_prosody)%>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Pattern", "Percent of all data"))
r2pros<-table(
  subset(mdata,Reading==2)$two_level_prosody
) %>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Pattern", "r2")) 
r1pros<-table(
  subset(mdata,Reading==1)$two_level_prosody
) %>%
  prop.table() %>% 
  `*` (100) %>%
  round(1) %>%
  hux() %>%
  setNames(c("Pattern", "r1")) 

allpros$`Cold readings` <- r1pros$r1
allpros$`Previewed readings` <- r2pros$r2
```
```{r pros2lvl}
kable(allpros,caption="Prosodic pattern by reading")%>% kable_styling(latex_options = "hold_position")
```

\clearpage

## Prosody models

Models predicting the PP1 break and the object break are presented in table \ref{tab:lmPros}. No random slopes were included, as those models did not converge.

```{r prosmodelsPre,cache=T}
pp1Mod<- glmer(PP1~Reading+Condition_Q*Condition_GP+(1|IID)+(1|SID),data=mdata,family=binomial)
objMod<- glmer(OBJ~Reading+Condition_Q*Condition_GP+(1|IID)+(1|SID),data=mdata,family=binomial)
```
```{r prosmodels}
huxreg(  
  list("PP1"=pp1Mod,"Object"=objMod),
  coefs = c(
    "Intercept"="(Intercept)",
    "GP"="Condition_GPTRUE",
    "Q"="Condition_QTRUE",
    "GP:Q Interaction"="Condition_QTRUE:Condition_GPTRUE",
    "Preview" = "Reading2",
    "Participant"="sd_(Intercept).SID",
    "Item"="sd_(Intercept).IID"
  ),
  statistics = c(
    N="nobs",
    "logLik",
    "AIC"
  )
) %>%
  set_caption("Logistic regression models of prosody") %>%
  set_label("lmPros") %>%
  set_tabular_environment("tabular")
```

\clearpage

# Fluency

This section presents the counts of recordings where the reader struggled to maintain fluency. Table \ref{tab:strug} shows the overall pattern across reading.

```{r strugpre}
all_strug <-table(mdata$STRUG,mdata$Reading)
colnames(all_strug)<-c("Cold reading", "Previewed reading")
row.names(all_strug)<-c("Fluent", "Struggle")
```
```{r strug}
# TODO combine this table and next
kable(all_strug, caption="Difficulty in reading by reading type") %>%
  kable_styling(latex_options = "hold_position")
```

Table \ref{tab:gpstrug} shows the pattern across reading for just +GP items.

```{r gpstrug}
GP_strug <- with(subset(mdata,Condition_GP==TRUE),table(STRUG,Reading))
colnames(GP_strug)<-c("Cold reading", "Previewed reading")
row.names(GP_strug)<-c("Fluent", "Struggle")
kable(GP_strug, caption="Difficulty in reading by reading type for garden paths")%>% kable_styling(latex_options = "hold_position")
```

## Fluency models

Table \ref{tab:strugMod} shows a number of logistic regression models. Models with complex random slope structures failed to converge, and models with random slopes for just *Previewed Reading* were worse than those without random slopes, so the models presented have no random slopes for any predictors. None of the models differ in statistically significant ways, except that the model with no random effects is significantly worse than the others (e.g. no random effects (AIC=575) compared to full model (AIC=547), &Chi;^2^(3)=3, p < 0.001).

```{r strugModelPre,cache=T}
models.strug <- glmer(STRUG~Condition_Q*Condition_GP+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)
models.strug.noRand <- glm(STRUG~Condition_Q+Condition_GP+Reading,data=mdata,family=binomial)
models.strug.noInt <- glmer(STRUG~Condition_Q+Condition_GP+Reading+(1|IID)+(1|SID),data=mdata,family=binomial)
models.strug.noCon <- glmer(STRUG~Reading+(1|IID)+(1|SID),data=mdata,family=binomial)
```
```{r strugMod}
huxreg(
  list(
    "Full"=models.strug, 
    "No interaction"=models.strug.noInt, 
    "Reading only"=models.strug.noCon
  ),
  coefs = c(
    "Intercept"="(Intercept)",
    "+GP"="Condition_GPTRUE",
    "+Q"="Condition_QTRUE",
    "+GP +Q"="Condition_QTRUE:Condition_GPTRUE",
    "Previewed reading" = "Reading2",
    "Participant"="sd_(Intercept).SID",
    "Item"="sd_(Intercept).IID"
  ),
  statistics = c(
    N="nobs",
    "logLik",
    "AIC"
  )
) %>% 
  set_caption("Logistic regression models of disfluency") %>% 
  set_label("strugMod") %>%
  set_latex_float("htbp") %>%
  set_tabular_environment("tabular")


compNoRand <- anova (models.strug,models.strug.noRand)
```

Cold vs. previewed reading is a statistically significant predictor in every case.

\clearpage

# Inter-reading time (IRT) {#results-irt}

```{r irt-setup, cache=T}
itemsDf <- read_csv(
  "../csvs/src/items.csv", 
  col_types = cols(
    OBJ = col_skip(), 
    `P>NP1` = col_skip(), 
    `P>NP2+GP` = col_skip(), 
    `P>NP2-GP` = col_skip(), 
    target = col_character()
  )
)
itemsDf$Item<-itemsDf$target

# load files
use_old <- FALSE
old<-"../csvs/irt-rvad-4_11.csv"
new<-"../csvs/irt-merged.csv"
raw_file <- read_csv(ifelse(use_old,old,new), 
  col_types = cols(
    Item = col_factor(levels = seq(1,48)), 
    Participant = col_character()
  )
)

irt_data <- raw_file

# P 8 is messed up
irt_data<-subset(irt_data,Participant != 8)

# demographics
pmeta <- read_csv("../csvs/p-meta.csv")
pmeta$Participant <- pmeta$ID
irt_data<-merge(pmeta,irt_data,by="Participant")
irt_data$wkd <- ifelse(irt_data$DOTW == "MONDAY", 1,
                ifelse(irt_data$DOTW == "TUESDAY", 2, 
                ifelse(irt_data$DOTW == "WEDNESDAY", 3, 
                ifelse(irt_data$DOTW == "THURSDAY", 4, 
                5))))


# counts
irt_data$Participant <- as.factor(irt_data$Participant)
irt_data$Participant <- relevel(irt_data$Participant,ref=9)
recs<-nrow(irt_data)
subjs<-length(levels(irt_data$Participant))
items<-length(levels(irt_data$Item))
expectN <- subjs * items
  
irt_data$cond <- paste(
  ifelse(irt_data$Condition_Q,"+Q","-Q"),
  ifelse(
    irt_data$isFiller,
    ifelse(irt_data$Condition_GP,"+PP","-PP"),
    ifelse(irt_data$Condition_GP,"+GP","-GP")
  )
)

irt_data$Q <- ifelse(
  irt_data$Condition_Q,
  "+Q",
  "-Q"
)
irt_data$GP <- ifelse(
  irt_data$Condition_GP,
  "+GP",
  "-GP"
)

# utterance lengths
if(!use_old){
  # only available in newer files
  uls <- append(irt_data$`R1 UL`,irt_data$`R2 UL`)
  uls_desc <- describe(uls)
  uls_r1_desc <- describe(irt_data$`R1 UL`)
  uls_r2_desc <- describe(irt_data$`R2 UL`)
}

irt_props_all <- describe(irt_data$irt)
irt_data_all <- irt_data # data before trimming

# exclude 250 < IRTs > 25000
irt_min <- 250
irt_max <- 25000

# note how many IRTs are excluded for implausibility
irt_lo <- subset(irt_data, irt < irt_min)
irt_hi <- subset(irt_data, irt > irt_max)

# subset to trimmed items
irt_data <- subset(
  irt_data, 
  irt > irt_min & irt < irt_max
)
# with fillers
irt_data_allitems <- irt_data
irt_fillers <- subset(irt_data,isFiller)
# experimental only
irt_data <- subset(irt_data,!isFiller)
irt_data <- (merge(itemsDf, irt_data, by = 'Item'))
# make Participant and Item factors with specified ref levels 
irt_data$Participant<-relevel(irt_data$Participant,ref=5)
irt_data$Item<-relevel(as.factor(irt_data$Item),ref=1)
# winsorize top/bottom 5% of data (for normal distrbution, this is +/- 2sd)
# see: https://sciencing.com/relationship-between-standard-deviations-percentiles-8768703.html
win_trim=0.05
irt_data <- irt_data %>% group_by(Participant) %>% mutate(win_irt = winsor(irt, trim=win_trim))

# log 10 transform
irt_data$wirt.log10 <- log10(irt_data$win_irt)

# note properties
irt_props <- describe(irt_data$irt)
wirt_props <- describe(irt_data$win_irt)

# sd by condition table
sdByConditionLong <- aggregate(
  irt_data$win_irt,
  by=list(
    "Q"=irt_data$Q,
    "GP"=irt_data$GP
  ),
  FUN=sd
)
# means by condition table
meansByConditionLong <- aggregate(
  irt_data$win_irt,
  by=list(
    "Q"=irt_data$Q,
    "GP"=irt_data$GP
  ),
  FUN=mean
)
names(meansByConditionLong)[3] <- "mean"
# concise means by condition table
meansByCondition <- meansByConditionLong %>% spread(Q,mean) 
names(meansByCondition)[1] <- "Condition"
# add sd and se to meansByConditionLong
meansByConditionLong$sd<-sdByConditionLong$x
meansByConditionLong$se<-sdByConditionLong$x/sqrt(irt_props$n)


# difference in condition means
diffs<-list(Condition="Increase", `-Q`=diff(meansByCondition$`-Q`), `+Q`= diff(meansByCondition$`+Q`))
meansByCondition<-rbind(meansByCondition, diffs)
cdiff <- meansByCondition$`-Q`[3]-meansByCondition$`+Q`[3]

# participant means by condition
pmeansByCondition <- aggregate(
  irt_data$irt,
  by=list(
    "Condition"=irt_data$cond,
    "Participant"=irt_data$Participant
  ),
  FUN=mean
) %>% spread(Condition,x) 
pmeansByCondition$pattern <- (
  pmeansByCondition$`+Q +GP` - pmeansByCondition$`+Q -GP` <
  pmeansByCondition$`-Q +GP` - pmeansByCondition$`-Q -GP`
) 

# simple P means
spm <- aggregate(
  irt_data$irt,
  by=list(
    "Participant"=irt_data$Participant
  ),
  FUN=mean
) 

# meta 
json <- read_file("../meta-4_11.json")
meta<-fromJSON(json)
handset <- read.csv("../csvs/_SITA_SET_VALUES.csv")
meta[meta$file %in% handset$Filename,]$agg <- NA
meta[meta$file %in% handset$Filename,]$hpf <- NA
hscount <- sum(handset$Filename %in% meta$file)


write_csv(irt_data_allitems,"export/all_data.csv")
```

This document examines the inter-reading time (IRT) from the study. IRT was measured over `r recs` recordings: 32 participants, 48 items = `r subjs * items` recording pairs (reading 1 and reading 2), with `r  subjs * items - recs` missing pairs. The missing data are a result of one or both recordings from a pair being unusable due to technical issues (e.g. a failure of recording equipment, or participant error).

## Distribution of IRT

The raw IRTs including fillers and before any outliers are trimmed are distributed as shown in Figure \ref{fig:rawIRThist}. Overall mean IRT of these data (n = `r irt_props_all$n`), is `r round(irt_props_all$mean/1000,1)`s. The longest is `r round(irt_props_all$max/1000,1)`s and the shortest `r round(irt_props_all$min,0)`ms. Median IRT is `r round(irt_props_all$median/1000,1)`s.

```{r rawIRThist,fig.cap="Distribution of raw IRT"}
histSettings = geom_histogram(binwidth = 500,color="white",fill="#333333")
ggplot(irt_data_all, aes(irt)) +
  histSettings +
  xlab("Raw IRT") + 
  ylab("Frequency")
```

IRTs below `r irt_min`ms (`r nrow(irt_lo)`) and above `r round(irt_max/1000,1)`s (`r nrow(irt_hi)`) are (assumed to be implausible) omitted. Experimental data were then Winsorized by participant to bring data in the `r win_trim*100`th and `r 100-(100*win_trim)`th percentile of data to the value at those tresholds. The resulting measure is referred to as wIRT and is distribued as shown in Figure \ref{fig:wIRT} (n = `r wirt_props$n`). Overall mean for wIRT is `r round(wirt_props$mean/1000,1)`s. The longest IRT is `r round(wirt_props$max/1000,1)`s and the shortest is `r round(wirt_props$min,0)`ms. Median wIRT is `r round(wirt_props$median/1000,1)`s.

```{r wIRT,fig.cap="Distribution of wIRT"}
ggplot(irt_data, aes(win_irt)) +
  histSettings + 
  xlab("wIRT") + ylab("Frequency") + 
  ggtitle(
    "Distribution of wIRT (ms)", 
    subtitle="Bin size = 500ms"
  )
```

For the purposes of regression analysis, a common log transformation reduces the skew in the data. This distribution is seen in Figure \ref{fig:log10wins}.

```{r log10wins,fig.cap="Common log of wIRT"}
ggplot(irt_data, aes(wirt.log10)) +
  geom_histogram(binwidth = 0.1, color="white",fill="#333333") + 
  xlab("Common log of wIRT") + ylab("Frequency") + 
  ggtitle("Distribution of Common Log of wIRT", subtitle="Bin size = 0.1")

```

\clearpage

## Means by condition

Table \ref{tab:mns} shows the mean wIRT by experimental condition. The top left cell represents the mean wIRT for the declaritive controls ("-Q -GP"). The bottom row shows the increase in IRT across the garden path condition. 

```{r mnspre}
meansByConditionS <- meansByCondition
meansByConditionS$`-Q` <- meansByConditionS$`-Q`/1000
meansByConditionS$`+Q` <- meansByConditionS$`+Q`/1000
```
```{r mns}
kable(
  meansByConditionS, 
  caption = "Means (s) by condition",
  digits = 2
)%>% kable_styling(latex_options = "hold_position")
```

The difference in the effect of &plusmn;GP across &plusmn;Q is `r round(cdiff/1000,2)`s. That is, the mean amount that IRT increased for a garden path declarative compared to a non-garden path declarative is `r round(cdiff/1000,2)`s `r ifelse(cdiff > 0, paste("more"),paste("less"))` than the amount that IRT increased for a garden path interrogative compared to a non-garden path interrogative.

```{r interactinplot,fig.cap="Mean IRT by condition",fig.height=4}

meansByConditionLong$Qn <- ifelse(
  meansByConditionLong$Q == "+Q", 
  "Interrogative", 
  "Declarative"
)

meansByConditionLong$GPn <- ifelse(
  meansByConditionLong$GP == "+GP", 
  "Garden path", 
  "Non-garden path"
)

ggplot(
  meansByConditionLong, 
  aes(mean,x=GPn,y=mean,group=Qn,linetype=Qn)
) + 
  geom_line() +
  geom_point() +
  ylim(6000,7200) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.125) +
  labs(
    x="", 
    y="Mean IRT (ms)",
    linetype="",
    title="Mean IRT by condition", 
    subtitle = "Confidence intervals represent one standard error"
  )
```

\clearpage

## Regression models of IRT

The models with random slopes for participant and item did not converge, so the tables in this section show models with no random slopes. 

```{r lmeMods, cache=T}

irt.full <- lme4::lmer(
  wirt.log10 ~ Condition_Q * Condition_GP + 
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noInteraction <- lme4::lmer(
  wirt.log10 ~ Condition_Q + Condition_GP + 
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noParticipant <- lme4::lmer(
  wirt.log10 ~ Condition_Q * Condition_GP + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noItem <- lme4::lmer(
  wirt.log10 ~ Condition_Q * Condition_GP + 
    (1 | Participant),
  data = irt_data,
  REML=F
)

irt.noFxd <- lme4::lmer(
  wirt.log10 ~
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noRand <- lm(wirt.log10 ~ Condition_Q * Condition_GP,
                 data = irt_data)

irt.dummy <- lm(wirt.log10 ~ Condition_Q * Condition_GP,
                  data = irt_data
                )
irt.dummy.noInt <- lm(wirt.log10 ~  Condition_Q + Condition_GP + 
                  Participant + Item,
                  data = irt_data
                )

irt.demoModel.KS <- lmerTest::lmer(
  wirt.log10 ~ Condition_Q * Condition_GP + Semester + wkd + Gender + ease + timeslot +
    bookReading + lightReading + Monolingual + (1|Participant) + (1|Item), 
  data = irt_data,
  REML=F
)
irt.demoModel <- lmerTest::lmer(
  wirt.log10 ~ Condition_Q * Condition_GP + Semester + wkd +
    Monolingual + (1|Participant) + (1|Item), 
  data = irt_data,
  REML=F
)
```

For the first model, fixed effects of &plusmn;GP and &plusmn;Q as well is the interaction between them were included, along with random effects of participant and item. The second model removes the interaction, but keeps both main effects.

```{r modTabLME}
huxreg(
  list(
    "Full"=irt.full, 
    "No interaction"=irt.noInteraction,
    "No random effects"=irt.noRand,
    "No fixed effects"=irt.noFxd
  ),
  coefs = c(
    "+GP"="Condition_GPTRUE",
    "+Q"="Condition_QTRUE",
    "+GP +Q"="Condition_QTRUE:Condition_GPTRUE"
  ),
  note=NULL,
  statistics = c(N="nobs","logLik","AIC")
) %>% 
  set_caption("Models") %>% 
  set_label("tab:models") %>%
  set_tabular_environment("tabular")
```

A model with no fixed effects and one with no random effects were also run. The estimates from these models can be seen in table \ref{tab:models}. 

\clearpage

Several model comparisons were made, seen in tables \ref{tab:modCom3}, \ref{tab:modCom}, and \ref{tab:modCom2}.

```{r modCom3}
cols <- c(
  "Df",
  "AIC",
  "BIC",
  "logLik",
  "deviance",
  "$\\chi^2$",
  "Df($\\chi$)",
  "Pr(>$\\chi^2$)"
)
comp <-anova(irt.full,irt.noFxd)
row.names(comp) <- c("No fixed effects", "Full")
kable(comp,caption="Full model vs. no fixed effects",col.names=cols,escape=F)
```

There are clearly main effects of both &plusmn;GP and &plusmn;Q: table \ref{tab:modCom3} shows that the full model is significantly better than the one with no fixed effects. 

```{r modCom}

comp <-anova(irt.full,irt.noInteraction)
row.names(comp) <- c("No interaction", "Full")
kable(comp,caption="Full model vs. no interaction",col.names=cols,escape=F)

```

The interaction between main effects, though, is not able to be confirmed (in fact, table \ref{tab:modCom} shows the non-interaction to be better, but not to a stastically significance degree).

```{r modCom2}
comp <- anova(irt.full,irt.noRand)
row.names(comp) <- c("No random effects", "Full")

kable(comp,caption="Full model vs. no random effects",col.names=cols,escape=F)
# tab <- hux(comp[,c(1:2,4,6:8)],autoformat = T)
# tab <- add_rows(
#   tab, 
#   hux("Df","AIC","logLik","&Chi;<sup>2</sup>","Df(&Chi;)","p value"),
#   after=0
# )
# tab <- insert_column(
#   tab, c("","No random effects", "Full")
# )
# 
# tab %>% set_escape_contents(F,row=1,col=5:7) %>%
#   set_number_format(value=2,col = c(3:5,7),row=2:3) %>%
#   set_label("tab:modComp2") %>% 
#   set_caption("No random effects vs. full model") %>%
#   set_top_border(row=1,value=1,col=everywhere) %>%
#   set_bottom_border(row=1,value=1,col=2:7) %>% 
#   set_bottom_border(row=final(1),value=1,col=everywhere) 
```

Table \ref{tab:modCom2} shows that the random effects of participant and item improve the model in a stastically signifcant way.

\clearpage

## Effect of verb on IRT

If we consider the mean wIRT by which of the 4 verbs occured in the target sentence (*cram*, *set*, *put*, or *stick*), we see that there was some difference in how the two experimental manipulations (&plusmn;GP = garden path status and &plusmn;Q = interrogative vs. declarative status) effected wIRT. The means (and standard deviation) across the conditions are reported for each verb in table \ref{tab:verbConMeans}.

```{r verbMeans}
# means by condition table
meansByVerb <- aggregate(
  irt_data$win_irt/1000,
  by=list(
    "Condition"=irt_data$cond,
    "Verb"=irt_data$V
  ),
  FUN=mean
) %>% spread(Condition,x)
# sd by condition table
sdByVerb <- aggregate(
  irt_data$win_irt/1000,
  by=list(
    "Condition"=irt_data$cond,
    "Verb"=irt_data$V
  ),
  FUN=sd
) %>% spread(Condition,x)
meansByVerb$`Declarative GP effect`<-meansByVerb$`-Q +GP`-meansByVerb$`-Q -GP`
meansByVerb$`Interrogative GP effect`<-meansByVerb$`+Q +GP`-meansByVerb$`+Q -GP`
meansByVerb$`Difference in effect`<-meansByVerb$`Declarative GP effect`-meansByVerb$`Interrogative GP effect`
```

```{r verbConMeans}
meansNsd<-sdByVerb
for (col in colnames(meansNsd)[2:5]){
  meansNsd[[col]]<- paste(
    round(meansByVerb[[col]],1), 
    " (",
    round(meansNsd[[col]],1),
    ")",
    sep=""
  )
}

kable(
  meansNsd,
  caption="Mean (sd) wIRT by condition and verb in seconds"
) %>% 
  kable_styling(latex_options = "hold_position")
```

To isolate the effect of the garden path for interrogatives as compared to declartives, we can subtract the mean for declarative non-garden paths from the mean for declarative garden paths, and then do the same for interrogatives. These measures are referred to as the "declarative GP effect" and "interrogative GP effect" in \ref{verbConDiffMeans}. The difference between the declarative GP effect from the interrogative GP effect is labeled the "difference in effect." We can see that for 2 of the 4 verbs (*set* and *stick*), there was a positive difference in effect, while for the other two we find a negative one.

```{r verbConDiffMeans}
kable(meansByVerb[,c(1,6:8)],caption="Effect of GP on wIRT by verb", digits=1) %>% kable_styling(latex_options = "hold_position")
```
## Individual variation in IRT

Individuals vary with regard to the effect of the garden path condition on IRT. For `r table(pmeansByCondition$pattern)["TRUE"]` of `r nrow(pmeansByCondition)`, the increase in IRT for garden paths is greater for interrogatives than it is for declaratives.

```{r pPattern}
kable(
  pmeansByCondition[c(1:5)],
  caption="Mean wIRT (ms) by condition and participant",
  longtable=T
)%>% kable_styling(latex_options = c("hold_position", "repeat_header"))
```

\clearpage

## Interrogative processing cost is represented in IRT

Interrogatives appear to have a computational processing cost when compared to interrogatives [cf. @lehiste1973phonetic]. The filler sentences in this study were designed so as to provide a diagnostic of the interrogative effect on IRT. 

```{r fillers, results="asis"}
mean.irtByQ <- aggregate(
  irt_fillers$irt, 
  by=list("+Q"=irt_fillers$Condition_Q),
  FUN=mean
)
mean.irtByPP <- aggregate(
  irt_fillers$irt, 
  by=list("+PP"=irt_fillers$Condition_GP),
  FUN=mean
)
mean.irtByQnPP <- aggregate(
  irt_fillers$irt, 
  by=list("+Q"=irt_fillers$Condition_Q,"+PP"=irt_fillers$Condition_GP),
  FUN=mean
)
fillerModel <- lmer(irt ~ Condition_Q + (1 |Participant) + (1 |Item),data=irt_fillers, REML=F)
fillerModel.pp <- lmer(irt ~ Condition_Q * Condition_GP + (1|Participant) + (1 |Item),data=irt_fillers, REML=F)
fillerModel.ppNoInt <- lmer(irt ~ Condition_Q + Condition_GP + (1|Participant) + (1 |Item),data=irt_fillers, REML=F)

huxreg(
  list("Only Interogitivity"=fillerModel,"Full"=fillerModel.pp,"No interaction"=fillerModel.ppNoInt),
  number_format = 2, 
  coefs=c(
    "(Intercept)"="(Intercept)",
    "+Q" = "Condition_QTRUE",
    "+GP" ="Condition_GPTRUE",
    "+Q * +GP" = "Condition_QTRUE:Condition_GPTRUE" 
  )
) 
```

The mean IRT for interrogative fillers was `r round(mean.irtByQ[1,]$x/1000,1)`s; for declarative, `r round(mean.irtByQ[1,]$x/1000,1)`s. Interrogatives elicited a mean IRT of `r round(diff(mean.irtByQ$x),0)`ms longer than declaratives. Half of the fillers had a string of two PPs at the end. This did not impact IRT to the same degree (a difference of `r abs(round(diff(mean.irtByPP$x),0))`ms across &plusmn;PP).

A mixed effects regression model (no random slope structure, due to convergence errors) found a significant main effect of &plusmn;Q (estimate = 379ms, t = 2.24, p < 0.05)

\clearpage

# Delay comparison for cold vs. previewed readings

A comparison of the delay for cold readings compared with that of previewed readings can lend insight into the extent to which subjects followed task instructions.

"Delay" here is the amount of time after the start of a recording until the beginning of phonation of the target sentence. Cold readings are also called "reading 1", while previewed readings are the same as "reading 2". Implausible delays of >15s are excluded in the data shown here.

```{r delayComparison, fig.cap="Delay comparison across reading"}
raw_rs_file <- read_csv("../csvs/merged.csv")
raw_rs_file <- subset(raw_rs_file,!Participant %in% c(8))
raw_rs <- subset(raw_rs_file,!isFiller & Leading < 15000)
raw_rs$reading <- raw_rs$Reading
raw_rs$Reading <- ifelse(raw_rs$reading == 1, "Cold", "Previewed")
ggplot(raw_rs, aes(Leading, fill = Reading)) +
  geom_histogram(binwidth = 400,position="dodge",color="black") +
  scale_fill_manual(values=c("black","white")) +
  ggtitle("Distribution of delay by reading", 
          subtitle = "Bin size = 400ms")

diffs <- raw_rs[c("Reading","Leading","Participant","Item","isFiller",
                  "Condition_Q","Condition_GP")]  %>% spread(Reading,Leading)

diffs$diffs <- diffs$Previewed-diffs$Cold
diffDis<- describe(diffs$diffs)
diffsByP<-aggregate(diffs~Participant,data=diffs,FUN=function(x){round(mean(x))})
colnames(diffsByP) <- c("Participant", "Mean difference in delay (ms)")
diffsByP.props <- describe(diffsByP$`Mean difference in delay (ms)`)
```

For cold readings, n = `r table(raw_rs$Reading)["Cold"]` and for previewed, n = `r table(raw_rs$Reading)["Previewed"]`. 

## Reading 1 delays by participant

```{r}
r1data <- subset(raw_rs, reading == 1)
r1delByP <- aggregate(r1data$Leading,by=list("Participant" = r1data$Participant), FUN=mean)
hidel <- mean(r1delByP$x) + sd(r1delByP$x)/2
lodel <- mean(r1delByP$x) - sd(r1delByP$x)/2
r1delByP$r1DelCat <- ifelse(r1delByP$x < lodel, "FAST", ifelse(
  r1delByP$x > hidel, "SLOW", "NORMAL"
))

colnames(r1delByP)[2] <- "r1delbyp"

irt_data<-merge(r1delByP,irt_data,by="Participant")
mdata$Participant <- mdata$SID
mdata<-merge(r1delByP,mdata,by="Participant")
write_csv(irt_data,"export/exp_wins_irt.csv")
```
```{r}
del.irt.full <- lmerTest::lmer(
  wirt.log10 ~ Condition_Q * Condition_GP * r1DelCat +
    (1 | Participant) + 
    (1 | Item),
  data = subset(irt_data,r1DelCat != "NORMAL"),
  REML=F
)

mmdata <- subset(mdata,r1DelCat != "NORMAL" & Reading == 2)
del.pp1Mod<- glmer(PP1~Condition_Q*Condition_GP*r1DelCat+
                     (1|IID)+(1|SID),data=mmdata,family=binomial)
del.objMod<- glmer(OBJ~Condition_Q*Condition_GP*r1DelCat+
                     (1|IID)+(1|SID),data=mmdata,family=binomial)
summary(del.irt.full)
summary(del.pp1Mod)
summary(del.objMod)
```

## Difference in delay across paired readings

Overall, each recording pair (n = `r diffDis$n`) has a mean difference in delay (DelDif = previewed delay - cold delay) of `r round(diffDis$mean/1000,1)`s (sd = `r round(diffDis$sd/1000,1)`s), with a minumum of `r round(diffDis$min/1000,1)`s and a max of `r round(diffDis$max/1000,1)`s. The median DelDif is `r round(diffDis$median/1000,1)`s. The distribution DelDif is shown in Figure \ref{fig:deddif}.

```{r deddif, fig.cap="Distribution of DelDif"}
ggplot(na.omit(diffs), aes(diffs)) +
  geom_histogram(binwidth = 500,color="white",fill="black") +
  labs(x="Difference in delay", y="Count",
       title="Distribution of difference in delay", subtitle="Bin width = 500ms")
```

If we calculate the mean delay difference by participant, we find a mean participant DelDef of `r round(diffsByP.props$mean/1000,1)`s. Each participant's DelDif is &le; `r diffsByP.props$min`ms and &ge; `r round( diffsByP.props$max/1000,1)`s, with a median of `r round(diffsByP.props$median/1000,2)`s. Table \ref{tab:difsbyp} shows these values.

```{r difsbyp}
kable(
  diffsByP[order(diffsByP[,2]),],
  row.names=F,
  digits = 0,
  caption="Delay differences by participant",
  longtab=T
)%>% kable_styling(latex_options = c("hold_position", "repeat_header"))
```

The distribution of the participants' DelDifs can be found in Figure \ref{fig:difhistbyp}.

```{r difhistbyp, fig.cap="Mean difference in delay by participant"}
ggplot(diffsByP, aes(`Mean difference in delay (ms)`/1000)) +
  geom_histogram(binwidth = 1,color="white",fill="black") +
  labs(x="Mean difference in delay", y="Count",title="Mean difference in delay by participant", subtitle="Bin size = 1s")
```
\pagebreak

# Additional tables and figures {#etc}

Addtional figures and tables appear here without discussion, for the curious reader.

```{r irtzoomLft, fig.cap="Left tail of raw IRT distribution"}
ggplot(subset(irt_data_all,irt<1000), aes(irt)) +
  geom_histogram(binwidth = 50,color="white",fill="#333333") + 
  xlab("Raw IRT") + ylab("Frequency") + 
  ggtitle("Left tail of IRT distribution (ms)",subtitle="IRT < 1s, bin size = 50ms")
```


```{r zoomRgt, fig.cap="Right tail of raw IRT distribution"}
ggplot(subset(irt_data_all,irt>22000), aes(irt/1000)) +
   geom_histogram(binwidth = 1, color="white", fill="#333333") +
  xlab("Raw IRT") + ylab("Frequency") + 
  ggtitle("Right tail of IRT distribution (s)", subtitle="IRT > 22s, bin size = 1s")
```

\clearpage
\pagebreak

`r if (knitr::is_html_output()) '# References {-}'`