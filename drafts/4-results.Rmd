# Results

This section reports various analyses of the recordings obtained. The analyses include the effect of sentence type (declarative vs. interrogative, garden path vs. non-garden path) on the location of prosodic breaks, as well as "study" or inter-reading time (IRT). In order to evaluate the extent to which participants followed the instruction to read immediately for reading 1 and then study the sentence for reading 2, the amount of time that a sentence is displayed before a participant begins to read it (delay) is also discussed and compared across reading 1 vs. reading 2.

## Participants in the reported analyses

There is a total of 32 participants included, 48 total items, 16 of which are experimental items, with each item read twice by each participant. The 32 filler items are not included in analyses except where specified. The same recordings are used for all analyses.

```{r results_setup,echo=F,warning=F,message=F}
knitr::opts_chunk$set(
  echo=FALSE, 
  warning=FALSE, 
  message=FALSE, 
  fig.height = 3, 
  fig.pos="H"
)
options(tinytex.verbose = TRUE)
bgcolor <- "#ffffff"
par(bg = bgcolor)

kable <- function(data,...) {
  knitr::kable(data, booktabs = TRUE,...)
}

library(readr)
library(huxtable)
library(dplyr)
library(tidyr)
library(knitr)
library(ggplot2)
library(ggthemes)
library(jsonlite)
library(kableExtra)
library(psych)
library(lme4)

### global plot themeing
theme_set(
  theme_tufte() + 
    theme(
      plot.background = element_rect(fill = bgcolor,color=bgcolor),
      panel.border = element_blank()
    )
)
irt_data <- read_csv("export/irt_data.csv")
irt_data_allitems <- read_csv("export/all_data.csv")
mdata <- read_csv("export/prosody_data.csv")
irt_fillers <- subset(irt_data_allitems,isFiller)
# absolute cutoffs: exclude 250 < IRTs > 25000
irt_min <- 250
irt_max <- 25000
# cutoff ns:
irt_lo <- 2
irt_hi <- 5
# winsor cutoff: +/- %2.5
win_trim=0.025

missingPairs <- 9
```


```{r describe}

### counts
irt_data$Participant <- as.factor(irt_data$Participant)
irt_data$Participant <- relevel(irt_data$Participant,ref=9)
recs<-nrow(irt_data)
subjs<-length(levels(irt_data$Participant))
items<-length(levels(irt_data$Item))
expectN <- subjs * items

# utterance lengths
uls <- append(irt_data$`R1 UL`,irt_data$`R2 UL`)
uls_desc <- describe(uls)
uls_r1_desc <- describe(irt_data$`R1 UL`)
uls_r2_desc <- describe(irt_data$`R2 UL`)

### irt properties
irt_props_all <- describe(irt_data_allitems$irt)
irt_props <- describe(irt_data$irt)
wirt_props <- describe(irt_data$win_irt)

### sd by condition table
sdByConditionLong <- aggregate(
  irt_data$win_irt,
  by=list(
    "Q"=irt_data$Q,
    "GP"=irt_data$GP
  ),
  FUN=sd
)

### means by condition table
meansByConditionLong <- aggregate(
  irt_data$win_irt,
  by=list(
    "Q"=irt_data$Q,
    "GP"=irt_data$GP
  ),
  FUN=mean
)
names(meansByConditionLong)[3] <- "mean"
### concise means by condition table
meansByCondition <- meansByConditionLong %>% spread(Q,mean) 
names(meansByCondition)[1] <- "Condition"
### add sd and se to meansByConditionLong
meansByConditionLong$sd<-sdByConditionLong$x
meansByConditionLong$se<-sdByConditionLong$x/sqrt(irt_props$n)


### difference in condition means
diffs<-list(Condition="Increase", `D`=diff(meansByCondition$`D`), `Q`= diff(meansByCondition$`Q`))
meansByCondition<-rbind(meansByCondition, diffs)
cdiff <- meansByCondition$`D`[3]-meansByCondition$`Q`[3]

### participant means by condition
pmeansByCondition <- aggregate(
  irt_data$irt,
  by=list(
    "Condition"=irt_data$cond,
    "Participant"=irt_data$Participant
  ),
  FUN=mean
) %>% spread(Condition,x) 
pmeansByCondition$pattern <- (
  pmeansByCondition$`Q +GP` - pmeansByCondition$`Q -GP` <
  pmeansByCondition$`D +GP` - pmeansByCondition$`D -GP`
) 

### simple P means
spm <- aggregate(
  irt_data$irt,
  by=list(
    "Participant"=irt_data$Participant
  ),
  FUN=mean
) 

 
prosDescrip <- describe(mdata)
tot<-as.data.frame(xtabs( ~ Condition_GP + Condition_Q, data=mdata))
gtot <- tot

orderMap <- read_csv(
  "../csvs/src/order-p-map.csv",
  col_types = cols(
    ID = col_character(),
    Order = col_character(),
    LIST = col_character()
  )
)

orderMap$Participant <- orderMap$ID
orderMap$ID <- NULL

mdata<-merge(mdata,orderMap,by="Participant")

versiontab <- mdata %>% 
  filter(!duplicated(Participant)) %>%
  with(table("Version"=LIST,Order)) %>%
  addmargins() 

rownames(versiontab)[1:4]<-paste("Version", rownames(versiontab))
```
```{r vtab}
versiontab %>% kable(
  caption="No. of participants per version-order combination",
  col.names = c("1", "2", "Sum"),
  align="c"
) %>% kable_styling() %>% 
  add_header_above(c(" "=1, "Order"=2, " "=1))
```

There were 4 versions of the experiment, and two possible orderings, with approximately equal number of participants for each version-order combination. Ideally there would be 4 participants per version-order combination, but due to participant attrition and issues during data collection, the distribution is as in Table \ref{tab:vtab}.

Some items are missing due to technical issues during data collection. Data are also excluded if either recording from a pair of recordings (reading 1 or reading 2) is missing (there were `r missingPairs` incomplete pairs excluded) because without the other member, it is difficult to determine the extent to which the participant followed instructions (i.e. did not study the sentence before reading 1, did study the sentence before reading 2). Recordings with no reported breaks are excluded from the prosodic analyses, since they are unlikely to represent the reader's intended prosodic structure (there were `r table(mdata$simple2lvl)["NEITHER"]` such recordings). The paired readings of these are not excluded, and IRTs extracted from them are included in the timing analyses, since delay information is available for both readings. Ultimately, `r nrow(mdata)` experimental item recordings are analyzed (`r nrow(irt_data)` pairs). The distribution of these recordings across the experimental item versions is shown in table \ref{tab:totByCond}.

```{r totByCond}
totDisp <- gtot %>% as.data.frame() %>%
  spread(Condition_Q,Freq) 
totDisp[[1]] <- c("-GP", "+GP")
kable(
  totDisp,
  col.names=c(" ", "D", "Q"),
  caption="Number of recordings by condition"
) %>% kable_styling(latex_options = c("hold_position"))
```

If every items for each of the 32 participants had been available and included, the expected number per bin would be `r 32*16/4*2`[^n].

## Prosody {#results-prosody}

This subsection presents the results of the independent rater's judgements regarding prosodic boundaries.

[^n]: There are 32 participants, 16 items, and 2 readings, divided across 4 bins.

The sentences can be informally broken into regions as in (@structure).

  (@structure) [~SUBJ~ She] [~VERBS~ had intended to set] [~OBJ~ the clothes] ~OBJ~ [~PP1~ in the hamper] ~PP1~ [~PP2~ onto the dresser].

In what follows, I will discuss prosodic breaks at the points directly after the direct object (referred to as OBJ) and directly after PP1 (referred to as PP1).

#### Breaks after PP1 and direct object

Because "natural prosody" is likely to be less often produced in Reading 1 than in a Reading 2, it's important to consider the prosodic patterns for the two readings independently. 

```{r byGPr2}
### r2
r2data <- subset(mdata,Reading==2)

pp1tab<-xtabs(PP1 ~ Condition_GP + Condition_Q, data=r2data)
objtab<-xtabs(OBJ ~ Condition_GP + Condition_Q, data=r2data)
tot<-as.data.frame(xtabs( ~ Condition_GP + Condition_Q, data=r2data))


pp1<-as.data.frame(pp1tab)
pp1$tot<-tot$Freq
pp1$pct <- pp1$Freq/pp1$tot
pp1$pretty <- paste0(
  pp1$Freq, 
  " (", 
  sprintf("%.1f",pp1$pct * 100), 
  "%)"
)
pp1disp <- pp1 %>%
  subset(select=c(
    "Condition_GP",
    "Condition_Q",
    "pretty"
  )) %>% 
  spread(Condition_Q,pretty)

obj<-as.data.frame(objtab)
obj$tot<-tot$Freq
obj$pct <- obj$Freq/obj$tot
obj$pretty <- paste0(
  obj$Freq, 
  " (", 
  sprintf("%.1f",obj$pct * 100), 
  "%)"
)
objdisp <- obj %>%
  subset(select=c(
    "Condition_GP",
    "Condition_Q",
    "pretty"
  )) %>% 
  spread(Condition_Q,pretty)

pp1obj <- cbind(pp1disp,objdisp[2:3])
pp1obj[[1]] <- c("-GP","+GP")
r2pp1<-pp1disp
r2obj<-objdisp


### r1
r1data <- subset(mdata,Reading==1)

pp1tab<-xtabs(PP1 ~ Condition_GP + Condition_Q, data=r1data)
objtab<-xtabs(OBJ ~ Condition_GP + Condition_Q, data=r1data)
tot<-as.data.frame(xtabs( ~ Condition_GP + Condition_Q, data=r1data))


pp1<-as.data.frame(pp1tab)
pp1$tot<-tot$Freq
pp1$pct <- pp1$Freq/pp1$tot
pp1$pretty <- paste0(
  pp1$Freq, 
  " (", 
  sprintf("%.1f",pp1$pct * 100), 
  "%)"
)
pp1disp <- pp1 %>%
  subset(select=c(
    "Condition_GP",
    "Condition_Q",
    "pretty"
  )) %>% 
  spread(Condition_Q,pretty)

obj<-as.data.frame(objtab)
obj$tot<-tot$Freq
obj$pct <- obj$Freq/obj$tot
obj$pretty <- paste0(
  obj$Freq, 
  " (", 
  sprintf("%.1f",obj$pct * 100), 
  "%)"
)
objdisp <- obj %>%
  subset(select=c(
    "Condition_GP",
    "Condition_Q",
    "pretty"
  )) %>% 
  spread(Condition_Q,pretty)

pp1objr1 <- cbind(pp1disp,objdisp[2:3])
pp1objr1[[1]] <- c("-GP","+GP")
r1pp1<-pp1disp
r1obj<-objdisp

pp1<-cbind(r1pp1,r2pp1[2:3])
pp1[[1]] <- c("-GP","+GP")

obj<-cbind(r1obj,r2obj[2:3])
obj[[1]] <- c("-GP","+GP")
```

The prevalence of PP1 breaks for each condition in Reading 1 and Reading 2 recordings is described in table \ref{tab:pp1}.

```{r pp1}
kable(
  pp1,
  caption="PP1 break by condition and reading",
  col.names = c("", "D", "Q","D", "Q")
) %>% 
  add_header_above(c(" "=1,"Reading 1"=2,"Reading 2"=2)) %>% 
  kable_styling(latex_options = c("hold_position"))
```


```{r obj}
kable(
  obj,
  caption="OBJ break by condition and reading",
  col.names = c("", "D", "Q","D", "Q")
) %>% 
  add_header_above(c(" "=1,"Reading 1"=2,"Reading 2"=2)) %>% 
  kable_styling(latex_options = c("hold_position"))
```

The primary difference across Readings is in the OBJ break distribution. 

#### PP1 and object breaks combined

It is perhaps more interesting to look at the combined distribution of the breaks: i.e., a sentence can have one of four patterns: OBJ and PP1 breaks are present; only OBJ or only PP1 is present; or neither is present. As mentioned earlier, there were only 5 cases where neither are present, and those are excluded.

```{r r2combobreaksBycondpre}
r2pdata<-droplevels(subset(mdata,Reading==2 & simple2lvl != "NEITHER"))
qdata <- subset(r2pdata,Condition_GP)
ddata <- subset(r2pdata,!Condition_GP)
qpros<-table(qdata$simple2lvl,qdata$Condition_Q) %>%
  prop.table(margin=2) %>% `*`(100) %>%
  round(1)
colnames(qpros)<-c("D","Q")

dpros<-table(ddata$simple2lvl,ddata$Condition_Q) %>%
  prop.table(margin=2) %>% `*`(100) %>%
  round(1)
colnames(dpros)<-c("D","Q")
ccombo<-as.data.frame(cbind(dpros,qpros))
rownames(ccombo)<-c("Both", "OBJ only", "PP1 only")

r1pdata<-droplevels(subset(mdata,Reading==2 & simple2lvl != "NEITHER"))
qdata <- subset(r1pdata,Condition_GP)
ddata <- subset(r1pdata,!Condition_GP)
qpros<-table(qdata$simple2lvl,qdata$Condition_Q) %>%
  prop.table(margin=2) %>% `*`(100) %>%
  round(1)
colnames(qpros)<-c("D","Q")

dpros<-table(ddata$simple2lvl,ddata$Condition_Q) %>%
  prop.table(margin=2) %>% `*`(100) %>%
  round(1)
colnames(dpros)<-c("D","Q")
cccombo<-as.data.frame(cbind(dpros,qpros))
rownames(cccombo)<-c("Both", "OBJ only", "PP1 only")

bothrbothb <- cbind(ccombo,cccombo)

```

```{r combobreaksBycond}
kable(bothrbothb,caption="Breaks (%) by condition",align="c") %>%
  add_header_above(c(" "=1,rep(c("Non-garden path" = 2, "Garden path"=2),2))) %>%
  add_header_above(c(" "=1, "Reading 1" = 4, "Reading 2" = 4)) %>%
  column_spec(1,bold=T)%>% kable_styling(latex_options = "hold_position")

```

Table \ref{tab:combobreaksBycond} shows that for +GP sentences, there are very few instances with the OBJ-only pattern (0.8% in declaratives, 2.5% in interrogatives); whereas that pattern is fairly robust for -GP sentences (31.1% in declaratives, 31.4% in interrogatives). The pattern with both breaks is somewhat more common for +GP sentences (72.1% in declaratives, 71.7% in interrogatives) than -GP (54.1% in declaratives, 43.0% in interrogatives). The PP1-only pattern occurs at about the same rate in +GP interrogatives (25.8%) as in -GP interrogatives (25.6%) and +GP declaratives (27%), but is noticeably less common for -GP declaratives (14.8%).

<!--
todo
consider moving R1 delay analysis here
-->

#### PP1 and object breaks and their relative prominence

Table \ref{tab:pros2lvl} presents data similar to those in the previous section, but it incorporates the rater's judgement of the relative prominence of the breaks. The &gt; symbol indicates that the rater found the break on the left of that symbol to be stronger, or more prominent, than the break on the left. When no symbol is shown between the two breaks, the rather found them to be of equal prominence. Please be aware that inter-rater reliability for relative prominence was not good, as discussed in section \ref{sec:raterRel}.

```{r pros2lvlPre}

r2p2lv<-prop.table(xtabs(~two_level_prosody+condition,data=subset(mdata,Reading==2)),margin = 2) * 100
r1p2lv<-prop.table(xtabs(~two_level_prosody+condition,data=subset(mdata,Reading==2)),margin = 2) * 100

p2lv <- cbind(r1p2lv,s=r2p2lv)
p2lv <- as.data.frame(cbind(p2lv,ord=c(1,2,3,5,4)))
colnames(p2lv) <- paste0(colnames(p2lv),c(rep("",4),rep("-r2",4)))
p2lv <- cbind("Pattern"=rownames(r2p2lv),p2lv)
p2lv <- p2lv %>% arrange(ord)


kable(
  p2lv[1:9], 
  digits = 1, 
  align="c",
  caption="Prosodic pattern type by condition and reading",
  col.names=c("Pattern",rep(colnames(r2p2lv),2))
) %>% 
  add_header_above(c(" "=1, "Reading 1" = 4, "Reading 2" = 4)) %>%
  column_spec(5,border_right = T) %>%
  kable_styling(latex_options = c("hold_position"))


```

Another way of looking at these same data is to think of a recording as being PP1-dominant (i.e., PP1 is the only or the strongest break), OBJ-dominate, or neither. This categorization is useful because it creates binary outcomes that can be subjected to logistic regression analyses. The frequency of these patterns is reported in table \ref{tab:domtab}.

<!-- 

todo 

  * split dom tables into OBJ tables and PP1 table?

-->

```{r domsetup}
pdom <- xtabs(~condition+pdom,data=mdata)%>% prop.table(margin=1)
pdom.r1 <- xtabs(~condition+pdom,data=subset(mdata,Reading==1))%>% prop.table(margin=1)
pdom.r2 <- xtabs(~condition+pdom,data=subset(mdata,Reading==2))%>% prop.table(margin=1)

odom <- xtabs(~condition + odom ,data=mdata) %>% prop.table(margin=1)
odom.r1 <- xtabs(~condition + odom,data=subset(mdata,Reading==1))%>% prop.table(margin=1)
odom.r2 <- xtabs(~condition + odom,data=subset(mdata,Reading==2))%>% prop.table(margin=1)
```

```{r domtab}

# todo -- both readings, 1 break per table, just dom
pp1domn <- cbind(pdom.r1,pdom.r2)* 100
objdomn <- cbind(odom.r1,odom.r2)* 100
domtab<-cbind(pp1domn,objdomn)
kable(
  domtab, 
  caption="Break dominance (%) by condition",
  col.names=c(rep(c("Not dominant", "Dominant"), 4)),
  align="c",
  digits=1
) %>%
  add_header_above(c(" "=1,rep(c("Reading 1" = 2, "Reading 2" = 2),2))) %>%
  add_header_above(c(" "=1,c("PP1" = 4, "OBJ" = 4))) %>%
  column_spec(5,border_right = 1) %>%
  kable_styling(latex_options = c("hold_position"))
```

\clearpage

### Regression models predicting break occurence

Models predicting the PP1 break and the object break are presented in table \ref{tab:lmPros}. No random slopes were included, as models with random slopes did not converge. For all models in this section, the intercept represents the declarative, non-garden path case. Where Reading is included as a factor, the intercept represents Reading 1.

```{r r2prosmod,cache=T}
r2data<-subset(mdata,Reading==2)
# fails to converge
# pp1Mod<- glmer(PP1~Condition_Q*Condition_GP+(1|IID)+(1|SID),data=r2data,family=binomial)
objMod<- glmer(OBJ~Condition_Q*Condition_GP+(1|IID)+(1|SID),data=r2data,family=binomial)
pdomMod<- glmer(pdom~Condition_Q*Condition_GP+(1|IID)+(1|SID),data=r2data,family=binomial)
odomMod<- glmer(odom~Condition_Q*Condition_GP+(1|IID)+(1|SID),data=r2data,family=binomial)
```

```{r prosmodelsPre,cache=T}
both.pp1Mod<- glmer(PP1~Reading+Condition_Q*Condition_GP+(1|IID)+(1|SID),data=mdata,family=binomial)
both.objMod<- glmer(OBJ~Reading+Condition_Q*Condition_GP+(1|IID)+(1|SID),data=mdata,family=binomial)
both.pdomMod<- glmer(pdom~Reading+Condition_Q*Condition_GP+(1|IID)+(1|SID),data=mdata,family=binomial)
both.odomMod<- glmer(odom~Reading+Condition_Q*Condition_GP+(1|IID)+(1|SID),data=mdata,family=binomial)
```



```{r bothprosmodels}
#fails to converge
huxreg(  
  list("PP1"=both.pp1Mod, "OBJ"=both.objMod,"PP1 Dominance"=both.pdomMod,"OBJ Dominance"=both.odomMod),
  coefs = c(
    "Intercept"="(Intercept)",
    "GP"="Condition_GPTRUE",
    "Q"="Condition_QTRUE",
    "GP:Q Interaction"="Condition_QTRUE:Condition_GPTRUE",
    "Reading" = "Reading"
  ),
  statistics = c(
    N="nobs",
    "logLik",
    "AIC"
  )
) %>%
  set_caption("Logistic regression models of prosody") %>%
  set_label("lmPros") %>%
  set_tabular_environment("tabular")
```

Reading is a statistically siginficant predictor for three of the four models shown in table \ref{tab:bothprosmodels}. Models which exclude Reading 1 are shown in \ref{tab:prosmodels}, as these data are more likely to represent true prosodic breaks, or the intended prosody of the reader, rather than mistakes or hesitations. For the models over only Reading 2, the one predicting the presence of a PP1 break failed to converge.

```{r prosmodels}
huxreg(  
  list("OBJ"=objMod,"PP1 Dominance"=pdomMod,"OBJ Dominance"=odomMod),
  coefs = c(
    "Intercept"="(Intercept)",
    "GP"="Condition_GPTRUE",
    "Q"="Condition_QTRUE",
    "GP:Q Interaction"="Condition_QTRUE:Condition_GPTRUE"
  ),
  statistics = c(
    N="nobs",
    "logLik",
    "AIC"
  )
) %>%
  set_caption("Logistic regression models of prosody, Reading 2 only") %>%
  set_label("lmPros") %>%
  set_tabular_environment("tabular")
```

Note that the model predicting the presence of the PP1 break failed to converg, and so is omitted from the Reading 2 only models.
```
TODO 

Models that exclude the interaction term and that exclude Q vs D as predictor
```
\clearpage

## Inter-reading time (IRT) {#results-irt}

This document examines the inter-reading time (IRT) from the study. IRT was measured over `r recs` recordings: 32 participants, 48 items = `r subjs * items` recording pairs (reading 1 and reading 2), with `r  subjs * items - recs` missing pairs. The missing data are a result of one or both recordings from a pair being unusable due to technical issues (e.g. a failure of recording equipment, or participant error).

#### Distribution of IRT and data clean-up {#irtDis}

The raw IRTs for experimental items, before any outliers are trimmed, are distributed as in figure \ref{fig:rawIRThist}. Overall mean IRT of these data (n = `r irt_props_all$n`), is `r round(irt_props_all$mean/1000,1)`s. The longest is `r round(irt_props_all$max/1000,1)`s and the shortest `r round(irt_props_all$min,0)`ms. Median IRT is `r round(irt_props_all$median/1000,1)`s.

```{r rawIRThist,fig.cap="Distribution of raw IRT"}
histSettings = geom_histogram(binwidth = 0.5,color="white",fill="#333333")
ggplot(irt_data, aes(irt/1000)) +
  histSettings +
  xlab("Raw IRT (seconds)") + 
  ylab("Frequency") +  
  ggtitle(
    "Distribution of raw IRT", 
    subtitle="Bin size = 0.5s"
  )
```

IRTs below `r irt_min`ms (`r irt_lo`) and above `r round(irt_max/1000,1)`s (`r irt_hi`) are assumed to be implausible and omitted. Experimental data were then Winsorized by participant to bring data in the `r win_trim*100`th and `r 100-(100*win_trim)`th percentile of data to the value at those tresholds. The resulting measure is referred to as wIRT and is distribued as shown in Figure \ref{fig:wIRT} (n = `r wirt_props$n`). Overall mean for wIRT is `r round(wirt_props$mean/1000,1)`s. The longest wIRT is `r round(wirt_props$max/1000,1)`s and the shortest is `r round(wirt_props$min,0)`ms. Median wIRT is `r round(wirt_props$median/1000,1)`s.

```{r wIRT,fig.cap="Distribution of wIRT"}
ggplot(irt_data, aes(win_irt/1000)) +
  histSettings + 
  xlab("wIRT (seconds)") + 
  ylab("Frequency") + 
  ggtitle(
    "Distribution of wIRT", 
    subtitle="Bin size = 0.5s"
  )
```
\clearpage

#### Means by condition

Table \ref{tab:mns} shows the mean wIRT by experimental condition. The top left cell represents the mean wIRT for the declaritive controls ("D -GP"). The bottom row shows the increase in IRT across the garden path condition. 

```{r mnspre}
meansByConditionS <- meansByCondition
meansByConditionS$`D` <- meansByConditionS$`D`/1000
meansByConditionS$`Q` <- meansByConditionS$`Q`/1000
```
```{r mns}
kable(
  meansByConditionS, 
  caption = "Means (s) by condition",
  digits = 2
)%>% kable_styling(latex_options = "hold_position")
```

The difference in the effect of &plusmn;GP across &plusmn;Q is `r round(cdiff/1000,2)`s. That is, the mean amount that IRT increased for a garden path declarative compared to a non-garden path declarative is `r round(cdiff/1000,2)`s `r ifelse(cdiff > 0, paste("more"),paste("less"))` than the amount that IRT increased for a garden path interrogative compared to a non-garden path interrogative.

```{r interactinplot,fig.cap="Mean IRT by condition",fig.height=4}

meansByConditionLong$Qn <- ifelse(
  meansByConditionLong$Q == "Q", 
  "Interrogative", 
  "Declarative"
)

meansByConditionLong$GPn <- ifelse(
  meansByConditionLong$GP == "+GP", 
  "Garden path", 
  "Non-garden path"
)

ggplot(
  meansByConditionLong, 
  aes(mean/1000,x=GPn,y=mean/1000,group=Qn,linetype=Qn)
) + 
  geom_line() +
  geom_point() +
  ylim(6,7.2) +
  geom_errorbar(aes(ymin=(mean-se)/1000, ymax=(mean+se)/1000), width=.125) +
  labs(
    x="", 
    y="Mean IRT (ms)",
    linetype="",
    title="Mean IRT by condition", 
    subtitle = "Error bars represent one standard error"
  )
```

\clearpage

#### Regression models of IRT

The models with random slopes for participant and item did not converge, so the tables in this section show models with no random slopes. 

```{r lmeMods, cache=T}

irt.full <- lme4::lmer(
  wirt ~ Condition_Q * Condition_GP + 
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noInteraction <- lme4::lmer(
  wirt ~ Condition_Q + Condition_GP + 
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noParticipant <- lme4::lmer(
  wirt ~ Condition_Q * Condition_GP + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noItem <- lme4::lmer(
  wirt ~ Condition_Q * Condition_GP + 
    (1 | Participant),
  data = irt_data,
  REML=F
)

irt.noFxd <- lme4::lmer(
  wirt ~
    (1 | Participant) + 
    (1 | Item),
  data = irt_data,
  REML=F
)

irt.noRand <- lm(wirt ~ Condition_Q * Condition_GP,
                 data = irt_data)

irt.dummy <- lm(wirt ~ Condition_Q * Condition_GP,
                  data = irt_data
                )
irt.dummy.noInt <- lm(wirt ~  Condition_Q + Condition_GP + 
                  Participant + Item,
                  data = irt_data
                )

irt.demoModel.KS <- lmerTest::lmer(
  wirt ~ Condition_Q * Condition_GP + Semester + wkd + Gender + ease + timeslot +
    bookReading + lightReading + Monolingual + (1|Participant) + (1|Item), 
  data = irt_data,
  REML=F
)
irt.demoModel <- lmerTest::lmer(
  wirt ~ Condition_Q * Condition_GP + Semester + wkd +
    Monolingual + (1|Participant) + (1|Item), 
  data = irt_data,
  REML=F
)

irt.summer <- lmerTest::lmer(
  wirt ~ Condition_Q * Condition_GP +
    Monolingual + (1|Participant) + (1|Item), 
  data = subset(irt_data, Semester!="Summer"),
  REML=F
)
```

For the first model, fixed effects of &plusmn;GP and &plusmn;Q as well is the interaction between them were included, along with random effects of participant and item. The second model removes the interaction, but keeps both main effects.

```{r modTabLME}

#todo redo the table display

huxreg(
  list(
    "Full"=irt.full, 
    "No interaction"=irt.noInteraction,
    "No random effects"=irt.noRand,
    "No fixed effects"=irt.noFxd
  ),
  coefs = c(
    "+GP"="Condition_GPTRUE",
    "Q"="Condition_QTRUE",
    "+GP Q"="Condition_QTRUE:Condition_GPTRUE"
  ),
  note=NULL,
  statistics = c(N="nobs","logLik","AIC")
) %>% 
  set_caption("Models") %>% 
  set_label("tab:models") %>%
  set_tabular_environment("tabular")
```

A model with no fixed effects and one with no random effects were also run. The estimates from these models can be seen in table \ref{tab:models}. 

\clearpage

Several model comparisons were made, seen in tables \ref{tab:modCom3}, \ref{tab:modCom}, and \ref{tab:modCom2}.

```{r modCom3}
cols <- c(
  "Df",
  "AIC",
  "BIC",
  "logLik",
  "deviance",
  "$\\chi^2$",
  "Df($\\chi$)",
  "Pr(>$\\chi^2$)"
)
comp <-anova(irt.full,irt.noFxd)
row.names(comp) <- c("No fixed effects", "Full")
kable(comp,caption="Full model vs. no fixed effects",col.names=cols,escape=F)
```

Table \ref{tab:modCom3} shows that the improvement of the full model over the one with with no fixed effects approaches significance (p < 0.1). 

```{r modCom}

comp <-anova(irt.full,irt.noInteraction)
row.names(comp) <- c("No interaction", "Full")
kable(comp,caption="Full model vs. no interaction",col.names=cols,escape=F)

```

The interaction between main effects, though, is not able to be confirmed (in fact, table \ref{tab:modCom} shows the non-interaction to be better, but not to a stastically significance degree).

```{r modCom2}
comp <- anova(irt.full,irt.noRand)
row.names(comp) <- c("No random effects", "Full")

kable(comp,caption="Full model vs. no random effects",col.names=cols,escape=F)
### tab <- hux(comp[,c(1:2,4,6:8)],autoformat = T)
### tab <- add_rows(
###   tab, 
###   hux("Df","AIC","logLik","&Chi;<sup>2</sup>","Df(&Chi;)","p value"),
###   after=0
### )
### tab <- insert_column(
###   tab, c("","No random effects", "Full")
### )
### 
### tab %>% set_escape_contents(F,row=1,col=5:7) %>%
###   set_number_format(value=2,col = c(3:5,7),row=2:3) %>%
###   set_label("tab:modComp2") %>% 
###   set_caption("No random effects vs. full model") %>%
###   set_top_border(row=1,value=1,col=everywhere) %>%
###   set_bottom_border(row=1,value=1,col=2:7) %>% 
###   set_bottom_border(row=final(1),value=1,col=everywhere) 
```

Table \ref{tab:modCom2} shows that the random effects of participant and item improve the model in a stastically signifcant way.

\clearpage

#### Effect of verb on IRT

If we consider the mean wIRT by which of the 4 verbs occured in the target sentence (*cram*, *set*, *put*, or *stick*), we see that there was some difference in how the two experimental manipulations (&plusmn;GP = garden path status and &plusmn;Q = interrogative vs. declarative status) effected wIRT. The means (and standard deviation) across the conditions are reported for each verb in table \ref{tab:verbConMeans}.

```{r verbMeans}
### means by condition table
meansByVerb <- aggregate(
  irt_data$win_irt/1000,
  by=list(
    "Condition"=irt_data$cond,
    "Verb"=irt_data$V
  ),
  FUN=mean
) %>% spread(Condition,x)
### sd by condition table
sdByVerb <- aggregate(
  irt_data$win_irt/1000,
  by=list(
    "Condition"=irt_data$cond,
    "Verb"=irt_data$V
  ),
  FUN=sd
) %>% spread(Condition,x)
meansByVerb$`Declarative GP effect`<-meansByVerb$`D +GP`-meansByVerb$`D -GP`
meansByVerb$`Interrogative GP effect`<-meansByVerb$`Q +GP`-meansByVerb$`Q -GP`
meansByVerb$`Difference in effect`<-meansByVerb$`Declarative GP effect`-meansByVerb$`Interrogative GP effect`
```

```{r verbConMeans}
meansNsd<-sdByVerb
for (col in colnames(meansNsd)[2:5]){
  meansNsd[[col]]<- paste(
    round(meansByVerb[[col]],1), 
    " (",
    round(meansNsd[[col]],1),
    ")",
    sep=""
  )
}

kable(
  meansNsd,
  caption="Mean (sd) wIRT by condition and verb in seconds"
) %>% 
  kable_styling(latex_options = "hold_position")
```

To isolate the effect of the garden path for interrogatives as compared to declartives, we can subtract the mean for declarative non-garden paths from the mean for declarative garden paths, and then do the same for interrogatives. These measures are referred to as the "declarative GP effect" and "interrogative GP effect" in \ref{verbConDiffMeans}. The difference between the declarative GP effect from the interrogative GP effect is labeled the "difference in effect." We can see that for 2 of the 4 verbs (*set* and *stick*), there was a positive difference in effect, while for the other two we find a negative one.

```{r verbConDiffMeans}
kable(meansByVerb[,c(1,6:8)],caption="Effect of GP on wIRT by verb", digits=1) %>% kable_styling(latex_options = "hold_position")
```
#### Individual variation in IRT

Individuals vary with regard to the effect of the garden path condition on IRT. For `r table(pmeansByCondition$pattern)["TRUE"]` of `r nrow(pmeansByCondition)`, the increase in IRT for garden paths is greater for interrogatives than it is for declaratives.

```{r pPattern}
kable(
  pmeansByCondition[c(1:5)],
  caption="Mean wIRT (ms) by condition and participant",
  longtable=T
)%>% kable_styling(latex_options = c("hold_position", "repeat_header"))
```

\clearpage

### Interrogative processing cost is represented in IRT

Interrogatives appear to have a computational processing cost when compared to interrogatives [cf. @mehler1963some, @qp2]. The filler sentences in this study were designed so as to provide a diagnostic of the interrogative effect on IRT. 

```{r fillers, results="asis"}
mean.irtByQ <- aggregate(
  irt_fillers$irt, 
  by=list("Q"=irt_fillers$Condition_Q),
  FUN=mean
)
mean.irtByPP <- aggregate(
  irt_fillers$irt, 
  by=list("+PP"=irt_fillers$Condition_GP),
  FUN=mean
)
mean.irtByQnPP <- aggregate(
  irt_fillers$irt, 
  by=list("Q"=irt_fillers$Condition_Q,"+PP"=irt_fillers$Condition_GP),
  FUN=mean
)
fillerModel <- lme4::lmer(
  irt ~ Condition_Q + (1 |Participant) + (1 |Item), 
  data=irt_fillers, 
  REML=F
)
fillerModel.pp <- lme4::lmer(
  irt ~ Condition_Q * Condition_GP + (1|Participant) + (1 |Item), 
  data=irt_fillers,
  REML=F
)
fillerModel.ppNoInt <- lme4::lmer(
  irt ~ Condition_Q + Condition_GP + (1|Participant) + (1 |Item), 
  data=irt_fillers,
  REML=F
)

huxreg(
  list("Only Interogitivity"=fillerModel,"Full"=fillerModel.pp,"No interaction"=fillerModel.ppNoInt),
  number_format = 2, 
  coefs=c(
    "(Intercept)"="(Intercept)",
    "Q" = "Condition_QTRUE",
    "+GP" ="Condition_GPTRUE",
    "Q * +GP" = "Condition_QTRUE:Condition_GPTRUE" 
  )
) 
```

The mean IRT for interrogative fillers was `r round(mean.irtByQ[1,]$x/1000,1)`s; for declarative, `r round(mean.irtByQ[2,]$x/1000,1)`s. Interrogatives elicited a mean IRT of `r round(diff(mean.irtByQ$x)/1000,1)`s longer than declaratives. Half of the fillers had a string of two PPs at the end (+PP), and the other half had no trailing PPs (-PP). This did not impact IRT to the same degree (a difference of `r abs(round(diff(mean.irtByPP$x/100),2))`s across &plusmn;PP). When we look at -PP only, the impact of interrogativty on mean IRT is 0.3s, and for only +PP it's 0.4s.

A mixed effects regression model (no random slope structure, due to convergence errors) found a significant main effect of &plusmn;Q (estimate = 0.38s, t = 2.24, p < 0.05), but not for &plusmn;PP or the interaction of interrogativity with &plusmn;PP.

\clearpage

## Delay comparison for cold vs. previewed readings

A comparison of the delay for cold readings compared with that of previewed readings can lend insight into the extent to which subjects followed task instructions.

"Delay" here is the amount of time after the start of a recording until the beginning of phonation of the target sentence. Cold readings are also called "reading 1", while previewed readings are the same as "reading 2". Implausible delays of >15s are excluded in the data shown here.

```{r delayComparison, fig.cap="Delay comparison across reading"}
raw_rs_file <- read_csv("../csvs/merged.csv")
raw_rs_file$UID <- as.factor(with(raw_rs_file, paste(Participant,Item,Reading,sep="-")))
raw_rs_file <- subset(raw_rs_file,UID %in% mdata$UID)
raw_rs <- subset(raw_rs_file,!isFiller)
raw_rs$reading <- raw_rs$Reading
raw_rs$Reading <- ifelse(raw_rs$reading == 1, "Cold", "Previewed")
ggplot(raw_rs, aes(Leading/1000, fill = Reading)) +
  geom_histogram(binwidth = 0.5,position="dodge",color="black") +
  scale_fill_manual(values=c("black","white")) +
  ggtitle("Distribution of delay by reading", 
          subtitle = "Bin size = 0.5s")

diffs <- raw_rs[c("Reading","Leading","Participant","Item","isFiller",
                  "Condition_Q","Condition_GP")]  %>% spread(Reading,Leading)

diffs$diffs <- diffs$Previewed-diffs$Cold
diffDis<- describe(diffs$diffs)
diffsByP<-aggregate(diffs~Participant,data=diffs,FUN=function(x){round(mean(x))})
colnames(diffsByP) <- c("Participant", "Mean difference in delay (ms)")
diffsByP.props <- describe(diffsByP$`Mean difference in delay (ms)`)
```

For each reading, n = `r table(raw_rs$Reading)["Cold"]` (total n = `r nrow(raw_rs)`).

# Reading 1 delay category

```{r r1delcatset,echo=F,warning=F,message=F}
knitr::opts_chunk$set(
  echo=FALSE, 
  warning=FALSE, 
  message=FALSE, 
  fig.height = 3, 
  fig.pos="H"
)
options(tinytex.verbose = TRUE)
bgcolor <- "#ffffff"
par(bg = bgcolor)

kable <- function(data,...) {
  knitr::kable(data, booktabs = TRUE,...)
}

ms2s<-function(x,d=2) {
  return (format(x/1000,nsmall=d,digits=d))
}

library(extrafont)
library(readr)
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)
library(ggplot2)
library(psych)
library(ggthemes)

hidel <- 1050
lodel <- 901

mdata <- read_csv("../drafts/export/prosody_data.csv")
raw_rs_file <- read_csv("../csvs/merged.csv")
raw_rs_file$UID <- as.factor(with(raw_rs_file, paste(Participant,Item,Reading,sep="-")))
raw_rs_file <- subset(raw_rs_file,UID %in% mdata$UID)
raw_rs <- subset(raw_rs_file,!isFiller)
raw_rs$reading <- raw_rs$Reading


r1data <- subset(raw_rs, reading == 1)
r1delByP <- aggregate(r1data$Leading,by=list("Participant" = r1data$Participant), FUN=median)

r1delByP$r1DelCat <- ifelse(r1delByP$x < lodel, "FAST", ifelse(
  r1delByP$x > hidel, "SLOW", "NORMAL"
))
catdes <- sprintf("FAST median R1 delay $\\\\leq$ %0.2fs. SLOW median R1 delay $>$ %0.2fs",lodel/1000,hidel/1000)
r1deldes <- describe(r1delByP$x)
```


Reading 1 (R1) delay is the amount of time between the initial display of a sentence and the start of phonation. Participants' median R1 delay ranged from `r ms2s(r1deldes$min)`s to `r ms2s(r1deldes$max)`s with a standard deviation of `r ms2s(r1deldes$sd)`s. As a way of analyzing the protocol, and the extent to which participants performed as expected, participants were categorized based on their median R1 delay. In what follows, a fast median R1 delay is shorter than or equal to `r ms2s(lodel,2)`s, and a slow one is longer than `r ms2s(hidel,2)`s, resulting in 12 participants per category. Ten other participants categorized as "normal" and ignored. The distribution of participants across categories is shown in table \ref{tab:delcat}. These calculations were done over Reading 1 of experimental items (n = `r nrow(r1data)`, with `r 16*32 - nrow(r1data)` missing items).

```{r delcat}
tab <- table(r1delByP$r1DelCat)
tab[c(1,3)] %>% 
  kable(col.names=c("Delay category", "n"), caption="Participants by Reading 1 delay category") %>% 
  kable_styling(full_width = F,latex_options = c("hold_position")) %>% 
  footnote(catdes,escape = F)

colnames(r1delByP)[2] <- "r1delbyp"
mdata$Participant <- mdata$SID
mdata<-merge(r1delByP,mdata,by="Participant")
mdata <- subset(mdata,simple2lvl != "NEITHER")
mdata$condition <- factor(mdata$condition,levels(factor(mdata$condition))[c(1,3,2,4)])
adata<-mdata
```

The prosodic patterns produced by participants categorized as having fast or slow R1 delays were then considered separately from each other, in order to discern whether the preferred break patterns differed across that distinction. Figure \ref{fig:facet} shows the relative distribution of break patterns by condition for participants with fast and slow R1 delays.

```{r facet, fig.cap="Plot of pattern proportions per condition",fig.height=4,fig.pos="H"}

if(!"reading" %in% names(adata)){
  adata$reading <- adata$Reading
}
loadfonts(device="win")
adata$Reading <- paste("Reading", adata$reading)

pdata <- subset(adata, r1DelCat != "NORMAL")

ggplot(pdata,    
    aes(
      x=condition,
      y=..count..,
      fill=reorder(
        simple2lvl,
        ifelse(simple2lvl=="PP1", 1, ifelse(simple2lvl=="OBJ",3,2))
      )
    )) +
  geom_bar(position="fill",color="black",width=0.5) +
  labs(fill="Pattern",x=" ",y=" ",caption="FAST n=12, SLOW n = 12") +
  facet_grid(rows = vars(Reading),cols=vars(r1DelCat)) +
  scale_y_continuous(labels=scales::percent) + 
  scale_fill_brewer(breaks=c("PP1", "BOTH", "OBJ"), palette="Greys") +
  theme_minimal(base_size = 12, base_family="Georgia")
```

The same data are shown numerically in table \ref{tab:rsplit}.

```{r rsplit}
mdata<-subset(adata,reading==1)

fast <- subset(mdata,r1DelCat == "FAST")
slow <- subset(mdata,r1DelCat == "SLOW")

fastTabN <- xtabs(~simple2lvl + condition, data=fast) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)  
slowTabN <- xtabs(~simple2lvl + condition, data=slow) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)


fastTab <- xtabs(~simple2lvl + condition, data=fast) %>% 
  prop.table(margin=2) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)
slowTab <- xtabs(~simple2lvl + condition, data=slow) %>% 
  prop.table(margin=2) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)


tab<-cbind(fastTab,slowTab[2:5])
ntab<-cbind(fastTabN,slowTabN[2:5])
tab[2:9]  <- format(tab[2:9] * 100,nsmall=1,digits=1)
ntab[2:9] <- format(ntab[2:9],digits=0)


tab$m  <- "%"
ntab$m <- "n"
tab <- rbind(tab,ntab)

colnames(tab)[1] <- "Pattern"
colnames(tab)[6:9] <- paste0(colnames(tab)[6:9],".slow")
tab <- arrange(tab,Pattern)
tab <- tab %>% select(Pattern,m,everything())

r1tab<-tab


mdata<-subset(adata,reading==2)

fast <- subset(mdata,r1DelCat == "FAST")
slow <- subset(mdata,r1DelCat == "SLOW")

fastTabN <- xtabs(~simple2lvl + condition, data=fast) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)  
slowTabN <- xtabs(~simple2lvl + condition, data=slow) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)

fastTab <- xtabs(~simple2lvl + condition, data=fast) %>% 
  prop.table(margin=2) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)
slowTab <- xtabs(~simple2lvl + condition, data=slow) %>% 
  prop.table(margin=2) %>% 
  as.data.frame() %>% 
  spread(condition, Freq)


tab<-cbind(fastTab,slowTab[2:5])
ntab<-cbind(fastTabN,slowTabN[2:5])
tab[2:9]  <- format(tab[2:9] * 100,nsmall=1,digits=1)
ntab[2:9] <- format(ntab[2:9],digits=0)


tab$m  <- "%"
ntab$m <- "n"
tab <- rbind(tab,ntab)

colnames(tab)[1] <- "Pattern"
colnames(tab)[6:9] <- paste0(colnames(tab)[6:9],".slow")
tab <- arrange(tab,Pattern)
tab <- tab %>% select(Pattern,m,everything())


tab <- rbind(r1tab,tab)

tab %>% kable(
  align="c",
  caption="Simple break pattern by condition and R1 delay category",
  col.names=c(" "," ", rep(c("D -GP","Q -GP", "D +GP", "Q +GP"),2)), 
  digits=1
) %>% kable_styling() %>%
  column_spec(6,border_right = T) %>%
  collapse_rows(columns = 1) %>%
  add_header_above(c(" " = 2,"FAST (n=12)"=4,"SLOW (n=12)"=4)) %>%
  pack_rows(index = c("Reading 1" = 6, "Reading 2" = 6))%>% 
  footnote(catdes,escape = F)


```

There appears to be a clear difference between the participants categorized as having fast or slow R1 delays in the extent to which they used both breaks, with the slow cateogry of participants preferring more breaks than the fast category of participants. There also seems to be a larger increase in usage of both breaks from Reading 1 to Reading 2 for the fast category than for the slow.

<!-- todo break the above down more -->

Each participants' median R1 delay can be seen in Appendix \ref{sec:r1dbyp}.

\clearpage
<!--
      TODO examine demo data
-->